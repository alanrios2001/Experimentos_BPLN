2. TRABALHOS EM LINGUÍSTICA COMPUTACIONAL 
2.1. Desenvolvimentos em linguística computacional Como agora já sabemos, a Linguística Computacional é a área da ciência Linguística preocupada com o tratamento computacional da linguagem e das línguas naturais. Seus primeiros desenvolvimentos começaram nos anos 1950. Isso faz com que a Linguística Computacional seja uma área relativamente nova em relação à ciência Linguística propriamente dita. Embora o marco mais aceito para o estabelecimento da Linguística como ciência seja o surgimento da chamada “linguística comparativo-histórica” no começo do século XIX, os primeiros estudos linguísticos no Ocidente começaram com gramáticos e filósofos gregos e romanos há cerca de 2.400 anos. No Oriente, especialmente na Índia, a tradição de estudos gramaticais remonta 2.500 anos. Ou seja, se comparássemos à altura de uma girafa (o mais alto animal do planeta) o período de tempo na história em que se têm desenvolvido estudos gramaticais, o tempo de existência da Linguística Computacional não passaria da altura de um hamster. Não à toa estamos ainda recém engatinhando nesse assunto. A Linguística Computacional teve grande impulso graças principalmente a esforços para o desenvolvimento de programas de tradução automática nas décadas de 1950 e 1960, e seu surgimento está intrinsecamente ligado a desenvolvimentos na área da Inteligência Artificial. De acordo com Grisham (1992: 1),  o potencial [dos computadores] para o processamento de linguagem natural foi reconhecido bem cedo no 

 20 desenvolvimento de computadores, e trabalhos em Linguística Computacional — basicamente para tradução automática — começaram na década de 1950 em diversos centros de pesquisa. O rápido crescimento na área, no entanto, aconteceu principalmente a partir do final dos anos 1970.   Hoje em dia, a busca por interfaces mais amigáveis e por softwares voltados para o trabalho com linguagem natural têm motivado muitas pesquisas na área, e diversos são os frutos resultantes de estudos nas áreas da Inteligência Artificial e da Linguística Computacional. Isso não é de surpreender, pois, como observam McDonald & Yazdani (1990: 176), “a pesquisa em PLN pode proporcionar insights bastante úteis sobre processos e representações da linguagem na mente humana, apontando, assim, para a verdadeira IA” TP. Vejamos, então, algumas das aplicações que associam a Linguística à Informática; como nosso interesse aqui é ressaltar a relevância dos conhecimentos desenvolvidos pela Linguística, damos mais ênfase ao domínio linguístico envolvido nos trabalhos, e menos aos formalismos computacionais ou modelos de engenharia da computação que estão por trás deles1PT.  Envolvendo as áreas da Fonética e Fonologia, por exemplo, encontramos muitos aplicativos de PLN. A Fonética e a Fonologia são as áreas da Linguística preocupadas em estudar os sons das línguas humanas. Grosso modo, podemos dizer que a Fonética se ocupa do estudo dos fones, dos sons concretizados na fala. Ela está interessada nos elementos acústicos, articulatórios e fisiológicos dos sons da fala. A Fonologia, por outro lado, se concentra em estudar os fonemas e o sistema fonológico subjacente de uma língua. Ela investiga o sistema abstrato que envolve o conhecimento fonológico dos falantes.  
TP1PT Não iremos abranger todas as áreas do conhecimento linguístico que contam com desenvolvimentos e aplicações da Linguística Computacional. Pretendemos apenas servir como uma boa introdução ao assunto. Após a leitura deste capítulo, o leitor pode procurar obras como Cole et al. (1997), Garside, Leech & McEnery (1997), Grisham (2002) e, em português, Vieira & Lima (2001). 

 21 De maneira geral, podemos dizer que os desenvolvimentos que envolvem essas duas áreas da Linguística enquadram-se nas áreas de (a) reconhecimento de fala; (b) síntese de fala; e (c) sistemas de diálogos em língua falada.  Entre as aplicações que já foram desenvolvidas ou que ainda estão em estágio de desenvolvimento a partir de estudos fonéticos e fonológicos, podemos destacar os aplicativos de reconhecimento de fala, que apresentam diversas finalidades: eles podem servir desde meros reconhecedores de comandos de voz em um aparelho celular (o que torna possível a discagem a partir do reconhecimento da voz do proprietário do aparelho, como já acontece, por exemplo, nos aparelhos de celular Motorola V60, Motorola V60i e Motorola C333 TP2PT, todos já comercializados no Brasil), até programas que reconheçam a fala a ponto de serem capazes de digitar um texto ditado por um usuário, como o software Via Voice, desenvolvido pela IBM TP3PT. Na área da síntese de fala, destacam-se os programas que são capazes de gerar fala a partir de dados. Ou seja, são programas que fazem com que o computador possa pronunciar em “voz” alta tudo aquilo que o usuário digitar. Há, por exemplo, o programa Talk it!4, que pode “ler em voz alta” palavras isoladas digitadas por um usuário. Esse programa pronuncia apenas vocábulos isolados, em inglês e em espanhol, e pode auxiliar, por exemplo, um estudante a descobrir a pronúncia correta de palavras na língua-alvo.  Outros aplicativos que merecem destaque são os programas capazes de ler em voz alta textos maiores e documentos escritos e armazenados no computador, como o programa Virtual Vision5PT, desenvolvido pela MicroPower, por exemplo, que “lê em voz alta” os textos de documentos do MS Office e de páginas na internet. Além de  
TP2PT www.motorola.com.br. 
TP3PT www-3.ibm.com/software/speech. 4 www.text2speech.com. 
TP5PT www.micropower.com.br/dv/vvision/index.asp. 

 22 esses programas facilitarem o uso do computador para usuários leigos, eles auxiliam principalmente os usuários que apresentam algum tipo de deficiência visual. Ainda nas áreas da Fonética e da Fonologia, podemos destacar alguns aplicativos muito mais sofisticados, que envolvem a interação entre ser humano e máquina através de diálogos orais em linguagem natural. Programas que sejam capazes de conversar com o ser humano ainda estão em seus desenvolvimentos iniciais e são muito mais comuns em obras de ficção científica (como a precursora máquina inteligente HAL, do filme 2001: uma odisseia no espaço, de Stanley Kubrick) do que em nossa realidade. Contudo já sabemos que eles podem ter um potencial enorme para o desenvolvimento de softwares de atendimento eletrônico e de agentes inteligentes em áreas como a do ensino a distância (EAD) e da educação através do computador (como programas de ensino de idiomas, ou CALL — Computer Assisted Language Learning). Esse tipo de aplicativo envolve um conjunto de conhecimentos complexos. Além de conhecimentos de Fonética e Fonologia, desenvolvimentos nessa área devem envolver também o estudo da Análise da Conversação, da Semântica, da Pragmática e da Linguística Textual, entre outros. Aplicações como as que acabamos de mencionar certamente facilitarão o acesso a computadores pessoais e a aparelhos eletrônicos não apenas de pessoas normais, mas também e especialmente de pessoas com vários tipos de deficiência — por exemplo, pessoas com deficiência visual ou com incapacidade de mover as mãos —, que poderão interagir com a máquina através da linguagem falada. O que é preciso enfatizar aqui é que o desenvolvimento de sistemas com a capacidade de interação verbal com seres humanos exige uma equipe mista, composta tanto por pesquisadores com formação em Linguística quanto por cientistas da área da Engenharia Computacional. Esperamos que já esteja ficando claro ao leitor a importância da Linguística Computacional para desenvolvimentos futuros na área de interação homem x máquina.  

 23 Além da Fonética e da Fonologia, outras áreas da Linguística são de grande importância para o desenvolvimento de programas de PLN, especialmente a Sintaxe e a Semântica. Por ora, podemos entender a Sintaxe como a disciplina “que estuda as regras, as condições e os princípios subjacentes à organização estrutural dos constituintes das frases, ou seja, o estudo da ordem dos constituintes das frases” (Mateus & Xavier, 1992: 1079). E a Semântica, também provisoriamente, pode ser definida como a área da Linguística que se ocupa em estudar o significado das palavras e das proposições. Estudos de sintaxe e semântica são fundamentais para sistemas que envolvem a compreensão ou a geração automática de frases de uma língua. Este é o caso, por exemplo, dos chatterbots. Os chatterbots são programas desenvolvidos para interagir com usuários humanos através de diálogos em linguagem natural, na modalidade escrita, como a Persephone, do diálogo fictício que apresentamos na Introdução deste livro. Esse nome (chatterbot) vem da junção de duas palavras inglesas: chat (conversar, bater papo) e bot (abreviação de robot, robô)6.  O primeiro chatterbot desenvolvido foi a ELIZA TP7PT, criado pelo pesquisador Joseph Weinzenbaum, no MIT, em 1966. O programa ELIZA foi desenvolvido para ser uma espécie de psicólogo, ou conselheiro sentimental. Na verdade, o objetivo principal de Weinzenbaum não era criar um “psicólogo virtual”, mas apenas um programa de conversação, utilizando um sistema que se baseava em “moldes” (templates, em inglês) para construir suas frases.  Após desenvolver o programa, Weinzenbaum o testou, pedindo a diversas pessoas para que “conversassem” com o programa (através do  6 Curiosidade: a palavra robot (robô) foi criada pelo escritor tcheco Karel Capek (1890-1938) para designar trabalho repetitivo e forçado. Ela foi utilizada pela primeira vez em sua peça teatral R.U.R – Rossum’s Universal Robots, que estreou no Teatro Nacional de Praga em 25 de janeiro de 1921. 
TP7PT Dê uma olhada em www-ai.ijs.si/eliza/eliza.html. 

 24 teclado, como em uma moderna sala de bate-papo). O curioso da história é que, quando Weizenbaum pedia para que os outros interagissem com seu programa, muitas pessoas acabavam ficando tão íntimas da ELIZA que chegavam a pedir para que o próprio Weizenbaum saísse da sala, para que a conversa pudesse ser mais particular. Como você vê, estas pessoas se esqueciam de que ELIZA era, na verdade, apenas um programa de computador, e acabavam “desabafando” com ela. Alguns psicólogos chegaram a ver nisso o futuro da psicanálise.  Para você ter uma ideia de como ELIZA “se comunicava”, veja, no quadro abaixo, um trecho de uma conversa entre ela e uma usuária humana, apresentado em Weizenbaum (1966)8: Quadro 2.1: Exemplo de conversação com ELIZA Usuário: Os homens são todos iguais. ELIZA: EM QUE SENTIDO Usuário: Eles estão sempre nos importunando por algum motivo ou outro. ELIZA: PODE PENSAR EM UM EXEMPLO ESPECÍFICO U: Bem, o meu namorado me fez vir até aqui. ELIZA: SEU NAMORADO FEZ VOCÊ VIR ATÉ AQUI U: Ele diz que eu fico muito tempo deprimida. ELIZA: FICO TRISTE EM SABER QUE VOCÊ FICA DEPRIMIDA U: É verdade. Eu sou infeliz. ELIZA: VOCÊ ACHA QUE VIR AQUI VAI AJUDAR VOCÊ A NÃO SER INFELIZ U: Eu preciso de uma ajuda, acho que isso é certo. ELIZA: O QUE SIGNIFICARIA PARA VOCÊ SE VOCÊ CONSEGUISSE AJUDA U: Talvez eu pudesse aprender a conviver com a minha mãe. ELIZA: FALE-ME MAIS SOBRE A SUA FAMÍLIA U: Minha mãe cuida de mim. ELIZA: QUEM MAIS EM SUA FAMÍLIA CUIDA DE VOCÊ U: Meu pai ELIZA: SEU PAI U: De certa forma, você é como meu pai. ELIZA: QUE SEMELHANÇA VOCÊ VÊ  8 WEIZENBAUM, J. ELIZA – a computer program for the study of natural language communication between man and machine. Communications of the ACM 9, 1966; apud Covington (1994: 15). 

 25 U: Você não é muito agressiva, mas eu acho que você não quer que eu perceba isso. ELIZA: O QUE FAZ VOCÊ PENSAR QUE EU NÃO SOU AGRESSIVA U: Você não discute comigo. ELIZA: POR QUE VOCÊ ACHA QUE EU NÃO DISCUTO COM VOCÊ U: Você tem medo de mim. ELIZA: AGRADA A VOCÊ SABER QUE EU TENHO MEDO DE VOCÊ U: Meu pai tem medo de todo mundo. ELIZA: O QUE MAIS VEM À SUA MENTE QUANDO VOCÊ PENSA NO SEU PAI U: Valentões. ELIZA: ISSO TEM ALGUMA RELAÇÃO COM O FATO DE O SEU NAMORADO TER FEITO VOCÊ VIR AQUI  Ultimamente, os chatterbots vêm sendo desenvolvidos especialmente para trabalhar com atendimento virtual e com tutoriais educativos. Um programa desse tipo deve ser capaz de poder manter uma conversa com um humano da forma mais natural possível.  Há inclusive uma competição anual entre chatterbots, conhecida como Prêmio Loebner9, criado em 1991 por Hugh Loebner, um filantropo norte-americano. Nesta competição, os chatterbots são testados com base no Teste de Turing10.  No teste, um juiz humano deve comunicar-se com dois interlocutores (uma máquina e um outro humano). Através de perguntas e respostas, o juiz terá de decidir quem é a máquina e quem é o humano (ou ainda, se os dois são máquinas, ou se os dois interlocutores são humanos). O objetivo principal deste teste é definir a própria Inteligência Artificial: “se uma máquina não pode ser distinta de um ser humano nestas condições, então devemos atribuir a ela uma inteligência humana” (Hodges, 2001: 45). O Teste de Turing é ainda hoje considerado como parâmetro para avaliação de certos programas de Inteligência Artificial e até mesmo  
TP9PT www.loebner.net. 10 O que conhecemos hoje como Teste de Turing foi proposto pelo filósofo e matemático inglês Alan Turing (1921-1954), em 1950, em seu artigo “Computing Machinery and Intelligence” (Mind, 51). Turing chamou-o de “jogo de imitação”. 

 26 como a própria definição do conceito de Inteligência Artificial, apesar das críticas feitas por vários filósofos, entre os quais o norte-americano John Searle, uma das maiores autoridades da chamada “Filosofia da Mente”11. As limitações dos chatterbots baseados em “moldes” é que eventualmente eles acabam repetindo suas próprias frases — e as do interlocutor — e se contradizendo em suas “opiniões”. Por isso, acreditamos que as próximas gerações de chatterbots devem exigir dos programadores um profundo conhecimento da sintaxe (que permitirá que desenvolvam no programa a capacidade de gerar infinitas sentenças da língua combinando um número finito de regras e elementos lexicais) e de semântica (que tornará possível fazer com que o programa seja capaz de interpretar o significado do input linguístico dado a ele pelo usuário humano). E, é claro, outras áreas da Linguística poderão tornar as capacidades dos chatterbots ainda mais sofisticadas. Para mencionar apenas algumas: a Linguística do Texto poderá auxiliá-los a estabelecer as relações anafóricas intra- e extraoracionais do discurso; a Dialetologia, a compreender diferentes dialetos, gírias, regionalismos e jargões; e a Análise da Conversação, a determinar os turnos conversacionais, além de auxiliar na compreensão e no uso de marcadores conversacionais. Isto é, tornar os chatterbots máquinas capazes de interação verbal certamente exigirá muito do que as várias áreas da linguística estudam12.  Há outro tipo de aplicativo bastante comum hoje em dia que também necessita de conhecimentos sintáticos e semânticos relativamente sofisticados: são os tradutores eletrônicos. Os tradutores são programas que se encarregam da tradução automática de textos e de  11 Para saber mais sobre o Teste de Turing, recomendamos o website http://cogsci.ucsd.edu/~asay gin/tt/ttest.html. 12 Na pausa da leitura, talvez o leitor já possa se aventurar pela grande rede e conversar com alguns chatterbots. Visite a página http://bots.internet.com/search/s-chat.htm, para um começo. 

 27 sentenças de uma língua para outra, ou para outras. Os programas de tradução automática estão entre os primeiros sistemas que foram objeto de estudo da Linguística Computacional. Podemos dividir esta classe de programas em (a) gerenciadores de terminologia; (b) ferramentas de tradução automática; e (c) tradutores automáticos auxiliares à tradução humana.  O primeiro tipo de programas é especificamente planejado para auxiliar na tradução de textos técnicos de determinada área, e seu vocabulário pode ficar restrito aos termos técnicos e jargões dessa área (como os programas MultiTerm e Termwatch TP13PT). Já as ferramentas de tradução automática são as mais conhecidas: elas são softwares destinados à tradução automática de quaisquer documentos, sem qualquer restrição na escolha do léxico, gênero ou assunto do texto. Seu objetivo é traduzir textos irrestritos sem qualquer interferência ou ajuda de um tradutor humano. O desejo de desenvolver tradutores abrangentes e robustos assim foi a principal causa do grande impulso dado às pesquisas envolvendo traduções automáticas durante a Guerra Fria. Mesmo que o objetivo até hoje não tenha sido alcançado, e os resultados estejam muito aquém daqueles imaginados no princípio, muito progresso já foi feito nesta área. Os programas Power Translator e Systran ProTP14PT são exemplos de ferramentas de tradução automática abrangente. Por último, encontramos programas que auxiliam o tradutor humano na tradução de um texto. Esses tradutores não primam pela perfeição ou acabamento do texto final traduzido, mas almejam auxiliar o tradutor profissional a traduzir grandes quantidades de texto. Acredita-se que o uso de tais programas pode ajudar um tradutor humano a reduzir em 50% o tempo total gasto no trabalho de tradução e  
TP13PT Cf. www.multiterm.com/multitermonline/ e www.atril.com. 
TP14PT Cf. http://users.chariot.net.au/~translators/software/62.html e www.systransoft. com. 

 28 cerca de 15-30% no custo total com a tradução15PT. Exemplos de programas assim são o Trados e o Déjà Vu TP16PT. Além dos chatterbots e dos tradutores automáticos, conhecimentos em sintaxe e semântica são também fundamentais para outros aplicativos, como parsers, geradores automáticos de resumos, corretores ortográficos e gramaticais, classificadores automáticos de documentos digitais etc. (Para o leitor saber mais sobre esses aplicativos, recomendamos a leitura de Cole et al, 1997.) Veremos em seguida com mais detalhe o que são os parsers. 2.2. Processamento sintático computacional ou parsing Depois de um breve passeio por alguns aplicativos que vem sendo desenvolvidos com base em resultados e técnicas da Linguística Computacional, começaremos a tratar do assunto mais específico que este livro pretende abordar. Vamos ver, a partir daqui, como desenvolver um parser automático utilizando a linguagem Prolog. Mas antes, um pouco de história. O estudo da estrutura sintática das línguas naturais tem origens muito distantes, que nos remetem a trabalhos de gramáticos gregos e latinos, como Apolônio Díscolo (gramático grego do século II d.C.), Donato e Prisciano (gramáticos romanos, dos séculos IV e VI d.C., respectivamente). O próprio termo sintaxe vem do grego sýntaxis, que é formado por sýn (junto) e taxis (ordenar, colocar). Por ora, entenderemos a sintaxe como o estudo da estruturação interna da frase, em relação à sua estrutura de constituintes (na seção 3.1.2, veremos o que vem a ser uma estrutura de constituintes). A breve explicação de Dubois et al. (1988: 559) também nos servirá: a sintaxe é “a parte da gramática que descreve as regras pelas quais se combinam as  
TP15PT Cf. www.languagepartners.com/reference-center/whitepapers/catinto.htm. 
TP16PT Cf. www.trados.com e www.atril.com. 

 29 unidades significativas em frases”. Veremos que o estudo das regras de formação de constituintes sintáticos das línguas naturais é vital para o funcionamento de diversos aplicativos desenvolvidos em PLN, especialmente a construção de parsers. A palavra parsing em si não remete ao processamento sintático mediado por computador (ou processamento sintático computacional). O termo vem da expressão latina pars orationes (partes do discurso) e tem suas raízes na tradição clássica. De acordo com Mateus & Xavier (1992: 886), parsing pode ser entendido como o “processo de atribuição de uma estrutura e de uma interpretação a uma sequência linguística”.  No contexto da Linguística Computacional, entretanto, parsing diz respeito à interpretação automática (ou semiautomática) de sentenças de linguagem natural por meio de programas de computador conhecidos como parsers. Esses programas são capazes de classificar morfossintaticamente as palavras e expressões de sentenças em uma dada língua e, principalmente, de atribuir às sentenças a sua estrutura de constituintes, baseando-se em um modelo formal de gramática. E a estrutura de constituintes de uma sentença é fundamental para que ela receba uma interpretação adequada17. De acordo com Covington (1994: 42), fazer o parsing de uma sentença é “determinar, por um processamento algorítmico, se a sentença é gerada por uma determinada gramática, e se ela for, qual estrutura que a gramática atribui a ela”. Para Bateman, Forrest & Willis, autores do capítulo The use of syntactic annotation tools: partial and full parsing (In: Garside, Leech & McEnery, 1997), um dos principais objetivos da área de PLN nos últimos dez anos tem sido produzir um “analisador gramatical”, ou parser, de abrangência ampla. Para muitos aplicativos de PLN, o desafio é produzir um parser que poderá ser capaz de analisar automática e estruturalmente de maneira correta, de acordo  17 Existem também parsers semânticos, preocupados em fornecer a estrutura semântica das sentenças em linguagem natural; mas estes parsers, em geral, se utilizam da análise fornecida por um parser sintático. Não falaremos, entretanto, dos parsers semânticos aqui. 

 30 com um esquema de parsing definido, qualquer sentença do inglês que possa ocorrer naturalmente, sem restrições, de uma gama de gêneros textuais tão vasta quanto possível T (grifos dos autores) (Garside, Leech & McEnery, 1997: 166).  Vários parsers já foram desenvolvidos ao longo dos anos, porém nenhum deles foi ainda capaz de alcançar o objetivo proposto por Bateman, Forrest & Willis. A pequena amostra de parser que desenvolveremos ao longo deste trabalho evidentemente também não dará conta dessa árdua tarefa. Mas servirá para dar uma ideia do tipo de trabalho que se faz em Linguística Computacional, bem como do tipo de conhecimento em Linguística que se faz necessário. Afinal, nossa proposta aqui é apenas introduzir o leitor no assunto, tornando-o capaz de dar seus primeiros passos em Linguística Computacional e de terminar a leitura tendo uma ideia de como desenvolver seu primeiro software linguístico: um pequeno parser da língua portuguesa. Se nosso leitor estiver curioso e ávido por mais aventuras no mundo cibernético, especialmente no que trata de parsers da língua portuguesa, sugerimos duas visitas virtuais: a primeira em www.geocities.com/gabriel_othero. Nessa página, o leitor poderá baixar gratuitamente o parser Grammar Play, desenvolvido por Gabriel de Ávila Othero e Maurício Piccini, em 200418. A segunda visita poderá ser ao site do Projeto VISL — Visual Interactive Syntax Learning, em http://visl.hum.sdu.dk/visl/pt/, que apresenta o parser de língua portuguesa PALAVRAS, desenvolvido por Eckhard Bick19. Na próxima subseção, faremos uma breve apresentação do Prolog, uma linguagem de programação desenvolvida especificamente para o trabalho em Inteligência Artificial e Linguística Computacional; o Prolog será a linguagem que utilizaremos para desenvolver aqui um parser para a língua portuguesa.  18 Cf. Othero (2004). 19 Cf. Bick (1996) e (2000). 

 31 2.3. O Prolog O Prolog é uma linguagem de programação baseada na lógica. O nome Prolog vem justamente de PROgramming in LOGic (ou “programando em lógica”). Essa linguagem foi desenvolvida por Alain Colmerauer, na França, em 1975, e tem se tornado bastante popular entre pesquisadores de Linguística Computacional e Inteligência Artificial. O Prolog foi desenvolvido desde o princípio visando ao trabalho de processamento de línguas naturais e desenvolvimento de parsers automáticos. Ao contrário da maioria das linguagens de programação, que são de natureza “procedural”, o Prolog é uma linguagem “declarativa”. Isso quer dizer que programar em Prolog não significa prover ao computador um algoritmo cujos passos são ações executadas pelo computador até que chegue a um determinado resultado. Para o Prolog, é importante que o programador dê ao programa dados para combinações — representados por proposições em um formato semelhante ao da lógica de primeira ordem —, e o Prolog resolverá, então, problemas pertinentes a esses dados, tentando demonstrar logicamente proposições derivadas a partir deles. Dougherty (1994) mostra de maneira bastante clara a diferença básica entre a programação em Prolog e a programação em outras linguagens computacionais, em sua maioria de natureza procedural. Para Dougherty (1994: 8-9), a maneira antiga (de um ponto de vista procedural) de se encarar a programação é a seguinte: Um computador é uma máquina que transforma informação procedendo através de uma sequência de passos. A menos que ele tenha sido programado, ele não faz nada. (…) A tarefa do programador é dizer ao computador como resolver o problema, mostrando a ele passos detalhados que devem ser seguidos para chegar à resposta correta. Um programa de computador é um conjunto detalhado de passos que o programa deve seguir para produzir qualquer resultado (grifos do autor). Programar em Prolog, ao contrário, não deixa a máquina assumir um papel tão “passivo” e dependente do programador. Por ser uma 

 32 linguagem declarativa, o Prolog deixa que o computador decida a resposta de um problema a partir dos dados que tem disponíveis. Ainda segundo Dougherty (1994: 15), a maneira de se encarar a programação em Prolog pode ser resumida no que segue: Um computador é uma máquina que tem disponíveis instantaneamente todas as propriedades de todos os objetos em seu banco de dados, além de todas as possíveis relações que existem entre esses objetos. A tarefa do programador é descrever ao computador em nossa terminologia que objetos e relações lógicas entre os objetos definem as possíveis respostas. Um programa de computador é um filtro para separar o joio do trigo (que são as combinações que estão de acordo com nossas condições lógicas) (grifos do autor). Por isso, a programação em Prolog modificou a maneira tradicional de se pensar em programação, especialmente no que diz respeito a trabalhos envolvendo Inteligência Artificial. De acordo com McDonald & Yazdani (1990: ix),  O Prolog é uma linguagem de programação nova e uma nova maneira de olhar para a programação. A maioria das outras linguagens de programação, como o BASIC e o Pascal, apresentam ao computador uma solução para um problema na forma de uma série de instruções para que a máquina as execute estritamente na ordem em que foram especificadas. Programar com o PROLOG (…) deve ser declarativo, um programa deve simplesmente ser o enunciado do problema. A maneira como o problema é solucionado e a sequência de instruções por que o computador deve passar para resolvê-lo são decididas pelo sistema.PT Além disso, a maioria das versões recentes do Prolog vem equipada com uma extensão nocional conhecida como DCG, ou Gramática de Cláusula Definida (do inglês Definite Clause Grammar), que facilita a implementação de regras formais de parsing. A DCG, como veremos mais detalhadamente na seção 3.2.2, é um formalismo de representação de gramáticas livres de contexto. Ela torna muito fácil implementar uma gramática e desenvolver um parser em Prolog, já que “uma gramática descrita em uma DCG é diretamente executada pelo Prolog como um analisador sintático” (Bratko, 1997: 431).  Por esses motivos, o Prolog é a linguagem utilizada em muitos dos trabalhos que desenvolvem parsers (ou amostras de parsers) sintáticos e 

 33 semânticos, para a língua portuguesa, como em Almeida et al. (2003), Othero (2004), Pagani (2004) e Vieira & Lima (2001). Para a língua inglesa, também encontramos vários exemplos de sistemas de parsing em Prolog; podemos destacar os trabalhos pioneiros de Pereira & Shieber (1987) e Pereira & Warren (1980). Além destes, também são bastante conhecidos os trabalhos de Clocksin & Mellish (1987), Gazdar & Mellish (1989), Covington (1994) e Dougherty (1994). Talvez ainda seja um pouco cedo para o leitor procurar essa bibliografia. Porém, ao terminarmos o livro, acreditamos que o leitor será capaz de compreender melhor e de maneira mais eficiente as obras que mencionamos nos dois parágrafos acima.  

