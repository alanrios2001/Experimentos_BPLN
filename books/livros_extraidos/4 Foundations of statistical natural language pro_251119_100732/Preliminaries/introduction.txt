p/CX /CX1 Introduction
The aim of a linguistic science is to be able to characterize and explain
the multitude of linguistic observations circling around us, in conversa-tions, writing, and other media. Part of that has to do with the cognitiveside of how humans acquire, produce, and understand language, partof it has to do with understanding the relationship between linguisticutterances and the world, and part of it has to do with understandingthe linguistic structures by which language communicates. In order to
approach the last problem, people have proposed that there are rules
rules
which are used to structure linguistic expressions. This basic approach
has a long history that extends back at least 2000 years, but in this cen-tury the approach became increasingly formal and rigorous as linguistsexplored detailed grammars that attempted to describe what were well-formed versus ill-formed utterances of a language.
However, it has become apparent that there is a problem with this con-
ception. Indeed it was noticed early on by Edward Sapir, who summed it
up in his famous quote “All grammars leak” (Sapir 1921: 38). It is justnot possible to provide an exact and complete characterization of well-formed utterances that cleanly divides them from all other sequencesof words, which are regarded as ill-formed utterances. This is becausepeople are always stretching and bending the ‘rules’ to meet their com-municative needs. Nevertheless, it is certainly not the case that the rules
are completely ill-founded. Syntactic rules for a language, such as that a
basic English noun phrase consists of an optional determiner, some num-ber of adjectives, and then a noun, do capture major patterns within thelanguage. But somehow we need to make things looser, in accounting forthe creativity of language use.

p/CX /CX4 1 Introduction
This book explores an approach that addresses this problem head on.
Rather than starting oﬀ by dividing sentences into grammatical and un-grammatical ones, we instead ask, “What are the common patterns thatoccur in language use?” The major tool which we use to identify thesepatterns is counting things, otherwise known as statistics, and so the sci-
entiﬁc foundation of the book is found in probability theory. Moreover,
we are not merely going to approach this issue as a scientiﬁc question,but rather we wish to show how statistical models of language are builtand successfully used for many natural language processing (
NLP)t a s k s .
While practical utility is something diﬀerent from the validity of a the-ory, the usefulness of statistical models of language tends to conﬁrmthat there is something right about the basic approach.
Adopting a Statistical
NLPapproach requires mastering a fair number
of theoretical tools, but before we delve into a lot of theory, this chapterspends a bit of time attempting to situate the approach to natural lan-guage processing that we pursue in this book within a broader context.O n es h o u l dﬁ r s th a v es o m ei d e aa b o u t why many people are adopting
a statistical approach to natural language processing and of how one
should go about this enterprise. So, in this ﬁrst chapter, we examine some
of the philosophical themes and leading ideas that motivate a statistical
approach to linguistics and
NLP, and then proceed to get our hands dirty
by beginning an exploration of what one can learn by looking at statisticsover texts.
1.1 Rationalist and Empiricist Approaches to Language
Some language researchers and many NLP practitioners are perfectly
happy to just work on text without thinking much about the relationshipbetween the mental representation of language and its manifestation inwritten form. Readers sympathetic with this approach may feel like skip-ping to the practical sections, but even practically-minded people haveto confront the issue of what prior knowledge to try to build into their
model, even if this prior knowledge might be clearly diﬀerent from what
might be plausibly hypothesized for the brain. This section brieﬂy dis-cusses the philosophical issues that underlie this question.
Between about 1960 and 1985, most of linguistics, psychology, artiﬁ-
cial intelligence, and natural language processing was completely domi-nated by a rationalist approach. A rationalist approach is characterized
rationalist

p/CX /CX1.1 Rationalist and Empiricist Approaches to Language 5
by the belief that a signiﬁcant part of the knowledge in the human mind is
not derived by the senses but is ﬁxed in advance, presumably by geneticinheritance. Within linguistics, this rationalist position has come to dom-inate the ﬁeld due to the widespread acceptance of arguments by NoamChomsky for an innate language faculty. Within artiﬁcial intelligence,
rationalist beliefs can be seen as supporting the attempt to create intel-
ligent systems by handcoding into them a lot of starting knowledge andreasoning mechanisms, so as to duplicate what the human brain beginswith.
Chomsky argues for this innate structure because of what he perceives
as a problem of the poverty of the stimulus (e.g., Chomsky 1986: 7). He
poverty of the
stimulus suggests that it is diﬃcult to see how children can learn something as
complex as a natural language from the limited input (of variable quality
and interpretability) that they hear during their early years. The rational-ist approach attempts to dodge this diﬃcult problem by postulating thatthe key parts of language are innate – hardwired in the brain at birth aspart of the human genetic inheritance.
Anempiricist approach also begins by postulating some cognitive abil-
empiricist
ities as present in the brain. The diﬀerence between the approaches is
therefore not absolute but one of degree. One has to assume some initial
structure in the brain which causes it to prefer certain ways of organiz-ing and generalizing from sensory inputs to others, as no learning ispossible from a completely blank slate, a tabula rasa . But the thrust of
empiricist approaches is to assume that the mind does not begin withdetailed sets of principles and procedures speciﬁc to the various com-ponents of language and other cognitive domains (for instance, theories
of morphological structure, case marking, and the like). Rather, it is as-
sumed that a baby’s brain begins with general operations for association,pattern recognition, and generalization, and that these can be applied tothe rich sensory input available to the child to learn the detailed structureof natural language. Empiricism was dominant in most of the ﬁelds men-tioned above (at least the ones then existing!) between 1920 and 1960,and is now seeing a resurgence. An empiricist approach to
NLPsuggests
that we can learn the complicated and extensive structure of language
by specifying an appropriate general language model, and then inducingthe values of parameters by applying statistical, pattern recognition, andmachine learning methods to a large amount of language use.
Generally in Statistical
NLP, people cannot actually work from observ-
ing a large amount of language use situated within its context in the

p/CX /CX6 1 Introduction
world. So, instead, people simply use texts, and regard the textual context
as a surrogate for situating language in a real world context. A body oftexts is called a corpus –corpus is simply Latin for ‘body,’ and when you
corpus
have several such collections of texts, you have corpora . Adopting such corpora
a corpus-based approach, people have pointed to the earlier advocacy of
empiricist ideas by the British linguist J. R. Firth, who coined the slogan
“You shall know a word by the company it keeps” (Firth 1957: 11). How-ever an empiricist corpus-based approach is perhaps even more clearlyseen in the work of American structuralists (the ‘post-Bloomﬁeldians’),
American
structuralists particularly Zellig Harris. For example, (Harris 1951) is an attempt to ﬁnd
discovery procedures by which a language’s structure can be discoveredautomatically. While this work had no thoughts to computer implemen-
tation, and is perhaps somewhat computationally naive, we ﬁnd here also
the idea that a good grammatical description is one that provides a com-pact representation of a corpus of texts.
It is not appropriate to provide a detailed philosophical treatment of
scientiﬁc approaches to language here, but let us note a few more dif-ferences between rationalist and empiricist approaches. Rationalists andempiricists are attempting to describe diﬀerent things. Chomskyan (or
generative ) linguistics seeks to describe the language module of the hu-
generative
linguistics man mind (the I-language) for which data such as texts (the E-language)
provide only indirect evidence, which can be supplemented by nativespeaker intuitions. Empiricist approaches are interested in describingthe E-language as it actually occurs. Chomsky (1965: 3–4) thus makesa crucial distinction between linguistic competence , which reﬂects the
linguistic
competence knowledge of language structure that is assumed to be in the mind of
an a t i v es p e a k e r ,a n d linguistic performance in the world, which is af- linguistic
performance fected by all sorts of things such as memory limitations and distracting
noises in the environment. Generative linguistics has argued that one canisolate linguistic competence and describe it in isolation, while empiricistapproaches generally reject this notion and want to describe actual useof language.
This diﬀerence underlies much of the recent revival of interest in em-
piricist techniques for computational work. During the second phase of
work in artiﬁcial intelligence (roughly 1970–1989, say) people were con-cerned with the science of the mind, and the best way to address that wasseen as building small systems that attempted to behave intelligently.This approach identiﬁed many key problems and approaches that are

p/CX /CX1.2 Scientiﬁc Content 7
still with us today, but the work can be criticized on the grounds that it
dealt only with very small (often pejoratively called ‘toy’) problems, andoften did not provide any sort of objective evaluation of the general ef-ﬁcacy of the methods employed. Recently, people have placed greateremphasis on engineering practical solutions. Principally, they seek meth-
ods that can work on raw text as it exists in the real world, and objective
comparative evaluations of how well diﬀerent methods work. This newemphasis is sometimes reﬂected in naming the ﬁeld ‘Language Technol-ogy’ or ‘Language Engineering’ instead of
NLP. As we will discuss below,
such goals have tended to favor Statistical NLPapproaches, because they
are better at automatic learning ( knowledge induction ), better at disam- induction
biguation, and also have a role in the science of linguistics.
Finally, Chomskyan linguistics, while recognizing certain notions of
competition between principles, depends on categorical principles, which categorical
sentences either do or do not satisfy. In general, the same was true of
American structuralism. But the approach we will pursue in Statistical
NLPdraws from the work of Shannon, where the aim is to assign proba-
bilities to linguistic events, so that we can say which sentences are ‘usual’and ‘unusual’. An upshot of this is that while Chomskyan linguists tend
to concentrate on categorical judgements about very rare types of sen-
tences, Statistical
NLPpractitioners are interested in good descriptions
of the associations and preferences that occur in the totality of languageuse. Indeed, they often ﬁnd that one can get good real world performanceby concentrating on common types of sentences.
1.2 Scientiﬁc Content
Many of the applications of the methods that we present in this book havea quite applied character. Indeed, much of the recent enthusiasm for
statistical methods in natural language processing derives from peopleseeing the prospect of statistical methods providing practical solutionsto real problems that have eluded solution using traditional
NLPmethods.
But if statistical methods were just a practical engineering approach, an
approximation to diﬃcult problems of language that science has not yetbeen able to ﬁgure out, then their interest to us would be rather limited.Rather, we would like to emphasize right at the beginning that there areclear and compelling scientiﬁc reasons to be interested in the frequency

p/CX /CX8 1 Introduction
with which linguistic forms are used, in other words, statistics, as one
approaches the study of language.
1.2.1 Questions that linguistics should answer
What questions does the study of language concern itself with? As a startwe would like to answer two basic questions:
What kinds of things do people say?
What do these things say/ask/request about the world?
From these two basic questions, attention quickly spreads to issues about
how knowledge of language is acquired by humans, and how they actu-ally go about generating and understanding sentences in real time. Butlet us just concentrate on these two basic questions for now. The ﬁrstcovers all aspects of the structure of language, while the second dealswith semantics, pragmatics, and discourse – how to connect utterances
with the world. The ﬁrst question is the bread and butter of corpus lin-
guistics, but the patterns of use of a word can act as a surrogate for deepunderstanding, and hence can let us also address the second questionusing corpus-based techniques. Nevertheless patterns in corpora moreeasily reveal the syntactic structure of a language, and so the majority ofwork in Statistical
NLPhas dealt with the ﬁrst question of what kinds of
things people say, and so let us begin with it here.
How does traditional (structuralist/generative) linguistics seek to an-
swer this question? It abstracts away from any attempt to describe thekinds of things that people usually say, and instead seeks to describeacompetence grammar that is said to underlie the language (and which
competence
grammar generative approaches assume to be in the speaker’s head). The extent to
which such theories approach the question of what people say is merelyto suggest that there is a set of sentences – grammatical sentences –
which are licensed by the competence grammar, and then other strings
of words are ungrammatical. This concept of grammaticality is meant to
grammaticality
be judged purely on whether a sentence is structurally well-formed, and
not according to whether it is the kind of thing that people would sayor whether it is semantically anomalous. Chomsky gave Colorless green
ideas sleep furiously as an example of a sentence that is grammatical, al-

p/CX /CX1.2 Scientiﬁc Content 9
though semantically strange and not the kind of thing you would expect
people to say. Syntactic grammaticality is a categorical binary choice.1
Now, initially, a distinction between grammatical and ungrammatical
sentences does not seem so bad. We immediately notice when a non-native speaker says something really wrong – something ungrammatical
– and we are able to correct such sentences to grammatical ones. In con-
trast, except when there are bad speech errors, a native speaker normallyproduces grammatical sentences. But there are at least two reasons whywe should seek more. Firstly, while maintaining a binary split betweengrammatical and ungrammatical sentences may seem plausible in simplecases, it becomes increasingly far-fetched as we extend our investiga-tion. Secondly, regardless of this, there are many reasons to be interested
in the frequency with which diﬀerent sentences and sentence types are
used, and simply dividing sentences into grammatical and ungrammati-cal sentences gives no information about this. For instance, very oftennon-native speakers say or write things that are not in any way syntac-tically ungrammatical, but just somehow subtly odd. Here’s an examplefrom a student essay:
(1.1) In addition to this, she insisted that women were regarded as a diﬀerent
existence from men unfairly.
We might respond to this passage by saying that we can understand the
message, but it would sound better expressed slightly diﬀerently. Thisis a statement about the conventionality of certain modes of expression.
conventionality
But a convention is simply a way in which people frequently express or
do something, even though other ways are in principle possible.
The fact that sentences do not divide neatly into two sets – grammat-
ical and ungrammatical ones – is well known to anyone who has beenin linguistics for a while. For many of the complicated sentences of in-terest to theoretical linguistics, it is diﬃcult for human beings to decidewhether they are grammatical or not. For example, try your hand at judg-
ing the grammaticality of the following sentences drawn (not at random)
1. Some versions of Chomsky’s 1980s theory, Government-Binding theory (GB), provide a
minor degree of gradedness by suggesting that sentences that disobey some constraintsare only sort of weird while ones that disobey other constraints are truly horrible, but theformal theory, in GB and elsewhere, provides little support for these notions. Linguistsgenerally rely on an informal system of stars and question marks for initially gradingsentences (where * (ungrammatical) >?*>??>? (questionable)), but these gradations
are converted into a binary grammatical/ungrammatical distinction when people try todevelop the principles of grammar.

p/CX /CX10 1 Introduction
from (van Riemsdijk and Williams 1986) – a textbook, not even a research
paper – before peeking at the answers in the footnote.2
(1.2) a. John I believe Sally said Bill believed Sue saw.
b. What did Sally whisper that she had secretly read?
c. John wants very much for himself to win.d. (Those are) the books you should read before it becomes diﬃcult to
talk about.
e. (Those are) the books you should read before talking about becomes
diﬃcult.
f. Who did Jo think said John saw him?g. That a serious discussion could arise here of this topic was quite un-
expected.
h. The boys read Mary’s stories about each other.
We ﬁnd that most people disagree with more than one of van Riemsdijk
and Williams’s claims about which sentences are grammatical. This re-sult raises real questions about what, if anything, generative linguisticsis describing.
This diﬃculty has led to many statements in the linguistics literature
about judgements being diﬃcult, or the facts quite obscure, as if some-
how there is a categorical answer to whether each sentence is grammati-
cal, but it is hard for human beings to work out what that answer is. Yet,despite these manifest diﬃculties, most of theoretical linguistics contin-ues to work in a framework that deﬁnes such observations to be out ofthe realm of interest (relegating them to performance eﬀects). We be-lieve that this is unsustainable. On the other hand, it must be noticedthat most simple sentences are either clearly acceptable or unacceptable
and we would want our theory to be able to account for this observation.
Perhaps the right approach is to notice the parallel with other cases ofcategorical perception that have been described in the psychological liter-
categorical
perception ature. For instance, although the timing of voicing onset which diﬀerenti-
ates a /p/ sound from a /b/ sound is a continuous variable (and its typical
2. Answers: a. ok, b. bad, c. ok,d .ok,e .b a d ,f . ok,g .ok,h .b a d .

p/CX /CX1.2 Scientiﬁc Content 11
value varies between languages), human beings perceive the results cat-
egorically, and this is why a theory of phonology based on categoricalphonemes is largely viable, despite all the movements and variations inphonological production occurring in a continuous space. Similarly forsyntax, a categorical theory may suﬃce for certain purposes. Neverthe-
less, we would argue that the diﬃculties in giving grammaticality judge-
ments to complex and convoluted sentences show the implausibility ofextending a binary distinction between grammatical and ungrammaticalstrings to all areas of language use.
1.2.2 Non-categorical phenomena in language
But beyond the above diﬃculties in giving grammaticality judgements, ifwe peek into the corners of language, we see clear evidence of failures ofcategorical assumptions, and circumstances where considerations of fre-quency of use are essential to understanding language. This suggests thatwhile a categorical view of language may be suﬃcient for many purposes,
categorical view of
language we must see it as an approximation that also has its limitations (just as
Newtonian physics is good for many purposes but has its limits).3
One source of data on non-categorical phenomena in language is to
look at the history of language change (others are looking at sociolin-guistic variation and competing hypotheses during language acquisition).Over time, the words and syntax of a language changes. Words willchange their meaning and their part of speech. For instance, English
while used to be exclusively a noun meaning ‘time,’ a usage that survives
mainly in a few ﬁxed phrases such as to take a while , but changed to be
mainly used as a complementizer introducing subordinate clauses ( While
you were out, . . . ). It doesn’t make sense to say that categorically until
some day in 1742 while was only a noun and then it became a comple-
mentizer – even if this claim is only being made for certain speakersrather than the speech community as a whole. Rather, one would expect
a gradual change. One hypothesis is that if the frequency of use of a word
in various contexts gradually changes so that it departs from the typicalproﬁle of use of words in the category to which it formerly belonged,and rather its proﬁle of use comes to more resemble words of another
3. Readers not familiar with linguistics and NLPmay have trouble understanding this
section and may wish to skip it, but to return to it after reading chapter 3. The historicalexamples include various archaic spellings – the standardization of English spelling is arelatively modern phenomenon. Reading them aloud is often helpful for decoding them.

p/CX /CX12 1 Introduction
category, then it will come to be reanalyzed as a word of that diﬀerent
category. During the period of change, one would expect to see evidenceof noncategorical behavior.
Blending of parts of speech: near
At ﬁrst blush it appears that the word near can be used either as an
adjective as in (1.3a) or as a preposition (1.3b):
(1.3) a. We will review that decision in the near future.
b. He lives near the station.
Evidence for near as an adjective includes its position between a deter-
miner and noun as in (1.3a) – a classic adjective position – and the fact
that it can form an adverb by adding -ly:We nearly lost . Evidence for
near as a preposition includes that it can head the locative phrase com-
plements of verbs like liveas in (1.3b) – a classic role for prepositions, and
that such a phrase can be modiﬁed by right , which is normally restricted
to modifying prepositional phrases: He lives right near the station (cf.He
swam right across the lake vs.??That’s a right red car ). So far, though,
this data is not that surprising: many words in English seem to have
multiple parts of speech. For example, many words are both nouns andverbs, such as play:They saw a play vs.They play lacrosse on Thursdays .
But the interesting thing is that near can simultaneously show adjective
properties and preposition properties, and thus appears to behave as acategory blend. This happens in sentences like:
(1.4) a. He has never been nearer the center of the ﬁnancial establishment.
b. We live nearer the water than you thought.
Realization in the comparative form ( nearer )i sah a l l m a r ko fa d j e c t i v e s
(and adverbs). Other categories do not form comparatives and superla-
tives.
4On the other hand, grammatical theory tells us that adjectives and
nouns do not take direct objects, hence we have to insert prepositions
4. The thoughtful reader might note that some prepositions do have related forms ending
in-erwhich are perhaps related to comparatives ( upper, downer, inner, outer ), but we note
that none of these prepositions have a superlative that is formed in analogy to regularadjectival superlatives, as near does (that is, nearest ), and that none of these other forms
in-ercan be used in preposition-like uses. We cannot say: *John lives inner Sydney than
Fred.

p/CX /CX1.2 Scientiﬁc Content 13
after adjectives and say unsure ofhis beliefs orconvenient forpeople
who work long hours . In this sense nearer is behaving like a preposition
by heading a locative phrase and taking a direct object. Thus in thesesentences nearer is simultaneously showing properties of adjectives and
prepositions that are not available to the other category. Hence it is ex-
hibiting a blended status somewhere between these two parts of speech,
which are normally taken as categorically distinct.
Language change: kind of andsort of
New uses for the word sequences kind of andsort of present a convincing
example of how diﬀerent frequencies of use in certain constructions can
lead to what is apparently categorical change. In modern English, theexpressions sort of andkind of have at least two distinct uses. In one, sort
orkind functions as a noun with ofas a following preposition introducing
a prepositional phrase, as in sentences such as What sort of animal made
these tracks? But there is another usage in which these expressions can
best be thought of as degree modiﬁers, akin to somewhat orslightly :
(1.5) a. We are kind of hungry.
b. He sort of understood what was going on.
We can tell that kind/sort of is not behaving as a normal noun preposition
sequence here because it is appearing in contexts – such as between thesubject noun phrase and the verb – where normally one cannot insert a
noun-preposition sequence (for example, one cannot say *He variety of
understood what was going on ).
Historically, kind andsort were clearly nouns. Among other things,
they could be preceded by a determiner and followed by a PP:
(1.6) a. A nette sent in to the see, and of alle kind of ﬁshis gedrynge. [1382]
b. I knowe that sorte of men ryght well. [1560]
Unambiguous degree modiﬁer uses did not appear until the nineteenth
century:
(1.7) a. I kind of love you, Sal—I vow. [1804]
b. It sort o’ stirs one up to hear about old times. [1833]

p/CX /CX14 1 Introduction
It does not appear that this new construction was borrowed from another
language. Rather it appears to be a language internal development. Howcould this innovation have come about?
A plausible hypothesis is to notice that when we have kind/sort of pre-
ceding an adjective, then it is actually ambiguous between these two read-
ings:
(1.8) a. [ npa [kind] [ ppof [npdense rock]]]
b. [npa[ap[mod kind of] dense] rock]
And what one ﬁnds is that between the sixteenth and the nineteenth
century, there was a signiﬁcant rise in the use of kind/sort of in this
[Det { sort/kind } of AdjP N] frame:
(1.9) a. Their ﬁnest and best, is a kind of course red cloth. [c. 1600]
b. But in such questions as the present, a hundred contradictory views
may preserve a kind of imperfect analogy. [1743]
(Note that course is here a variant spelling of coarse .) In this environment,
sort/kind of ﬁlls a slot that could be occupied by a noun head followed
by a preposition, but it also ﬁlls a slot that could be occupied by a de-gree modiﬁer (with a diﬀerent syntactic structure). As this usage becamemore common, kind/sort of was more commonly being used in a typical
degree modiﬁer slot; in other words, it grew to look syntactically morelike a degree modiﬁer. Moreover, the semantics of these particular nounswas such that they could easily be thought of as degree modiﬁers. This
frequency change seems to have driven a change in syntactic category,
and in time the use of kind/sort of was extended to other contexts such
as modifying verb phrases.
The general point here is that while language change can be sudden
(due to either external or internal factors), it is generally gradual. Thedetails of gradual change can only be made sense of by examining fre-quencies of use and being sensitive to varying strengths of relationships,
and this type of modeling requires statistical, as opposed to categorical,
observations.
Although there have only been a few attempts to use Statistical
NLPfor
explaining complex linguistic phenomena, what is exciting about the sub-ject matter of this book from the point of view of theoretical linguisticsis that this new way of looking at language may be able to account for

p/CX /CX1.2 Scientiﬁc Content 15
things such as non-categorical phenomena and language change much
better than anything existing today.
1.2.3 Language and cognition as probabilistic phenomena
A more radical argument for probability as part of a scientiﬁc under-standing of language is that human cognition is probabilistic and thatlanguage must therefore be probabilistic too since it is an integral partof cognition. A frequent response to our previous examples of non-categorical phenomena in language is that they are marginal and rare.Most sentences are either clearly grammatical or clearly ungrammatical.And most of the time, words are used in only one part of speech, without
blending. But if language and cognition as a whole are best explained
probabilistically, then probability theory must be a central part of an ex-planatory theory of language.
The argument for a probabilistic approach to cognition is that we live
in a world ﬁlled with uncertainty and incomplete information. To be ableto interact successfully with the world, we need to be able to deal withthis type of information. Suppose you want to determine whether it is
safe to wade through a river. You see that the water is ﬂowing slowly, so
probably it won’t drag you away. You are pretty certain that no piranhasor alligators live in this area. You integrate all this information in eval-uating how safe it is to cross the river. Now, if someone tells you, “thewater is only knee-deep if you walk towards that tall tree over there”, thenthis linguistic information will be just one more source of information toincorporate. Processing the words, forming an idea of the overall mean-
ing of the sentence, and weighing it in making a decision is no diﬀerent
in principle from looking at the current, forming an idea of the speedof the water, and taking this sensory information into account. So thegist of this argument is that the cognitive processes used for languageare identical or at least very similar to those used for processing otherforms of sensory input and other forms of knowledge. These cognitiveprocesses are best formalized as probabilistic processes or at least by
means of some quantitative framework that can handle uncertainty and
incomplete information.
The facts of language often look quite diﬀerent depending on whether
or not one is sympathetic to an important role for quantitative meth-ods in linguistics. A famous example is Chomsky’s dictum that probabil-ity theory is inappropriate for formalizing the notion of grammaticality .
grammaticality

p/CX /CX16 1 Introduction
He argued that computing the probability of sentences from a corpus
of utterances would assign the same low probability to all unattestedsentences, grammatical and ungrammatical ones alike, and hence not ac-count for linguistic productivity (Chomsky 1957: 16). This argument onlymakes sense if one has a bias against probabilistic representation of con-
cepts in general. Consider the cognitive representation of the concept
tall. Suppose you see a man who is seven feet tall and it is the ﬁrst per-
son you’ve ever seen of that height. You will easily recognize this personas a tallman, not as an uncategorizable man. Similarly, it will be easy
for you to recognize a person of another unattested height, say four feet,as deﬁnitely not tall. In this book, we will look at probabilistic models
that can easily learn and represent this type of regularity and make the
right judgement for unattested examples. Indeed, a major part of Statis-
tical
NLPis deriving good probability estimates for unseen events. The
premise that all unattested instances will be treated alike in a probabilis-tic framework does not hold.
We believe that much of the skepticism towards probabilistic mod-
els for language (and for cognition in general) stems from the fact thatthe well-known early probabilistic models (developed in the 1940s and
1950s) are extremely simplistic. Because these simplistic models clearly
do not do justice to the complexity of human language, it is easy to viewprobabilistic models in general as inadequate. One of the insights wehope to promote in this book is that complex probabilistic models can beas explanatory as complex non-probabilistic models – but with the addedadvantage that they can explain phenomena that involve the type of un-certainty and incompleteness that is so pervasive in cognition in general
and in language in particular.
These issues relate to the treatment of semantics in Statistical
NLP.
We mentioned earlier that most existing work in Statistical NLPhas con-
centrated on the lower levels of grammatical processing, and people havesometimes expressed skepticism as to whether statistical approaches canever deal with meaning. But the diﬃculty in answering this question ismainly in deﬁning what ‘meaning’ is! It is often useful in practice if ‘mean-
ing’ is viewed as symbolic expressions in some language, such as when
translating English into a database query language like
SQL. This sort
of translation can certainly be done using a Statistical NLPsystem (we
discuss the process of translation in chapter 13). But from a Statistical
NLPperspective, it is more natural to think of meaning as residing in
the distribution of contexts over which words and utterances are used.

pa/CX /CX1.3 The Ambiguity of Language: Why NLPIs Diﬃcult 17
Philosophically, this brings us close to the position adopted in the later
writings of Wittgenstein (that is, Wittgenstein 1968), where the mean-ing of a word is deﬁned by the circumstances of its use (a use theory of
use theory of
meaning meaning ) – see the quotations at the beginning of the chapter. Under this
conception, much of Statistical NLPresearch directly tackles questions of
meaning.
1.3 The Ambiguity of Language: Why NLPIs Diﬃcult
AnNLPsystem needs to determine something of the structure of text –
normally at least enough that it can answer “Who did what to whom?”Conventional parsing systems try to answer this question only in termsof possible structures that could be deemed grammatical for some choiceof words of a certain category. For example, given a reasonable grammar,a standard
NLPsystem will say that sentence (1.10) has 3 syntactic anal-
yses, often called parses :
(1.10) Our company is training workers.
The three diﬀering parses might be represented as in (1.11):
(1.11) a. S
NP
Our companyVP
Aux
isVP
V
trainingNP
workers
b. S
NP
Our companyVP
V
isNP
VP
V
trainingNP
workers

p/CX /CX18 1 Introduction
c. S
NP
Our companyVP
V
isNP
AdjP
trainingN
workers
There is (a), the one humans perceive, where is training is the verb group,
and two others with isas the main verb: in (b) the rest is a gerund (cf. Our
problem is training workers ), while in (c) training modiﬁes workers (cf.
Those are training wheels ). The last two parses are semantically anoma-
lous, but in most current systems semantic analysis is done only aftersyntactic analysis (if at all). This means that, as sentences get longer andgrammars get more comprehensive, such ambiguities lead to a terriblemultiplication of parses. For instance, Martin et al. (1987) report theirsystem giving 455 parses for the sentence in (1.12):
5
(1.12) List the sales of the products produced in 1973 with the products pro-
duced in 1972.
Therefore, a practical NLPsystem must be good at making disambigua-
tion decisions of word sense, word category, syntactic structure, and
semantic scope. But the goal of maximizing coverage while minimiz-ing resultant ambiguity is fundamentally inconsistent with symbolic
NLP
systems, where extending the coverage of the grammar to obscure con-structions simply increases the number of undesired parses for commonsentences and vice versa. Furthermore, experience with AI approaches toparsing and disambiguation, which seek models with deep understand-
ing, has shown that hand-coded syntactic constraints and preference
rules are time consuming to build, do not scale up well, and are brit-tle in the face of the extensive use of metaphor in language (Lakoﬀ 1987).For instance a traditional approach is to use selectional restrictions ,a n d
selectional
restrictions say, for example, that a verb like swallow requires an animate being as its
subject and a physical object as its object. But such a restriction woulddisallow common and straightforward metaphorical extensions of the us-
age of swallow such as these:
5. See also Church and Patil (1982) for similar examples.

p/CX /CX1.4 Dirty Hands 19
(1.13) a. I swallowed his story, hook, line, and sinker.
b. The supernova swallowed the planet.
Disambiguation strategies that rely on manual rule creation and hand-
tuning produce a knowledge acquisition bottleneck, and still perform
poorly when evaluated on naturally occurring text.
A Statistical NLPapproach seeks to solve these problems by automat-
ically learning lexical and structural preferences from corpora. Ratherthan parsing solely using syntactic categories, such as part of speech la-bels, we recognize that there is a lot of information in the relationshipsbetween words, that is, which words tend to group with each other. This
collocational knowledge can be exploited as a window onto deeper se-
mantic relationships. In particular, the use of statistical models oﬀersa good solution to the ambiguity problem: statistical models are robust,generalize well, and behave gracefully in the presence of errors and newdata. Thus Statistical
NLPmethods have led the way in providing suc-
cessful disambiguation in large scale systems using naturally occurringtext. Moreover, the parameters of Statistical
NLPmodels can often be esti-
mated automatically from text corpora, and this possibility of automatic
learning not only reduces the human eﬀort in producing NLPsystems, but
raises interesting scientiﬁc issues regarding human language acquisition.
1.4 Dirty Hands
1.4.1 Lexical resources
So much for motivation. How does one actually proceed? Well, ﬁrst of all,one needs to get one’s hands on some lexical resources : machine-readable
lexical resources
text, dictionaries, thesauri, and also tools for processing them. We will
brieﬂy introduce a few important ones here since we will be referringto them throughout the book. You can consult the website for moreinformation on how to actually get your hands on them.
The Brown corpus is probably the most widely known corpus. It is
Brown corpus
a tagged corpus of about a million words that was put together at Brown
university in the 1960s and 1970s. It is a balanced corpus .T h a t i s , a n balanced corpus
attempt was made to make the corpus a representative sample of Amer-
ican English at the time. Genres covered are press reportage, ﬁction,scientiﬁc text, legal text, and many others. Unfortunately, one has to payto obtain the Brown corpus, but it is relatively inexpensive for research

p/CX /CX20 1 Introduction
purposes. Many institutions with NLPresearch have a copy available, so
ask around. The Lancaster-Oslo-Bergen (LOB)corpus was built as a British Lancaster-Oslo-
Bergen corpus English replication of the Brown corpus.
The Susanne corpus is a 130,000 word subset of the Brown corpus, Susanne corpus
which has the advantage of being freely available. It is also annotated
with information on the syntactic structure of sentences – the Brown cor-
pus only disambiguates on a word-for-word basis. A larger corpus ofsyntactically annotated (or parsed) sentences is the Penn Treebank .T h e
Penn Treebank
text is from the Wall Street Journal . It is more widely used, but not avail-
able for free.
TheCanadian Hansards , the proceedings of the Canadian parliament, Canadian Hansards
are the best known example of a bilingual corpus , a corpus that contains bilingual corpus
parallel texts in two or more languages that are translations of each other. parallel texts
Such parallel texts are important for statistical machine translation and
other cross-lingual NLPwork. The Hansards are another resource that
one has to pay for.
In addition to texts, we also need dictionaries. WordNet is an electronic WordNet
dictionary of English. Words are organized into a hierarchy. Each node
consists of a synset of words with identical (or close to identical) mean- synset
ings. There are also some other relations between words that are deﬁned,
such as meronymy or part-whole relations. WordNet is free and can bedownloaded from the internet.
More details on corpora can be found in chapter 4.
1.4.2 Word counts
Once we have downloaded some text, there are a number of quite inter-
esting issues in its low-level representation, classiﬁcation, and process-ing. Indeed, so many that chapter 4 is devoted to these questions. Butfor the moment, let us suppose that our text is being represented as alist of words. For the investigation in this section, we will be using MarkTwain’s Tom Sawyer .
There are some obvious ﬁrst questions to ask. What are the most com-
mon words in the text? The answer is shown in table 1.1. Notice how
this list is dominated by the little words of English which have importantgrammatical roles, and which are usually referred to as function words ,
function words
such as determiners, prepositions, and complementizers. The one really
exceptional word in the list is Tom whose frequency clearly reﬂects the
text that we chose. This is an important point. In general the results one

p/CX /CX1.4 Dirty Hands 21
Word Freq. Use
the 3332 determiner (article)
and 2972 conjunction
a 1775 determinerto 1725 preposition, verbal inﬁnitive markerof 1440 prepositionwas 1161 auxiliary verbit 1027 (personal/expletive) pronounin 906 preposition
that 877 complementizer, demonstrative
he 877 (personal) pronounI 783 (personal) pronounhis 772 (possessive) pronounyou 686 (personal) pronounTom 679 proper nounwith 642 preposition
Table 1.1 Common words in Tom Sawyer .
gets depends on the corpus or sample used. People use large and var-
ied samples to try to avoid anomalies like this, but in general the goal ofusing a truly ‘representative’ sample of all of English usage is somethingof a chimera, and the corpus will reﬂect the materials from which it wasconstructed. For example, if it includes material from linguistics researchpapers, then words like ergativity, causativize ,a n d lexicalist may well oc-
cur, but otherwise they are unlikely to be in the corpus at all, no matter
how large it is.
How many words are there in the text? This question can be interpreted
in two ways. The question about the sheer length of the text is distin-guished by asking how many word tokens there are. There are 71,370.
word tokens
So this is a very small corpus by any standards, just big enough to illus-
trate a few basic points. Although Tom Sawyer is a reasonable length
novel, it is somewhat less than half a megabyte of online text, and for
broad coverage statistical grammars we will often seek collections of textthat are orders of magnitude larger. How many diﬀerent words, or inother words, how many word types appear in the text? There are 8,018.
word types
This is actually quite a small number for a text its size, and presumably
reﬂects the fact that Tom Sawyer is written in a colloquial style for chil-

p/CX /CX22 1 Introduction
Word Frequency of
Frequency Frequency
1 3993
2 12923 6644 4105 2436 1997 172
8 131
98 2
10 91
11–50 540
51–100 99
>100 102
Table 1.2 Frequency of frequencies of word types in Tom Sawyer .
dren (for instance, a sample of newswire the same size contained slightly
over 11,000 word types). In general in this way one can talk about to- tokens
kens, individual occurrences of something, and types , the diﬀerent things types
present. One can also calculate the ratio of tokens to types, which is sim-
ply the average frequency with which each type is used. For Tom Sawyer ,
it is 8.9.6
The above statistics tell us that words in the corpus occur ‘on average’
about 9 times each. But one of the greatest problems in Statistical NLP
is that word types have a very uneven distribution. Table 1.2 shows how
many word types occur with a certain frequency. Some words are verycommon, occurring over 700 times and therefore individually account-ing for over 1% of the words in the novel (there are 12 such words intable 1.1). Overall, the most common 100 words account for slightly overhalf (50.9%) of the word tokens in the text. On the other extreme, note
that almost half (49.8%) of the word types occur only once in the corpus.
Such words are referred to as hapax legomena , Greek for ‘read only once.’
hapax legomena
Even beyond these words, note that the vast majority of word types oc-
6. This ratio is not a valid measure of something like ‘text complexity’ just by itself, since
the value varies with the size of the text. For a valid comparison, one needs to normalizethe lengths of the texts, such as by calculating the measure over windows of 1,000 words.

p/CX /CX1.4 Dirty Hands 23
cur extremely infrequently: over 90% of the word types occur 10 times or
less. Nevertheless, very rare words make up a considerable proportion ofthe text: 12% of the text is words that occur 3 times or less.
Such simple text counts as these can have a use in applications such
as cryptography, or to give some sort of indication of style or author-
ship. But such primitive statistics on the distribution of words in a text
are hardly terribly linguistically signiﬁcant. So towards the end of thechapter we will begin to explore a research avenue that has slightly morelinguistic interest. But these primitive text statistics already tell us thereason that Statistical
NLPis diﬃcult: it is hard to predict much about
the behavior of words that you never or barely ever observed in your cor-pus. One might initially think that these problems would just go away
when one uses a larger corpus, but this hope is not borne out: rather,
lots of words that we do not see at all in Tom Sawyer will occur – once or
twice – in a large corpus. The existence of this long tail of rare words isthe basis for the most celebrated early result in corpus linguistics, Zipf’slaw, which we will discuss next.
1.4.3 Zipf’s laws
In his book Human Behavior and the Principle of Least Eﬀort ,Z i p fa r g u e s
that he has found a unifying principle, the Principle of Least Eﬀort, whichunderlies essentially the entire human condition (the book even includessome questionable remarks on human sexuality!). The Principle of LeastEﬀort argues that people will act so as to minimize their probable averagerate of work (i.e., not only to minimize the work that they would have to
do immediately, but taking due consideration of future work that might
result from doing work poorly in the short term). The evidence for thistheory is certain empirical laws that Zipf uncovered, and his presentationof these laws begins where his own research began, in uncovering certainstatistical distributions in language. We will not comment on his generaltheory here, but will mention some of his empirical language laws.
The famous law: Zipf’s law
If we count up how often each word (type) of a language occurs in a large
corpus, and then list the words in order of their frequency of occurrence,we can explore the relationship between the frequency of a word fand
its position in the list, known as its rankr. Zipf’s law says that:
rank

p/CX /CX24 1 Introduction
Word Freq. Rank fr Word Freq. Rank fr
(f)(r)( f)(r)
the 3332 1 3332 turned 51 200 10200and 2972 2 5944 you’ll 30 300 9000a 1775 3 5235 name 21 400 8400
he 877 10 8770 comes 16 500 8000
but 410 20 8400 group 13 600 7800be 294 30 8820 lead 11 700 7700there 222 40 8880 friends 10 800 8000one 172 50 8600 begin 9 900 8100about 158 60 9480 family 8 1000 8000more 138 70 9660 brushed 4 2000 8000
never 124 80 9920 sins 2 3000 6000
Oh 116 90 10440 Could 2 4000 8000two 104 100 10400 Applausive 1 8000 8000
Table 1.3 Empirical evaluation of Zipf’s law on Tom Sawyer .
f/1
r(1.14)
or, in other words:
There is a constant ksuch thatfrk (1.15)
For example, this says that the 50thmost common word should occur
with three times the frequency of the 150thmost common word. This
relationship between frequency and rank appears ﬁrst to have been no-
ticed by Estoup (1916), but was widely publicized by Zipf and continuesto bear his name. We will regard this result not actually as a law, but as aroughly accurate characterization of certain empirical facts.
Table 1.3 shows an empirical evaluation of Zipf’s law on the basis of
Tom Sawyer . Here, Zipf’s law is shown to approximately hold, but we
note that it is quite a bit oﬀ for the three highest frequency words, and
further that the product frtends to bulge a little for words of rank
around 100, a slight bulge which can also be noted in many of Zipf’sown studies. Nevertheless, Zipf’s law is useful as a rough description ofthe frequency distribution of words in human languages: there are a fewvery common words, a middling number of medium frequency words,and many low frequency words. Zipf saw in this a deep signiﬁcance.

p/CX /CX1.4 Dirty Hands 25
According to his theory both the speaker and the hearer are trying to
minimize their eﬀort. The speaker’s eﬀort is conserved by having a smallvocabulary of common words and the hearer’s eﬀort is lessened by hav-ing a large vocabulary of individually rarer words (so that messages areless ambiguous). The maximally economical compromise between these
competing needs is argued to be the kind of reciprocal relationship be-
tween frequency and rank that appears in the data supporting Zipf’s law.However, for us, the main upshot of Zipf’s law is the practical problemthat for most words our data about their use will be exceedingly sparse.Only for a few words will we have lots of examples.
The validity and possibilities for the derivation of Zipf’s law is studied
extensively by Mandelbrot (1954). While studies of larger corpora some-
times show a closer match to Zipf’s predictions than our examples here,
Mandelbrot (1954: 12) also notes that “bien que la formule de Zipf donnel’allure générale des courbes, elle en représente très mal les détails [al-though Zipf’s formula gives the general shape of the curves, it is verybad in reﬂecting the details].” Figure 1.1 shows a rank-frequency plot ofthe words in one corpus (the Brown corpus) on doubly logarithmic axes.Zipf’s law predicts that this graph should be a straight line with slope −1.
Mandelbrot noted that the line is often a bad ﬁt, especially for low and
high ranks. In our example, the line is too low for most low ranks andtoo high for ranks greater than 10,000.
To achieve a closer ﬁt to the empirical distribution of words, Mandel-
brot derives the following more general relationship between rank andfrequency:
fPr
−Bor logflogP−Blogr (1.16)
HereP,Bandare parameters of a text, that collectively measure the
richness of the text’s use of words. There is still a hyperbolic distribu-tion between rank and frequency, as in the original equation (1.14). Ifthis formula is graphed on doubly logarithmic axes, then for large valuesofr, it closely approximates a straight line descending with slope −B,
just as Zipf’s law. However, by appropriate setting of the other parame-
ters, one can model a curve where the predicted frequency of the mostfrequent words is lower, while thereafter there is a bulge in the curve:just as we saw in the case of Tom Sawyer . The graph in ﬁgure 1.2 shows
that Mandelbrot’s formula is indeed a better ﬁt than Zipf’s law for ourcorpus. The slight bulge in the upper left corner and the larger slope

p/CX /CX26 1 Introduction
···
····
·
······························································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································
··········································································
···············································································································································
rankfrequency
1 10 100 1000 10000 1000001 10 100 1000 10000 100000
1 10 100 1000 10000 1000001 10 100 1000 10000 100000
Figure 1.1 Zipf’s law. The graph shows rank on the X-axis versus frequency
on the Y-axis, using logarithmic scales. The points correspond to the ranksand frequencies of the words in one corpus (the Brown corpus). The line is therelationship between rank and frequency predicted by Zipf for k100;000, that
isfr100;000.
ofB1:15 model the lowest and highest ranks better than the line in
ﬁgure 1.1 predicted by Zipf.
If we takeB1a n d0 then Mandelbrot’s formula simpliﬁes to
the one given by Zipf (see exercise 1.3). Based on data similar to the cor-pora we just looked at, Mandelbrot argues that Zipf’s simpler formulajust is not true in general: “lorsque Zipf essayait de représenter tout parcette loi, il essayait d’habiller tout le monde avec des vêtements d’uneseule taille [when Zipf tried to represent everything by this (i.e., his) law,
he tried to dress everyone with clothes of a single cut]”. Nevertheless,
Mandelbrot sees the importance of Zipf’s work as stressing that there areoften phenomena in the world that are not suitably modeled by Gaussian(normal) distributions, that is, ‘bell curves,’ but by hyperbolic distribu-tions – a fact discovered earlier in the domain of economics by Pareto.

p/CX /CX1.4 Dirty Hands 27
···
····
·
······························································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································································
··········································································
···············································································································································
rankfrequency
1 10 100 1000 10000 1000001 10 100 1000 10000 100000
1 10 100 1000 10000 1000001 10 100 1000 10000 100000
Figure 1.2 Mandelbrot’s formula. The graph shows rank on the X-axis versus
frequency on the Y-axis, using logarithmic scales. The points correspond to theranks and frequencies of the words in one corpus (the Brown corpus). The line isthe relationship between rank and frequency predicted by Mandelbrot’s formulaforP10
5:4,B1:15,100.
Other laws
References to Zipf’s law in the Statistical NLPliterature invariably refer
to the above law, but Zipf actually proposed a number of other empiricallaws relating to language which were also taken to illustrate the Principleof Least Eﬀort. At least two others are of some interest to the concernsof Statistical
NLP. One is the suggestion that the number of meanings
of a word is correlated with its frequency. Again, Zipf argues that con-
servation of speaker eﬀort would prefer there to be only one word with
all meanings while conservation of hearer eﬀort would prefer each mean-ing to be expressed by a diﬀerent word. Assuming that these forces areequally strong, Zipf argues that the number of meanings mof a word
obeys the law:
m/q
f (1.17)

p/CX /CX28 1 Introduction
or, given the previous law, that:
m/1pr(1.18)
Zipf ﬁnds empirical support for this result (in his study, words of fre-
quency rank about 10,000 average about 2.1 meanings, words of rankabout 5000 average about 3 meanings, and words of rank about 2000average about 4.6 meanings).
A second result concerns the tendency of content words to clump. For
a word one can measure the number of lines or pages between each oc-currence of the word in a text, and then calculate the frequency Fof
diﬀerent interval sizes I. For words of frequency at most 24 in a 260,000
word corpus, Zipf found that the number of intervals of a certain sizewas inversely related to the interval size ( F/I
−p,w h e r epvaried be-
tween about 1 and 1.3 in Zipf’s studies). In other words, most of the timecontent words occur near another occurrence of the same word.
The topic of word senses is discussed in chapter 7, while the clumping
of content words is discussed in section 15.3.
Other laws of Zipf’s include that there is an inverse relationship be-
tween the frequency of words and their length, that the greater the fre-quency of a word or morpheme, the greater the number of diﬀerent per-mutations (roughly, compounds and morphologically complex forms) itwill be used in, and yet further laws covering historical change and thefrequency of phonemes.
The signiﬁcance of power laws
As a ﬁnal remark on Zipf’s law, we note that there is a debate on how
surprising and interesting Zipf’s law and ‘power laws’ in general are asa description of natural phenomena. It has been argued that randomlygenerated text exhibits Zipf’s law (Li 1992). To show this, we constructa generator that randomly produces characters from the 26 letters of thealphabet and the blank (that is, each of these 27 symbols has an equal
chance of being generated next). Simplifying slightly, the probability of a
word of length nbeing generated is(
26
27n1
27: the probability of generating
a non-blank character ntimes and the blank after that. One can show
that the words generated by such a generator obey a power law of theform Mandelbrot suggested. The key insights are (i) that there are 26times more words of length n1 than length n, and (ii) that there is a

p/CX /CX1.4 Dirty Hands 29
constant ratio by which words of length nare more frequent than words
of lengthn1. These two opposing trends combine into the regularity
of Mandelbrot’s law. See exercise 1.4.
There is in fact a broad class of probability distributions that obey
power laws when the same procedure is applied to them that is used to
compute the Zipf distribution: ﬁrst counting events, then ranking them
according to their frequency (Günter et al. 1996). Seen from this angle,Zipf’s law seems less valuable as a characterization of language. But thebasic insight remains: what makes frequency-based approaches to lan-guage hard is that almost all words are rare. Zipf’s law is a good way toencapsulate this insight.
1.4.4 Collocations
Lexicographers and linguists (although rarely those of a generative bent)have long been interested in collocations. A collocation is any turn of
collocation
phrase or accepted usage where somehow the whole is perceived to have
an existence beyond the sum of the parts. Collocations include com-pounds ( disk drive ), phrasal verbs ( make up ), and other stock phrases
(bacon and eggs ). They often have a specialized meaning or are idiomatic,
but they need not be. For example, at the time of writing, a favorite ex-pression of bureaucrats in Australia is international best practice .N o w
there appears to be nothing idiomatic about this expression; it is simplytwo adjectives modifying a noun in a productive and semantically com-positional way. But, nevertheless, the frequent use of this phrase as aﬁxed expression accompanied by certain connotations justiﬁes regarding
it as a collocation. Indeed, any expression that people repeat because
they have heard others using it is a candidate for a collocation.
Collocations are discussed in detail in chapter 5. We see later on that
collocations are important in areas of Statistical
NLP such as machine
translation (chapter 13) and information retrieval (chapter 15). In ma-chine translation, a word may be translated diﬀerently according to thecollocation it occurs in. An information retrieval system may want to
index only ‘interesting’ phrases, that is, those that are collocations.
Lexicographers are also interested in collocations both because they
show frequent ways in which a word is used, and because they are mul-tiword units which have an independent existence and probably shouldappear in a dictionary. They also have theoretical interest: to the extentthat most of language use is people reusing phrases and constructions

p/CX /CX30 1 Introduction
Frequency Word 1 Word 2
80871 of the
58841 in the
26430 to the21842 on the21839 for the18568 and the16121 that the15630 at the
15494 to be
13899 in a13689 of a13361 by the13183 with the12622 from the11428 New York
10007 he said
9775 as a9231 is a8753 has been8573 for a
Table 1.4 Commonest bigram collocations in the New York Times .
that they have heard, this serves to de-emphasize the Chomskyan focus
on the creativity of language use, and to give more strength to some-
thing like a Hallidayan approach that considers language to be insepara-ble from its pragmatic and social context.
Now collocations may be several words long (such as international best
practice ) or they may be discontinuous (such as make [something] up ), but
let us restrict ourselves to the simplest case and wonder how we can au-tomatically identify contiguous two word collocations. It was mentioned
above that collocations tend to be frequent usages. So the ﬁrst idea to try
might be simply to ﬁnd the most common two word sequences in a text.That is fairly easily done, and, for a corpus of text from the New York
Times (see page 153), the results are shown in table 1.4. Unfortunately,
this method does not seem to succeed very well at capturing the collo-cations present in the text. It is not surprising that these pairs of words

p/CX /CX1.4 Dirty Hands 31
(normally referred to as bigrams ) occur commonly. They simply rep- bigrams
resent common syntactic constructions involving individually extremely
common words. One problem is that we are not normalizing for the fre-quency of the words that make up the collocation. Given that the, of ,a n d
inare extremely common words, and that the syntax of prepositional
and noun phrases means that a determiner commonly follows a preposi-
tion, we should expect to commonly see of the andin the . But that does
not make these word sequences collocations. An obvious next step is tosomehow take into account the frequency of each of the words. We willlook at methods that do this in chapter 5.
A modiﬁcation that might be less obvious, but which is very eﬀective,
is to ﬁlter the collocations and remove those that have parts of speech
(or syntactic categories) that are rarely associated with interesting collo-
cations. There simply are no interesting collocations that have a preposi-tion as the ﬁrst word and an article as the second word. The two most fre-quent patterns for two word collocations are “adjective noun” and “nounnoun” (the latter are called noun-noun compounds). Table 1.5 showswhich bigrams are selected from the corpus if we only keep adjective-noun and noun-noun bigrams. Almost all of them seem to be phrases
that we would want to list in a dictionary – with some exceptions like last
year andnext year .
Our excursion into ‘collocation discovery’ illustrates the back and forth
in Statistical
NLPbetween modeling and data analysis. Our initial model
was that a collocation is simply a frequent bigram. We analyzed the re-sults we got based on this model, identiﬁed problems and then cameup with a reﬁned model (collocation = frequent bigram with a particular
part-of-speech pattern). This model needs further reﬁnement because of
bigrams like next year that are selected incorrectly. Still, we will leave
our investigation of collocations for now, and continue it in chapter 5.
1.4.5 Concordances
As a ﬁnal illustration of data exploration, suppose we are interested in
the syntactic frames in which verbs appear. People have researched how
to get a computer to ﬁnd these frames automatically, but we can also justuse the computer as a tool to ﬁnd appropriate data. For such purposes,people often use a Key Word In Context (
KWIC ) concordancing program Key Word In
Context which produces displays of data such as the one in ﬁgure 1.3. In such
a display, all occurrences of the word of interest are lined up beneath

p/CX /CX32 1 Introduction
Frequency Word 1 Word 2 Part-of-speech pattern
11487 New York A N
7261 United States A N
5412 Los Angeles N N3301 last year A N3191 Saudi Arabia N N2699 last week A N2514 vice president A N2378 Persian Gulf A N
2161 San Francisco N N
2106 President Bush N N2001 Middle East A N1942 Saddam Hussein N N1867 Soviet Union A N1850 White House A N1633 United Nations A N
1337 York City N N
1328 oil prices N N1210 next year A N1074 chief executive A N1073 real estate A N
Table 1.5 Frequent bigrams after ﬁltering. The most frequent bigrams in the
New York Times after applying a part-of-speech ﬁlter.
1 could find a target. The librarian “showed off” - running hither and thither w
2 elights in. The young lady teachers “showed off” - bending sweetly over pupils3 ingly. The young gentlemen teachers “showed off” with small scoldings and other4 seeming vexation). The little girls “showed off” in various ways, and the littl
5 n various ways, and the little boys “showed off” with such diligence that the a
6 t genuwyne?” Tom lifted his lip and showed the vacancy. “Well, all right,” sai7 is little finger for a pen. Then he showed Huckleberry how to make an H and an8 ow’s face was haggard, and his eyes showed the fear that was upon him. When he9 not overlook the fact that Tom even showed a marked aversion to these inquests
10 own. Two or three glimmering lights showed where it lay, peacefully sleeping,11 ird flash turned night into day and showed every little grass-blade, separate12 that grew about their feet. And it showed three white, startled faces, too. A13 he first thing his aunt said to him showed him that he had brought his sorrows
14 p from her lethargy of distress and showed good interest in the proceedings. S
15 ent a new burst of grief from Becky showed Tom that the thing in his mind had16 shudder quiver all through him. He showed Huck the fragment of candle-wick pe
Figure 1.3 Key Word In Context ( KWIC ) display for the word showed .

p/CX /CX1.4 Dirty Hands 33
NPagent showed oﬀ (PP[ with/in ]manner )
NPagent showed (NP recipient )0
BBBBBB@8
>>>>>><
>>>>>>:NP
content
CP[that]content
VP[inf] content
how VP[inf] content
CP[where ]content9
>>>>>>=
>>>>>>;1
CCCCCCA
NP
agent showed NP[ interest ] PP[in]content
NPagent showed NP[ aversion ] PP[to]content
Figure 1.4 Syntactic frames for showed inTom Sawyer .
one another, with surrounding context shown on both sides. Commonly,
KWIC programs allow you to sort the matches by left or right context.
However, if we are interested in syntactic frames, rather than particu-lar words, such sorting is of limited use. The data shows occurrencesof the word showed within the novel Tom Sawyer . There are 5 uses of
showed oﬀ (actually all within one paragraph of the text), each in dou-
ble quotes, perhaps because it was a neologism at the time, or perhaps
because Twain considered the expression slang. All of these uses are in-
transitive, although some take prepositional phrase modiﬁers. Beyondthese, there are four straightforward transitive verb uses with just adirect object (6, 8, 11, 12) – although there are interesting diﬀerencesbetween them with 8 being nonagentive, and 12 illustrating a sense of‘cause to be visible.’ There is one ditransitive use which adds the personbeing shown (16). Three examples make who was shown the object NP
and express the content either as a that-clause (13, 15) or as a non-ﬁnite
question-form complement clause (7). One other example has a ﬁnitequestion-form complement clause (10) but omits mention of the personwho is shown. Finally two examples have an NP object followed by aprepositional phrase and are quite idiomatic constructions (9, 14): show
an aversion PP[to] andshow an interest PP[in] . But note that while quite
idiomatic, they are not completely frozen forms, since in both cases the
object noun is productively modiﬁed to make a more complex NP. We
could systematize the patterns we have found as in ﬁgure 1.4.
Collecting information like this about patterns of occurrence of verbs
can be useful not only for purposes such as dictionaries for learners offoreign languages, but for use in guiding statistical parsers. A substantialpart of the work in Statistical
NLPconsists (or should consist!) of poring

p/CX /CX34 1 Introduction
over large amounts of data, like concordance lines and lists of candidates
for collocations. At the outset of a project this is done to understand theimportant phenomena, later to reﬁne the initial modeling, and ﬁnally toevaluate what was achieved.
1.5 Further Reading
Chomsky (1965: 47ﬀ, 1980: 234ﬀ, 1986) discusses the distinction be-tween rationalist and empiricist approaches to language, and presents ar-guments for the rationalist position. A recent detailed response to thesearguments from an ‘empiricist’ is (Sampson 1997). For people from a gen-
erative (computational) linguistics background wondering what Statisti-
cal
NLPcan do for them, and how it relates to their traditional concerns,
Abney (1996b) is a good place to start. The observation that there mustbe a preference for certain kinds of generalizations in order to bootstrapinduction was pointed out in the machine learning literature by Mitchell(1980), who termed the preference bias. The work of Firth is highly in-
bias
ﬂuential within certain strands of the British corpus linguistics tradition,
and is thoroughly covered in (Stubbs 1996). References from within the
Statistical NLPcommunity perhaps originate in work from AT&T, see for
instance (Church and Mercer 1993: 1). The Hallidayan approach to lan-guage is presented in (Halliday 1994).
Thorough discussions of grammaticality judgements in linguistics are
grammaticality
found in (Schütze 1996) and (Cowart 1997). Cowart argues for making
use of the judgements of a population of speakers, which is quite com-
patible with the approach of this book, and rather against the Chomskyan
approach of exploring the grammar of a single speaker. A good entrypoint to the literature on categorical perception is (Harnad 1987).
Lauer (1995b: ch. 3) advocates an approach involving probability dis-
tributions over meanings. See the Further Reading of chapter 12 for ref-erences to other Statistical
NLPwork that involves mapping to semantic
representations.
The discussion of kind/sort of is based on Tabor (1994), which should
be consulted for the sources of the citations used. Tabor provides a con-nectionist model which shows how the syntactic change discussed can becaused by changing frequencies of use. A lot of interesting recent workon gradual syntactic change can be found in the literature on grammati-
grammaticaliza-
tion calization (Hopper and Traugott 1993).

pa/CX /CX1.6 Exercises 35
Two proponents of an important role for probabilistic mechanisms in
cognition are Anderson (1983, 1990) and Suppes (1984). See (Oaksfordand Chater 1998) for a recent collection describing diﬀerent cognitivearchitectures, including connectionism. The view that language is bestexplained as a cognitive phenomenon is the central tenet of cognitive
linguistics (Lakoﬀ 1987; Langacker 1987, 1991), but many cognitive lin-
guists would not endorse probability theory as a formalization of cogni-tive linguistics. See also (Schütze 1997).
The novel Tom Sawyer is available in the public domain on the internet,
currently from sources including the Virginia Electronic Text Center (seethe website).
Zipf’s work began with (Zipf 1929), his doctoral thesis. His two major
books are (Zipf 1935) and (Zipf 1949). It is interesting to note that Zipf
was reviewed harshly by linguists in his day (see, for instance, (Kent 1930)and (Prokosch 1933)). In part these criticisms correctly focussed on thegrandiosity of Zipf’s claims (Kent (1930: 88) writes: “problems of phonol-ogy and morphology are not to be solved en masse by one grand general
formula”), but they also reﬂected, even then, a certain ambivalence to theapplication of statistical methods in linguistics. Nevertheless, prominent
American structuralists, such as Martin Joos and Morris Swadesh, did be-
come involved in data collection for statistical studies, with Joos (1936)emphasizing that the question of whether to use statistical methods inlinguistics should be evaluated separately from Zipf’s particular claims.
As well as (Mandelbrot 1954), Mandelbrot’s investigation of Zipf’s law
is summarized in (Mandelbrot 1983) – see especially chapters 38, 40,and 42. Mandelbrot attributes the direction of his life’s work (leading
to his well known work on fractals and the Mandelbrot set) to reading a
review of (Zipf 1949).
Concordances were ﬁrst constructed by hand for important literary and
religious works. Computer concordancing began in the late 1950s for thepurposes of categorizing and indexing article titles and abstracts. Luhn(1960) developed the ﬁrst computer concordancer and coined the termKWIC .
KWIC
1.6 Exercises
Exercise 1.1 [«« Requires some knowledge of linguistics]
Try to think of some other cases of noncategorical phenomena in language, per-
haps related to language change. For starters, look at the following pairs of

p/CX /CX36 1 Introduction
sentences, and try to work out the problems they raise. (Could these problems
be solved simply by assigning the words to two categories, or is there evidenceof mixed categoriality?)
(1.19) a. On the weekend the children had fun.
b. That’s the funnest thing we’ve done all holidays.
(1.20) a. Do you get much email at work?
b. This morning I had emails from ﬁve clients, all complaining.
Exercise 1.2 [«« Probably best attempted after reading chapter 4]
Replicate some of the results of section 1.4 on some other piece of text. (Alter-
natively, you could use the same text that we did so that you can check yourwork easily. In this case, you should only expect results similar to ours, sincethe exact numbers depend on various details of what is treated as a word, howcase distinctions are treated, etc.)
Exercise 1.3 [«]
Show that Mandelbrot’s law simpliﬁes to Zipf’s law for B1 and0.
Exercise 1.4 [««]
Construct a table like table 1.3 for the random character generator described
above on page 29 (which generates the letters athrough zand blank with equal
probability of 1 =27).
Exercise 1.5 [««]
Think about ways of identifying collocations that might be better than the meth-
ods used in this chapter.
Exercise 1.6 [««]
If you succeeded in the above exercise, try the method out and see how well it
appears to perform.
Exercise 1.7 [««]
Write a program to produce
KWIC displays from a text ﬁle. Have the user be able
to select the word of interest and the size of the surrounding context.

p/CX /CX“In 1786, I found, that in Germany they were engaged in a
species of political inquiry, to which they had given the name ofStatistics; and though I apply a diﬀerent idea to that word, forby Statistical is meant in Germany, an inquiry for the purposeof ascertaining the political strength of a country, or questions
respecting matters of state; whereas, the idea I annex to the
term, is an inquiry into the state of a country, for the purposeof ascertaining the quantum of happiness enjoyed by itsinhabitants, and the means of its future improvement; yet, asI thought that a new word might attract more public attention,I resolved on adopting it.”
(Sir J. Sinclair Statist. Acc. Scot. XX. App. p. xiii, 1798)



