p/CX /CX5 Collocations
A collocation is an expression consisting of two or more words that
correspond to some conventional way of saying things. Or in the wordsof Firth (1957: 181): ‚ÄúCollocations of a given word are statements of thehabitual or customary places of that word.‚Äù Collocations include nounphrases like strong tea andweapons of mass destruction , phrasal verbs
liketo make up , and other stock phrases like the rich and powerful .P a r -
ticularly interesting are the subtle and not-easily-explainable patterns of
word usage that native speakers all know: why we say a stiÔ¨Ä breeze but
not??a stiÔ¨Ä wind (while either a strong breeze ora strong wind is okay),
or why we speak of broad daylight (but not ?bright daylight or??narrow
darkness ).
Collocations are characterized by limited compositionality .W e c a l l a
compositionality
natural language expression compositional if the meaning of the expres-
sion can be predicted from the meaning of the parts. Collocations are not
fully compositional in that there is usually an element of meaning added
to the combination. In the case of strong tea ,strong has acquired the
meaning rich in some active agent which is closely related, but slightly
diÔ¨Äerent from the basic sense having great physical strength .I d i o m sa r e
the most extreme examples of non-compositionality. Idioms like to kick
the bucket orto hear it through the grapevine only have an indirect his-
torical relationship to the meanings of the parts of the expression. We
are not talking about buckets or grapevines literally when we use these
idioms. Most collocations exhibit milder forms of non-compositionality,like the expression international best practice that we used as an exam-
ple earlier in this book. It is very nearly a systematic composition of itsparts, but still has an element of added meaning. It usually refers to ad-ministrative eÔ¨Éciency and would, for example, not be used to describe a

p/CX /CX152 5 Collocations
cooking technique although that meaning would be compatible with its
literal meaning.
There is considerable overlap between the concept of collocation and
notions like term ,technical term ,a n d terminological phrase . As these term
technical term
terminological
phrasenames suggest, the latter three are commonly used when collocations
are extracted from technical domains (in a process called terminology
terminology
extractionextraction ). The reader should be warned, though, that the word term
has a diÔ¨Äerent meaning in information retrieval. There, it refers to bothwords and phrases. So it subsumes the more narrow meaning that wewill use in this chapter.
Collocations are important for a number of applications: natural lan-
guage generation (to make sure that the output sounds natural and mis-
takes like powerful tea orto take a decision are avoided), computational
lexicography (to automatically identify the important collocations to belisted in a dictionary entry), parsing (so that preference can be given toparses with natural collocations), and corpus linguistic research (for in-stance, the study of social phenomena like the reinforcement of culturalstereotypes through language (Stubbs 1996)).
There is much interest in collocations partly because this is an area that
has been neglected in structural linguistic traditions that follow Saussure
and Chomsky. There is, however, a tradition in British linguistics, asso-ciated with the names of Firth, Halliday, and Sinclair, which pays closeattention to phenomena like collocations. Structural linguistics concen-trates on general abstractions about the properties of phrases and sen-tences. In contrast, Firth‚Äôs Contextual Theory of Meaning emphasizes the
Contextual Theory
of Meaning importance of context: the context of the social setting (as opposed to
the idealized speaker), the context of spoken and textual discourse (as
opposed to the isolated sentence), and, important for collocations, thecontext of surrounding words (hence Firth‚Äôs famous dictum that a word ischaracterized by the company it keeps). These contextual features easilyget lost in the abstract treatment that is typical of structural linguistics.
A good example of the type of problem that is seen as important in
this contextual view of language is Halliday‚Äôs example of strong vs. pow-
erful tea (Halliday 1966: 150). It is a convention in English to talk about
strong tea ,n o t powerful tea , although any speaker of English would also
understand the latter unconventional expression. Arguably, there are nointeresting structural properties of English that can be gleaned from thiscontrast. However, the contrast may tell us something interesting aboutattitudes towards diÔ¨Äerent types of substances in our culture (why do we

p/CX /CX5.1 Frequency 153
usepowerful for drugs like heroin, but not for cigarettes, tea and coÔ¨Äee?)
and it is obviously important to teach this contrast to students who wantto learn idiomatically correct English. Social implications of language useand language teaching are just the type of problem that British linguistsfollowing a Firthian approach are interested in.
In this chapter, we will introduce a number of approaches to Ô¨Ånding
collocations: selection of collocations by frequency, selection based onmean and variance of the distance between focal word and collocatingword, hypothesis testing, and mutual information. We will then returnto the question of what a collocation is and discuss in more depth diÔ¨Äer-ent deÔ¨Ånitions that have been proposed and tests for deciding whethera phrase is a collocation or not. The chapter concludes with further
readings and pointers to some of the literature that we were not able
to include.
The reference corpus we will use in examples in this chapter consists
of four months of the New York Times newswire: from August through
November of 1990. This corpus has about 115 megabytes of text androughly 14 million words. Each approach will be applied to this corpusto make comparison easier. For most of the chapter, the New York Times
examples will only be drawn from Ô¨Åxed two-word phrases (or bigrams).
It is important to keep in mind, however, that we chose this pool forconvenience only. In general, both Ô¨Åxed and variable word combinationscan be collocations. Indeed, the section on mean and variance looks atthe more loosely connected type.
5.1 Frequency
Surely the simplest method for Ô¨Ånding collocations in a text corpus iscounting. If two words occur together a lot, then that is evidence thatthey have a special function that is not simply explained as the functionthat results from their combination.
Predictably, just selecting the most frequently occurring bigrams is not
very interesting as is shown in table 5.1. The table shows the bigrams
(sequences of two adjacent words) that are most frequent in the corpusand their frequency. Except for New York , all the bigrams are pairs of
function words.
There is, however, a very simple heuristic that improves these results
a lot (Justeson and Katz 1995b): pass the candidate phrases through a

p/CX /CX154 5 Collocations
C¬Ñw1w2¬Öw1w2
80871 of the
58841 in the
26430 to the
21842 on the21839 for the18568 and the16121 that the15630 at the15494 to be
13899 in a
13689 of a13361 by the13183 with the12622 from the11428 New York10007 he said
9775 as a
9231 is a8753 has been8573 for a
Table 5.1 Finding Collocations: Raw Frequency. C¬Ñ¬Öis the frequency of some-
thing in the corpus.
Tag Pattern Example
AN linear function
NN regression coeÔ¨Écients
AAN Gaussian random variable
ANN cumulative distribution function
NAN mean squared error
NNN class probability function
NPN degrees of freedom
Table 5.2 Part of speech tag patterns for collocation Ô¨Åltering. These patterns
were used by Justeson and Katz to identify likely collocations among frequentlyoccurring word sequences.

p/CX /CX5.1 Frequency 155
C¬Ñw1w2¬Öw1w2Tag Pattern
11487 New York A N
7261 United States A N
5412 Los Angeles N N
3301 last year A N3191 Saudi Arabia N N2699 last week A N2514 vice president A N2378 Persian Gulf A N2161 San Francisco N N
2106 President Bush N N
2001 Middle East A N1942 Saddam Hussein N N1867 Soviet Union A N1850 White House A N1633 United Nations A N1337 York City N N
1328 oil prices N N
1210 next year A N1074 chief executive A N1073 real estate A N
Table 5.3 Finding Collocations: Justeson and Katz‚Äô part-of-speech Ô¨Ålter.
part-of-speech Ô¨Ålter which only lets through those patterns that are likely
to be ‚Äòphrases.‚Äô1Justeson and Katz (1995b: 17) suggest the patterns in
table 5.2. Each is followed by an example from the text that they use as atest set. In these patterns A refers to an adjective, P to a preposition, andN to a noun.
Table 5.3 shows the most highly ranked phrases after applying the Ô¨Ål-
ter. The results are surprisingly good. There are only 3 bigrams that wewould not regard as non-compositional phrases: last year ,last week ,a n d
Ô¨Årst time .York City is an artefact of the way we have implemented the
Justeson and Katz Ô¨Ålter. The full implementation would search for thelongest sequence that Ô¨Åts one of the part-of-speech patterns and wouldthus Ô¨Ånd the longer phrase New York City , which contains York City .
The twenty highest ranking phrases containing strong andpowerful all
1. Similar ideas can be found in (Ross and Tukey 1975) and (Kupiec et al. 1995).

p/CX /CX156 5 Collocations
wC ¬Ñ strong;w¬Ö w C¬Ñ powerful;w¬Ö
support 50 force 13
safety 22 computers 10
sales 21 position 8
opposition 19 men 8showing 18 computer 8sense 18 man 7message 15 symbol 6defense 14 military 6gains 13 machines 6
evidence 13 country 6
criticism 13 weapons 5possibility 11 post 5feelings 11 people 5demand 11 nation 5challenges 11 forces 5challenge 11 chip 5
case 11 Germany 5
supporter 10 senators 4signal 9 neighbor 4man 9 magnet 4
Table 5.4 The nounswoccurring most often in the patterns ‚Äò strongw‚Äô and
‚Äòpowerfulw.‚Äô
have the form A N (where A is either strong orpowerful ). We have listed
them in table 5.4.
Again, given the simplicity of the method, these results are surpris-
ingly accurate. For example, they give evidence that strong challenge and
powerful computers are correct whereas powerful challenge andstrong
computers are not. However, we can also see the limits of a frequency-
based method. The nouns man andforce are used with both adjectives
(strong force occurs further down the list with a frequency of 4). A more
sophisticated analysis is necessary in such cases.
Neither strong tea norpowerful tea occurs in our New York Times cor-
pus. However, searching the larger corpus of the World Wide Web we Ô¨Ånd799 examples of strong tea and 17 examples of powerful tea (the latter
mostly in the computational linguistics literature on collocations), which

p/CX /CX5.2 Mean and Variance 157
indicates that the correct phrase is strong tea .2
Justeson and Katz‚Äô method of collocation discovery is instructive in
that it demonstrates an important point. A simple quantitative technique(the frequency Ô¨Ålter in this case) combined with a small amount of lin-guistic knowledge (the importance of parts of speech) goes a long way. In
the rest of this chapter, we will use a stop list that excludes words whose
most frequent tag is not a verb, noun or adjective.
Exercise 5.1 [¬´]
Add part-of-speech patterns useful for collocation discovery to table 5.2, includ-
ing patterns longer than two tags.
Exercise 5.2 [¬´]
Pick a document in which your name occurs (an email, a university transcript or
a letter). Does Justeson and Katz‚Äôs Ô¨Ålter identify your name as a collocation?
Exercise 5.3 [¬´]
We used the World Wide Web as an auxiliary corpus above because neither stong
teanorpowerful tea occurred in the New York Times . Modify Justeson and Katz‚Äôs
method so that it uses the World Wide Web as a resource of last resort.
5.2 Mean and Variance
Frequency-based search works well for Ô¨Åxed phrases. But many colloca-
tions consist of two words that stand in a more Ô¨Çexible relationship to
one another. Consider the verb knock and one of its most frequent argu-
ments, door. Here are some examples of knocking on or at a door from
our corpus:
(5.1) a. she knocked on his door
b. they knocked at the door
c. 100 women knocked on Donaldson‚Äôs door
d. a man knocked on the metal front door
The words that appear between knocked anddoor vary and the distance
between the two words is not constant so a Ô¨Åxed phrase approach wouldnot work here. But there is enough regularity in the patterns to allowus to determine that knock is the right verb to use in English for this
situation, not hit,beat orrap.
2. This search was performed on AltaVista on March 28, 1998.

p/CX /CX158 5 Collocations
Sentence: Stocks crash as rescue plan teeters
Bigrams: stocks crash stocks as stocks rescue
crash as crash rescue crash plan
as rescue as plan as teeters
rescue plan rescue teeters
plan teeters
Figure 5.1 Using a three word collocational window to capture bigrams at a
distance.
A short note is in order here on collocations that occur as a Ô¨Åxed phrase
versus those that are more variable. To simplify matters we only look
at Ô¨Åxed phrase collocations in most of this chapter, and usually at justbigrams. But it is easy to see how to extend techniques applicable tobigrams to bigrams at a distance. We deÔ¨Åne a collocational window (usu-ally a window of 3 to 4 words on each side of a word), and we enter every
word pair in there as a collocational bigram, as in Ô¨Ågure 5.1. We thenproceed to do our calculations as usual on this larger pool of bigrams.
However, the mean and variance based methods described in this sec-
tion by deÔ¨Ånition look at the pattern of varying distance between twowords. If that pattern of distances is relatively predictable, then we haveevidence for a collocation like knock . . . door that is not necessarily a
Ô¨Åxed phrase. We will return to this point and a more in-depth discussionof what a collocation is towards the end of this chapter.
One way of discovering the relationship between knocked anddoor is to
compute the mean andvariance of the oÔ¨Äsets (signed distances) between
mean
variancethe two words in the corpus. The mean is simply the average oÔ¨Äset. For
the examples in (5.1), we compute the mean oÔ¨Äset between knocked and
door as follows:
1
4¬Ñ3¬Ç3¬Ç5¬Ç5¬Ö¬É4:0
(This assumes a tokenization of Donaldson‚Äôs as three words Donaldson ,
apostrophe, and s, which is what we actually did.) If there was an oc-
currence of door before knocked , then it would be entered as a negative
number. For example, ‚àí3f o r the door that she knocked on . We restrict
our analysis to positions in a window of size 9 around the focal wordknocked .

p/CX /CX5.2 Mean and Variance 159
The variance measures how much the individual oÔ¨Äsets deviate from
the mean. We estimate it as follows.
s2¬ÉPn
i¬É1¬Ñdi‚àí¬Ød¬Ö2
n‚àí1(5.2)
wherenis the number of times the two words co-occur, diis the oÔ¨Äset for
co-occurrence i,a n d ¬Ødis the sample mean of the oÔ¨Äsets. If the oÔ¨Äset is
the same in all cases, then the variance is zero. If the oÔ¨Äsets are randomlydistributed (which will be the case for two words which occur together bychance, but not in a particular relationship), then the variance will behigh. As is customary, we use the sample deviation s¬Ép
s2, the square sample deviation
root of the variance, to assess how variable the oÔ¨Äset between two words
is. The deviation for the four examples of knocked /door in the above
case is 1:15:
s¬És
1
3(
¬Ñ3‚àí4:0¬Ö2¬Ç¬Ñ3‚àí4:0¬Ö2¬Ç¬Ñ5‚àí4:0¬Ö2¬Ç¬Ñ5‚àí4:0¬Ö2
1:15
The mean and deviation characterize the distribution of distances be-
tween two words in a corpus. We can use this information to discovercollocations by looking for pairs with low deviation. A low deviation
means that the two words usually occur at about the same distance. Zero
deviation means that the two words always occur at exactly the samedistance.
We can also explain the information that variance gets at in terms of
peaks in the distribution of one word with respect to another. Figure 5.2shows the three cases we are interested in. The distribution of strong with
respect to opposition has one clear peak at position ‚àí1 (corresponding
to the phrase strong opposition ). Therefore the variance of strong with
respect to opposition is small (s¬É0:67). The mean of ‚àí1:15 indicates that
strong usually occurs at position ‚àí1 (disregarding the noise introduced
by one occurrence at ‚àí4).
We have restricted positions under consideration to a window of size
9 centered around the word of interest. This is because collocations areessentially a local phenomenon. Note also that we always get a count of
0 at position 0 when we look at the relationship between two diÔ¨Äerent
words. This is because, for example, strong cannot appear in position 0
in contexts in which that position is already occupied by opposition .
Moving on to the second diagram in Ô¨Ågure 5.2, the distribution of
strong with respect to support is drawn out, with several negative po-
sitions having large counts. For example, the count of approximately 20

p/CX /CX160 5 Collocations
50
20frequency
ofstrong
Position of strong with respect to opposition (¬Ød¬É‚àí1:15;s¬É0:67).‚àí4‚àí3‚àí2‚àí1 01234
/BI/B9
50
20frequency
ofstrong
Position of strong with respect to support (¬Ød¬É‚àí1:45;s¬É1:07).‚àí4‚àí3‚àí2‚àí1 01234
/BI/B9
50
20frequency
ofstrong
Position of strong with respect to for(¬Ød¬É‚àí1:12;s¬É2:15).‚àí4‚àí3‚àí2‚àí1 01234
/BI/B9
Figure 5.2 Histograms of the position of strong relative to three words.

p/CX /CX5.2 Mean and Variance 161
s ¬ØdCount Word 1 Word 2
0.43 0.97 11657 New York
0.48 1.83 24 previous games
0.15 2.98 46 minus points
0.49 3.87 131 hundreds dollars
4.03 0.44 36 editorial Atlanta
4.03 0.00 78 ring New
3.96 0.19 119 point hundredth
3.96 0.29 106 subscribers by
1.07 1.45 80 strong support
1.13 2.57 7 powerful organizations
1.01 2.00 112 Richard Nixon
1.05 0.00 10 Garrison said
Table 5.5 Finding collocations based on mean and variance. Sample deviation
sand sample mean ¬Ødof the distances between 12 word pairs.
at position‚àí2 is due to uses like strong leftist support andstrong busi-
ness support . Because of this greater variability we get a higher s(1:07)
and a mean that is between positions ‚àí1a n d‚àí2(‚àí1:45).
Finally, the occurrences of strong with respect to forare more evenly
distributed. There is tendency for strong to occur before for(hence the
negative mean of ‚àí1:12), but it can pretty much occur anywhere around
for. The high deviation of s¬É2:15 indicates this randomness. This
indicates that forandstrong don‚Äôt form interesting collocations.
The word pairs in table 5.5 indicate the types of collocations that can
be found by this approach. If the mean is close to 1 :0 and the devia-
tion low, as is the case for New York , then we have the type of phrase
that Justeson and Katz‚Äô frequency-based approach will also discover. Ifthe mean is much greater than 1 :0, then a low deviation indicates an in-
teresting phrase. The pair previous /games (distance 2) corresponds to
phrases like in the previous 10 games orin the previous 15 games ;minus
/points corresponds to phrases like minus 2 percentage points ,minus
3 percentage points etc;hundreds /dollars corresponds to hundreds of
billions of dollars andhundreds of millions of dollars .
High deviation indicates that the two words of the pair stand in no
interesting relationship as demonstrated by the four high-variance exam-ples in table 5.5. Note that means tend to be close to zero here as one

p/CX /CX162 5 Collocations
would expect for a uniform distribution. More interesting are the cases
in between, word pairs that have large counts for several distances intheir collocational distribution. We already saw the example of strong
{ business } support in Ô¨Ågure 5.2. The alternations captured in the other
three medium-variance examples are powerful { lobbying } organizations ,
Richard { M. } Nixon ,a n d Garrison said /said Garrison (remember that
we tokenize Richard M. Nixon as four tokens: Richard ,M,. ,Nixon ).
The method of variance-based collocation discovery that we have in-
troduced in this section is due to Smadja. We have simpliÔ¨Åed thingssomewhat. In particular, Smadja (1993) uses an additional constraintthat Ô¨Ålters out ‚ÄòÔ¨Çat‚Äô peaks in the position histogram, that is, peaks thatare not surrounded by deep valleys (an example is at ‚àí2 for the combi-
nation strong /forin Ô¨Ågure 5.2). Smadja (1993) shows that the method
is quite successful at terminological extraction (with an estimated accu-racy of 80%) and at determining appropriate phrases for natural languagegeneration (Smadja and McKeown 1990).
Smadja‚Äôs notion of collocation is less strict than many others‚Äô. The
combination knocked /door is probably not a collocation we want to
classify as terminology ‚Äì although it may be very useful to identify for
the purpose of text generation. Variance-based collocation discovery is
the appropriate method if we want to Ô¨Ånd this type of word combination,combinations of words that are in a looser relationship than Ô¨Åxed phrasesand that are variable with respect to intervening material and relativeposition.
5.3 Hypothesis Testing
One diÔ¨Éculty that we have glossed over so far is that high frequency andlow variance can be accidental. If the two constituent words of a frequentbigram like new companies are frequently occurring words (as new and
companies are), then we expect the two words to co-occur a lot just by
chance, even if they do not form a collocation.
What we really want to know is whether two words occur together more
often than chance. Assessing whether or not something is a chance eventis one of the classical problems of statistics. It is usually couched in termsof hypothesis testing. We formulate a null hypothesis H
0that there is no null hypothesis
association between the words beyond chance occurrences, compute the
probabilitypthat the event would occur if H0were true, and then reject

p/CX /CX5.3 Hypothesis Testing 163
H0ifpis too low (typically if beneath a signiÔ¨Åcance level ofp< 0:05, signiÔ¨Åcance level
0:01, 0:005, or 0:001) and retain H0as possible otherwise.3
It is important to note that this is a mode of data analysis where we
look at two things at the same time. As before, we are looking for partic-ular patterns in the data. But we are also taking into account how much
data we have seen. Even if there is a remarkable pattern, we will discount
it if we haven‚Äôt seen enough data to be certain that it couldn‚Äôt be due tochance.
How can we apply the methodology of hypothesis testing to the prob-
lem of Ô¨Ånding collocations? We Ô¨Årst need to formulate a null hypothesiswhich states what should be true if two words do not form a colloca-tion. For such a free combination of two words we will assume that each
of the words w
1andw2is generated completely independently of the
other, and so their chance of coming together is simply given by:
P¬Ñw1w2¬Ö¬ÉP¬Ñw1¬ÖP¬Ñw2¬Ö
The model implies that the probability of co-occurrence is just the prod-
uct of the probabilities of the individual words. As we discuss at the
end of this section, this is a rather simplistic model, and not empirically
accurate, but for now we adopt independence as our null hypothesis.
5.3.1 The ttest
Next we need a statistical test that tells us how probable or improbable it
is that a certain constellation will occur. A test that has been widely used
for collocation discovery is the ttest. Thettest looks at the mean and
variance of a sample of measurements, where the null hypothesis is thatthe sample is drawn from a distribution with mean . The test looks at
the diÔ¨Äerence between the observed and expected means, scaled by thevariance of the data, and tells us how likely one is to get a sample of thatmean and variance (or a more extreme mean and variance) assuming that
the sample is drawn from a normal distribution with mean . To deter-
mine the probability of getting our sample (or a more extreme sample),we compute the tstatistic:
t¬É¬Øx‚àí
q
s2
N(5.3)
3. SigniÔ¨Åcance at a level of 0 :05 is the weakest evidence that is normally accepted in the
experimental sciences. The large amounts of data commonly available for Statistical NLP
tasks means the we can often expect to achieve greater levels of signiÔ¨Åcance.

p/CX /CX164 5 Collocations
where ¬Øxis the sample mean, s2is the sample variance, Nis the sample
size, andis the mean of the distribution. If the tstatistic is large enough
we can reject the null hypothesis. We can Ô¨Ånd out exactly how large it hasto be by looking up the table of the tdistribution we have compiled in
the appendix (or by using the better tables in a statistical reference book,
or by using appropriate computer software).
Here‚Äôs an example of applying the ttest. Our null hypothesis is that
the mean height of a population of men is 158cm. We are given a sampleof 200 men with ¬Øx¬É169 ands
2¬É2600 and want to know whether this
sample is from the general population (the null hypothesis) or whether itis from a diÔ¨Äerent population of smaller men. This gives us the followingtaccording to the above formula:
t¬É169‚àí158
q
2600
2003:05
If you look up the value of tthat corresponds to a conÔ¨Ådence level of
¬É0:005, you will Ô¨Ånd 2 :576.4Since thetwe got is larger than 2 :576,
we can reject the null hypothesis with 99.5% conÔ¨Ådence. So we can saythat the sample is not drawn from a population with mean 158cm, andour probability of error is less than 0.5%.
To see how to use the ttest for Ô¨Ånding collocations, let us compute the
tvalue for new companies . What is the sample that we are measuring the
mean and variance of? There is a standard way of extending the ttest
for use with proportions or counts. We think of the text corpus as along sequence of Nbigrams, and the samples are then indicator random
variables that take on the value 1 when the bigram of interest occurs, andare 0 otherwise.
Using maximum likelihood estimates, we can compute the probabilities
ofnew and companies as follows. In our corpus, new occurs 15,828
times, companies 4,675 times, and there are 14,307,668 tokens overall.
P¬Ñnew¬Ö¬É15828
14307668
P¬Ñcompanies¬Ö¬É4675
14307668
4. A sample of 200 means 199 degress of freedom, which corresponds to about the same
tas1degrees of freedom. This is the row of the table where we looked up 2 :576.

p/CX /CX5.3 Hypothesis Testing 165
The null hypothesis is that occurrences of new andcompanies are inde-
pendent.
H0:P¬Ñnew companies ¬Ö¬ÉP¬Ñnew¬ÖP¬Ñcompanies¬Ö
¬É15828
143076684675
143076683:61510‚àí7
If the null hypothesis is true, then the process of randomly generating
bigrams of words and assigning 1 to the outcome new companies and
0 to any other outcome is in eÔ¨Äect a Bernoulli trial with p¬É3:615
10‚àí7for the probability of new company turning up. The mean for this
distribution is ¬É3:61510‚àí7and the variance is 2¬Ép¬Ñ1‚àíp¬Ö(see
section 2.1.9), which is approximately p. The approximation 2¬Ép¬Ñ1‚àí
p¬Öpholds since for most bigrams pis small.
It turns out that there are actually 8 occurrences of new companies
among the 14,307,668 bigrams in our corpus. So, for the sample, wehave that the sample mean is: ¬Øx¬É
8
143076685:59110‚àí7. Now we have
everything we need to apply the ttest:
t¬É¬Øx‚àíq
s2
N5:59110‚àí7‚àí3:61510‚àí7
q
5:59110‚àí7
143076680:999932
Thistvalue of 0.999932 is not larger than 2.576, the critical value for
¬É0:005. So we cannot reject the null hypothesis that new andcompa-
niesoccur independently and do not form a collocation. That seems the
right result here: the phrase new companies is completely compositional
and there is no element of added meaning here that would justify elevat-ing it to the status of collocation. (The tvalue is suspiciously close to 1.0,
but that is a coincidence. See exercise 5.5.)
Table 5.6 shows tvalues for ten bigrams that occur exactly 20 times in
the corpus. For the top Ô¨Åve bigrams, we can reject the null hypothesisthat the component words occur independently for ¬É0:005, so these
are good candidates for collocations. The bottom Ô¨Åve bigrams fail thetest for signiÔ¨Åcance, so we will not regard them as good candidates forcollocations.
Note that a frequency-based method would not be able to rank the ten
bigrams since they occur with exactly the same frequency. Looking at thecounts in table 5.6, we can see that the ttest takes into account the num-
ber of co-occurrences of the bigram ( C¬Ñw
1w2¬Ö) relative to the frequencies
of the component words. If a high proportion of the occurrences of bothwords ( Ayatollah Ruhollah ,videocassette recorder ) or at least a very high

p/CX /CX166 5 Collocations
tC ¬Ñ w1¬ÖC ¬Ñ w2¬ÖC ¬Ñ w1w2¬Öw1w2
4.4721 42 20 20 Ayatollah Ruhollah
4.4721 41 27 20 Bette Midler
4.4720 30 117 20 Agatha Christie
4.4720 77 59 20 videocassette recorder
4.4720 24 320 20 unsalted butter
2.3714 14907 9017 20 Ô¨Årst made
2.2446 13484 10570 20 over many
1.3685 14734 13478 20 into them
1.2176 14093 14776 20 like people
0.8036 15019 15629 20 time last
Table 5.6 Finding collocations: The ttest applied to 10 bigrams that occur with
frequency 20.
proportion of the occurrences of one of the words ( unsalted ) occurs in
the bigram, then its tvalue is high. This criterion makes intuitive sense.
Unlike most of this chapter, the analysis in table 5.6 includes some
stop words ‚Äì without stop words, it is actually hard to Ô¨Ånd examples thatfail signiÔ¨Åcance. It turns out that most bigrams attested in a corpus occursigniÔ¨Åcantly more often than chance. For 824 out of the 831 bigrams that
occurred 20 times in our corpus the null hypothesis of independence can
be rejected. But we would only classify a fraction as true collocations.The reason for this surprisingly high proportion of possibly dependentbigrams (
824
8310:99) is that language ‚Äì if compared with a random word
generator ‚Äì is very regular so that few completely unpredictable eventshappen. Indeed, this is the basis of our ability to perform tasks likeword sense disambiguation and probabilistic parsing that we discuss in
other chapters. The ttest and other statistical tests are most useful as
a method for ranking collocations. The level of signiÔ¨Åcance itself is less
useful. In fact, in most publications that we cite in this chapter, the levelof signiÔ¨Åcance is never looked at. All that is used is the scores and theresulting ranking.
5.3.2 Hypothesis testing of diÔ¨Äerences
Thettest can also be used for a slightly diÔ¨Äerent collocation discovery
problem: to Ô¨Ånd words whose co-occurrence patterns best distinguish

p/CX /CX5.3 Hypothesis Testing 167
tC ¬Ñ w ¬ÖC ¬Ñ strongw)C¬Ñpowerfulw) Word
3.1622 933 0 10 computers
2.8284 2337 0 8 computer
2.4494 289 0 6 symbol
2.4494 588 0 6 machines2.2360 2266 0 5 Germany2.2360 3745 0 5 nation2.2360 395 0 5 chip2.1828 3418 4 13 force2.0000 1403 0 4 friends
2.0000 267 0 4 neighbor
7.0710 3685 50 0 support
6.3257 3616 58 7 enough4.6904 986 22 0 safety
4.5825 3741 21 0 sales
4.0249 1093 19 1 opposition3.9000 802 18 1 showing3.9000 1641 18 1 sense3.7416 2501 14 0 defense3.6055 851 13 0 gains3.6055 832 13 0 criticism
Table 5.7 Words that occur signiÔ¨Åcantly more often with powerful (the Ô¨Årst ten
words) and strong (the last ten words).
between two words. For example, in computational lexicography we may
want to Ô¨Ånd the words that best diÔ¨Äerentiate the meanings of strong and
powerful . This use of the ttest was suggested by Church and Hanks
(1989). Table 5.7 shows the ten words that occur most signiÔ¨Åcantly moreoften with powerful than with strong (Ô¨Årst ten words) and most signif-
icantly more often with strong than with powerful (second set of ten
words).
Thetscores are computed using the following extension of the ttest
to the comparison of the means of two normal populations:
t¬É¬Øx
1‚àí¬Øx2r
s12
n1¬Çs22
n2(5.4)
Here the null hypothesis is that the average diÔ¨Äerence is 0 ( ¬É0), so we

p/CX /CX168 5 Collocations
have ¬Øx‚àí¬É¬Øx¬É1
NP
¬Ñx1i‚àíx2i¬Ö¬É¬Øx1‚àí¬Øx2. In the denominator we add the
variances of the two populations since the variance of the diÔ¨Äerence oftwo random variables is the sum of their individual variances.
Now we can explain table 5.7. The tvalues in the table were computed
assuming a Bernoulli distribution (as we did for the basic version of the
ttest that we introduced Ô¨Årst). If wis the collocate of interest (e.g.,
computers orsymbol )a n dv
1andv2are the words we are comparing (e.g.,
powerful andstrong ), then we have ¬Øx1¬És2
1¬ÉP¬Ñv1w¬Ö,¬Øx2¬És2
2¬ÉP¬Ñv2w¬Ö.
We again use the approximation s2¬Ép‚àíp2p:
tP¬Ñv1w¬Ö‚àíP¬Ñv2w¬Öq
P¬Ñv1w¬Ö¬ÇP¬Ñv2w¬Ö
N
We can simplify this as follows.
tC¬Ñv1w¬Ö
N‚àíC¬Ñv2w¬Ö
Nq
C¬Ñv1w¬Ö¬ÇC¬Ñv2w¬Ö
N2(5.5)
¬ÉC¬Ñv1w¬Ö‚àíC¬Ñv2w¬Öp
C¬Ñv1w¬Ö¬ÇC¬Ñv2w¬Ö
whereC¬Ñx¬Ö is the number of times xoccurs in the corpus.
The application suggested by Church and Hanks (1989) for this form
of thettest was lexicography. The data in table 5.7 are useful to a lex-
icographer who wants to write precise dictionary entries that bring outthe diÔ¨Äerence between strong andpowerful . Based on signiÔ¨Åcant collo-
cates, Church and Hanks analyze the diÔ¨Äerence as a matter of intrinsic
vs. extrinsic quality. For example, strong support from a demographic
group means that the group is very committed to the cause in question,but the group may not have any power. So strong describes an intrinsic
quality. Conversely, a powerful supporter is somebody who actually has
the power to move things. Many of the collocates we found in our cor-pus support Church and Hanks‚Äô analysis. But there is more complexity to
the diÔ¨Äerence in meaning between the two words since what is extrinsic
and intrinsic can depend on subtle matters like cultural attitudes. For ex-ample, we talk about strong tea on the one hand and powerful drugs on
the other, a diÔ¨Äerence that tells us more about our attitude towards teaand drugs than about the semantics of the two adjectives (Church et al.1991: 133).

p/CX /CX5.3 Hypothesis Testing 169
w1¬Énew w1¬înew
w2¬Écompanies 8 4667
(new companies )(e.g., old companies )
w2¬îcompanies 15820 14287181
(e.g., new machines )(e.g., old machines )
Table 5.8 A 2-by-2 table showing the dependence of occurrences of new and
companies . There are 8 occurrences of new companies in the corpus, 4,667 bi-
grams where the second word is companies ,b u tt h eÔ¨Å r s tw o r di sn o t new, 15,820
bigrams with the Ô¨Årst word new and a second word diÔ¨Äerent from companies ,
and 14,287,181 bigrams that contain neither word in the appropriate position.
5.3.3 Pearson‚Äôs chi-square test
U s eo ft h ettest has been criticized because it assumes that probabili-
ties are approximately normally distributed, which is not true in general
(Church and Mercer 1993: 20). An alternative test for dependence whichdoes not assume normally distributed probabilities is the 
2test (pro-
nounced ‚Äòchi-square test‚Äô). In the simplest case, the 2test is applied to
2-by-2 tables like table 5.8. The essence of the test is to compare theobserved frequencies in the table with the frequencies expected for inde-pendence. If the diÔ¨Äerence between observed and expected frequencies
is large, then we can reject the null hypothesis of independence.
Table 5.8 shows the distribution of new andcompanies in the refer-
ence corpus that we introduced earlier. Recall that C¬Ñnew¬Ö¬É15;828,
C¬Ñcompanies¬Ö¬É4;675,C¬Ñnew companies ¬Ö¬É8, and that there are
14,307,668 tokens in the corpus. That means that the number of bi-gramsw
iwi¬Ç1with the Ô¨Årst token not being new and the second token
being companies is 4667¬É4675‚àí8. The two cells in the bottom row are
computed in a similar way.
The2statistic sums the diÔ¨Äerences between observed and expected
values in all squares of the table, scaled by the magnitude of the expectedvalues, as follows:
X
2¬ÉX
i;j¬ÑOij‚àíEij¬Ö2
Eij(5.6)
whereiranges over rows of the table, jranges over columns, Oijis the
observed value for cell ¬Ñi;j¬Ö andEijis the expected value.
One can show that the quantity X2is asymptotically 2distributed. In

p/CX /CX170 5 Collocations
other words, if the numbers are large, then X2has a2distribution. We
will return to the issue of how good this approximation is later.
The expected frequencies Eijare computed from the marginal proba-
bilities, that is, from the totals of the rows and columns converted intoproportions. For example, the expected frequency for cell ¬Ñ1;1¬Ö(new
companies ) would be the marginal probability of new occurring as the
Ô¨Årst part of a bigram times the marginal probability of companies occur-
ring as the second part of a bigram (multiplied by the number of bigramsin the corpus):
8¬Ç4667
N8¬Ç15820
NN5:2
That is, if newandcompanies occurred completely independently of each
other we would expect 5 :2 occurrences of new companies on average for
a text of the size of our corpus.
The2test can be applied to tables of any size, but it has a simpler
form for 2-by-2 tables: (see exercise 5.9)
2¬ÉN¬ÑO 11O22‚àíO12O21¬Ö2
¬ÑO11¬ÇO12¬Ö¬ÑO 11¬ÇO21¬Ö¬ÑO 12¬ÇO22¬Ö¬ÑO 21¬ÇO22¬Ö(5.7)
This formula gives the following 2value for table 5.8:
14307668¬Ñ814287181‚àí466715820¬Ö2
¬Ñ8¬Ç4667¬Ö¬Ñ8¬Ç15820¬Ö¬Ñ4667¬Ç14287181¬Ö¬Ñ15820¬Ç14287181¬Ö1:55
Looking up the 2distribution in the appendix, we Ô¨Ånd that at a proba-
bility level of ¬É0:05 the critical value is 2¬É3:841 (the statistic has
one degree of freedom for a 2-by-2 table). So we cannot reject the null
hypothesis that new andcompanies occur independently of each other.
Thus new companies is not a good candidate for a collocation.
This result is the same as we got with the tstatistic. In general, for the
problem of Ô¨Ånding collocations, the diÔ¨Äerences between the tstatistic
and the2statistic do not seem to be large. For example, the 20 bigrams
with the highest tscores in our corpus are also the 20 bigrams with the
highest2scores.
However, the 2test is also appropriate for large probabilities, for
which the normality assumption of the ttest fails. This is perhaps the
reason that the 2test has been applied to a wider range of problems in
collocation discovery.
One of the early uses of the 2test in Statistical NLPwas the identiÔ¨Å-

p/CX /CX5.3 Hypothesis Testing 171
cow:cow
vache 59 6
:vache 8 570934
Table 5.9 Correspondence of vache andcowin an aligned corpus. By applying
the2test to this table one can determine whether vache andcoware transla-
tions of each other.
corpus 1 corpus 2
word 1 60 9
word 2 500 76
word 3 124 20
...
Table 5.10 Testing for the independence of words in diÔ¨Äerent corpora using 2.
This test can be used as a metric for corpus similarity.
cation of translation pairs in aligned corpora (Church and Gale 1991b).5
The data in table 5.9 (from a hypothetical aligned corpus) strongly sug-
gest that vache is the French translation of English cow. Here, 59 is the
number of aligned sentence pairs which have cowin the English sentence
andvache in the French sentence etc. The 2value is very high here:
2¬É456400. So we can reject the null hypothesis that cow andvache
occur independently of each other with high conÔ¨Ådence. This pair is a
good candidate for a translation pair.
An interesting application of 2is as a metric for corpus similarity
(KilgarriÔ¨Ä and Rose 1998). Here we compile an n-by-two table for a large
n, for examplen¬É500. The two columns correspond to the two corpora.
Each row corresponds to a particular word. This is schematically shownin table 5.10. If the ratio of the counts are about the same (as is the casein table 5.10, each word occurs roughly 6 times more often in corpus 1
than in corpus 2), then we cannot reject the null hypothesis that both
corpora are drawn from the same underlying source. We can interpretthis as a high degree of similarity. On the other hand, if the ratios varywildly, then the X
2score will be high and we have evidence for a high
degree of dissimilarity.
5. They actually use a measure they call 2, which isX2multiplied by N. They do this
since they are only interested in ranking translation pairs, so that assessment of signiÔ¨Å-cance is not important.

p/CX /CX172 5 Collocations
H1 H2
P¬Ñw2jw1¬Öp ¬Éc2
Np1¬Éc12
c1
P¬Ñw2j:w1¬Öp ¬Éc2
Np2¬Éc2‚àíc12
N‚àíc1
c12out ofc1bigrams arew1w2b¬Ñc12;c1;p¬Ö b¬Ñc12;c1;p1¬Ö
c2‚àíc12out ofN‚àíc1bigrams are :w1w2b¬Ñc2‚àíc12;N‚àíc1;p¬Ö b¬Ñc2‚àíc12;N‚àíc1;p2¬Ö
Table 5.11 How to compute Dunning‚Äôs likelihood ratio test. For example, the
likelihood of hypothesis H2is the product of the last two lines in the rightmost
column.
Just as application of the ttest is problematic because of the under-
lying normality assumption, so is application of 2in cases where the
numbers in the 2-by-2 table are small. Snedecor and Cochran (1989: 127)advise against using 
2if the total sample size is smaller than 20 or if it
is between 20 and 40 and the expected value in any of the cells is 5 or
less.
5.3.4 Likelihood ratios
Likelihood ratios are another approach to hypothesis testing. We will see
below that they are more appropriate for sparse data than the 2test.
But they also have the advantage that the statistic we are computing, alikelihood ratio , is more interpretable than the X
2statistic. It is simply likelihood ratio
a number that tells us how much more likely one hypothesis is than the
other.
In applying the likelihood ratio test to collocation discovery, we ex-
amine the following two alternative explanations for the occurrence fre-quency of a bigram w
1w2(Dunning 1993):
Hypothesis 1. P¬Ñw2jw1¬Ö¬Ép¬ÉP¬Ñw2j:w1¬Ö
Hypothesis 2. P¬Ñw2jw1¬Ö¬Ép1¬îp2¬ÉP¬Ñw2j:w1¬Ö
Hypothesis 1 is a formalization of independence (the occurrence of w2is
independent of the previous occurrence of w1), Hypothesis 2 is a formal-
ization of dependence which is good evidence for an interesting colloca-
tion.6
6. We assume that p1p2if Hypothesis 2 is true. The case p1p2is rare and we will
ignore it here.

p/CX /CX5.3 Hypothesis Testing 173
We use the usual maximum likelihood estimates for p,p1andp2and
writec1,c2,a n dc12for the number of occurrences of w1,w2andw1w2
in the corpus:
p¬Éc2
Np1¬Éc12
c1p2¬Éc2‚àíc12
N‚àíc1(5.8)
Assuming a binomial distribution:
b¬Ñk;n;x¬Ö¬É 
n
k!
xk¬Ñ1‚àíx¬Ö¬Ñn‚àík¬Ö(5.9)
the likelihood of getting the counts for w1,w2andw1w2that we actually
observed is then L¬ÑH 1¬Ö¬Éb¬Ñc12;c1;p¬Öb¬Ñc2‚àíc12;N‚àíc1;p¬Öfor Hypothe-
sis 1 andL¬ÑH 2¬Ö¬Éb¬Ñc12;c1;p1¬Öb¬Ñc2‚àíc12;N‚àíc1;p2¬Öfor Hypothesis 2. Ta-
ble 5.11 summarizes this discussion. One obtains the likelihoods L¬ÑH 1¬Ö
andL¬ÑH 2¬Öjust given by multiplying the last two lines, the likelihoods of
the speciÔ¨Åed number of occurrences of w1w2and:w1w2, respectively.
The log of the likelihood ratio is then as follows:
log¬ÉlogL¬ÑH 1¬Ö
L¬ÑH 2¬Ö(5.10)
¬Élogb¬Ñc12;c1;p¬Öb¬Ñc 2‚àíc12;N‚àíc1;p¬Ö
b¬Ñc12;c1;p1¬Öb¬Ñc 2‚àíc12;N‚àíc1;p2¬Ö
¬ÉlogL¬Ñc12;c1;p¬Ö¬ÇlogL¬Ñc2‚àíc12;N‚àíc1;p¬Ö
‚àílogL¬Ñc12;c1;p1¬Ö‚àílogL¬Ñc2‚àíc12;N‚àíc1;p2¬Ö
whereL¬Ñk;n;x¬Ö¬Éxk¬Ñ1‚àíx¬Ön‚àík.
Table 5.12 shows the twenty bigrams of powerful which are highest
ranked according to the likelihood ratio when the test is applied to theNew York Times corpus. We will explain below why we show the quantity
‚àí2l o ginstead of. We consider all occurring bigrams here, including
rare ones that occur less than six times, since this test works well forrare bigrams. For example, powerful cudgels , which occurs 2 times, is
identiÔ¨Åed as a possible collocation.
One advantage of likelihood ratios is that they have a clear intuitive in-
terpretation. For example, the bigram powerful computers ise
0:582:96
1:31018times more likely under the hypothesis that computers is more
likely to follow powerful than its base rate of occurrence would suggest.
This number is easier to interpret than the scores of the ttest or the
2test which we have to look up in a table.

p/CX /CX174 5 Collocations
‚àí2l o gC ¬Ñ w1¬ÖC ¬Ñ w2¬ÖC ¬Ñ w1w2¬Öw1w2
1291.42 12593 932 150 most powerful
99.31 379 932 10 politically powerful
82.96 932 934 10 powerful computers
80.39 932 3424 13 powerful force57.27 932 291 6 powerful symbol51.66 932 40 4 powerful lobbies51.52 171 932 5 economically powerful51.05 932 43 4 powerful magnet50.83 4458 932 10 less powerful
50.75 6252 932 11 very powerful
49.36 932 2064 8 powerful position48.78 932 591 6 powerful machines47.42 932 2339 8 powerful computer43.23 932 16 3 powerful magnets43.10 932 396 5 powerful chip40.45 932 3694 8 powerful men
36.36 932 47 3 powerful 486
36.15 932 268 4 powerful neighbor35.24 932 5245 8 powerful political34.15 932 3 2 powerful cudgels
Table 5.12 Bigrams of powerful with the highest scores according to Dunning‚Äôs
likelihood ratio test.
But the likelihood ratio test also has the advantage that it can be more
appropriate for sparse data than the 2test. How do we use the likeli-
hood ratio for hypothesis testing? If is a likelihood ratio of a particular
form, then the quantity ‚àí2l o gis asymptotically 2distributed (Mood
et al. 1974: 440). So we can use the values in table 5.12 to test the nullhypothesisH
1against the alternative hypothesis H2. For example, we can
look up the value of 34 :15 for powerful cudgels in the table and reject H1
for this bigram on a conÔ¨Ådence level of ¬É0:005. (The critical value (for
one degree of freedom) is 7.88. See the table of the 2distribution in the
appendix.)
The particular form of the likelihood ratio that is required here is that
of a ratio between the maximum likelihood estimate over a subpart ofthe parameter space and the maximum likelihood estimate over the en-

p/CX /CX5.3 Hypothesis Testing 175
tire parameter space. For the likelihood ratio in (5.11), the entire space
is the space of pairs ¬Ñp1;p2¬Öfor the probability of w2occurring when w1
preceded (p1)a n dw2occurring when a diÔ¨Äerent word preceded ( p2). We
get the maximum likelihood for the data we observed if we assume themaximum likelihood estimates that we computed in (5.8). The subspace
is the subset of cases for which p
1¬Ép2. Again, the estimate in (5.8)
gives us the maximum likelihood over the subspace given the data we ob-served. It can be shown that if is a ratio of two likelihoods of this type
(one being the maximum likelihood over the subspace, the other over theentire space), then ‚àí2l o gis asymptotically 
2distributed. ‚ÄòAsymptot-
ically‚Äô roughly means ‚Äòif the numbers are large enough‚Äô. Whether or notthe numbers are large enough in a particular case is hard to determine,
but Dunning has shown that for small counts the approximation to 
2
is better for the likelihood ratio in (5.11) than, for example, for the X2
statistic in (5.6). Therefore, the likelihood ratio test is in general more
appropriate than Pearson‚Äôs 2test for collocation discovery.7
Relative frequency ratios. So far we have looked at evidence for collo-
cations within one corpus. Ratios of relative frequencies between two or relative
frequencies more diÔ¨Äerent corpora can be used to discover collocations that are char-
acteristic of a corpus when compared to other corpora (Damerau 1993).
Although ratios of relative frequencies do not Ô¨Åt well into the hypothe-
sis testing paradigm, we treat them here since they can be interpreted aslikelihood ratios.
Table 5.13 shows ten bigrams that occur exactly twice in our reference
corpus (the 1990 New York Times corpus). The bigrams are ranked ac-
cording to the ratio of their relative frequencies in our 1990 reference
corpus versus their frequencies in a 1989 corpus (again drawn from the
months August through November). For example, Karim Obeid occurs 68
times in the 1989 corpus. So the relative frequency ratio ris:
r¬É 2
14307668
68
117315640:024116
The bigrams in table 5.13 are mostly associated with news items that
were more prevalent in 1989 than in 1990: The Muslim cleric Sheik Abdul
7. However, even ‚àí2l o gis not approximated well by 2if the expected values in the
2-by-2 contingency table are less than 1.0 (Read and Cressie 1988; Pedersen 1996).

pa/CX /CX176 5 Collocations
Ratio 1990 1989 w1w2
0.0241 2 68 Karim Obeid
0.0372 2 44 East Berliners
0.0372 2 44 Miss Manners
0.0399 2 41 17 earthquake0.0409 2 40 HUD oÔ¨Écials0.0482 2 34 EAST GERMANS0.0496 2 33 Muslim cleric0.0496 2 33 John Le0.0512 2 32 Prague Spring
0.0529 2 31 Among individual
Table 5.13 Damerau‚Äôs frequency ratio test. Ten bigrams that occurred twice
in the 1990 New York Times corpus, ranked according to the (inverted) ratio of
relative frequencies in 1989 and 1990.
Karim Obeid (who was abducted in 1989), the disintegration of commu-
nist Eastern Europe ( East Berliners ,EAST GERMANS ,Prague Spring ), the
novel The Russia House byJohn Le Carre , a scandal in the Department of
Housing and Urban Development ( HUD), and the October 17 earthquake
in the San Francisco Bay Area. But we also Ô¨Ånd artefacts like Miss Manners
(whose column the New York Times newswire stopped carrying in 1990)
andAmong individual . The reporter Phillip H. Wiggins liked to use the
latter phrase for his stock market reports ( Among individual Big Board
issues . . . ), but he stopped writing for the Times in 1990.
The examples show that frequency ratios are mainly useful to Ô¨Ånd
subject-speciÔ¨Åc collocations. The application proposed by Damerau is to
compare a general text with a subject-speciÔ¨Åc text. Those words andphrases that on a relative basis occur most often in the subject-speciÔ¨Åctext are likely to be part of the vocabulary that is speciÔ¨Åc to the domain.
Exercise 5.4 [¬´¬´]
Identify the most signiÔ¨Åcantly non-independent bigrams according to the ttest
in a corpus of your choice.
Exercise 5.5 [¬´]
It is a coincidence that the tvalue for new companies is close to 1.0. Show this by
computing the tvalue of new companies for a corpus with the following counts.
C¬Ñnew¬Ö¬É30;000,C¬Ñcompanies¬Ö¬É9;000,C¬Ñnew companies ¬Ö¬É20, and corpus
sizeN¬É15;000;000.

p/CX /CX5.3 Hypothesis Testing 177
Exercise 5.6 [¬´]
We can improve on the method in section 5.2 by taking into account variance. In
fact, Smadja does this and the algorithm described in (Smadja 1993) thereforebears some similarity to the ttest.
Compute thetstatistic in equation (5.3) for possible collocations by substituting
mean and variance as computed in section 5.2 for ¬Øxands
2and (a) assuming
¬É0, and (b) assuming ¬Éround¬Ñ¬Øx¬Ö, that is, the closest integer. Note that we
are not testing for bigrams here, but for collocations of word pairs that occur atany Ô¨Åxed small distance.
Exercise 5.7 [¬´¬´]
As we pointed out above, almost all bigrams occur signiÔ¨Åcantly more often than
chance if a stop list is used for preÔ¨Åltering. Verify that there is a large proportionof bigrams that occur less often than chance if we do not Ô¨Ålter out functionwords.
Exercise 5.8 [¬´¬´]
Apply thettest of diÔ¨Äerences to a corpus of your choice. Work with the follow-
ing word pairs or with word pairs that are appropriate for your corpus: man /
woman ,blue /green ,lawyer /doctor .
Exercise 5.9 [¬´]
Derive equation (5.7) from equation (5.6).
Exercise 5.10 [¬´¬´]
Find terms that distinguish best between the Ô¨Årst and second part of a corpus
of your choice.
Exercise 5.11 [¬´¬´]
Repeat the above exercise with random selection. Now you should Ô¨Ånd that
fewer terms are signiÔ¨Åcant. But some still are. Why? Shouldn‚Äôt there be nodiÔ¨Äerences between corpora drawn from the same source? Do this exercise fordiÔ¨Äerent signiÔ¨Åcance levels.
Exercise 5.12 [¬´¬´]
Compute a measure of corpus similarity between two corpora of your choice.
Exercise 5.13 [¬´¬´]
KilgarriÔ¨Ä and Rose‚Äôs corpus similarity measure can also be used for assessing
corpus homogeneity. This is done by constructing a series of random divisionsof the corpus into a pair of subcorpora. The test is then applied to each pair. If
most of the tests indicated similarity, then it is a homogeneous corpus. Apply
this test to a corpus of your choice.

p/CX /CX178 5 Collocations
I¬Ñw1;w2¬ÖC ¬Ñ w1¬ÖC ¬Ñ w2¬ÖC ¬Ñ w1w2¬Öw1w2
18.38 42 20 20 Ayatollah Ruhollah
17.98 41 27 20 Bette Midler
16.31 30 117 20 Agatha Christie
15.94 77 59 20 videocassette recorder
15.19 24 320 20 unsalted butter
1.09 14907 9017 20 Ô¨Årst made
1.01 13484 10570 20 over many
0.53 14734 13478 20 into them
0.46 14093 14776 20 like people
0.29 15019 15629 20 time last
Table 5.14 Finding collocations: Ten bigrams that occur with frequency 20,
ranked according to mutual information.
5.4 Mutual Information
An information-theoretically motivated measure for discovering inter-
esting collocations is pointwise mutual information (Church et al. 1991; pointwise mutual
information Church and Hanks 1989; Hindle 1990). Fano (1961: 27‚Äì28) originally de-
Ô¨Åned mutual information between particular events x0andy0,i no u rc a s e
the occurrence of particular words, as follows:
I¬Ñx0;y0¬Ö¬Élog2P¬Ñx0y0¬Ö
P¬Ñx0¬ÖP¬Ñy0¬Ö(5.11)
¬Élog2P¬Ñx0jy0¬Ö
P¬Ñx0¬Ö(5.12)
¬Élog2P¬Ñy0jx0¬Ö
P¬Ñy0¬Ö(5.13)
This type of mutual information, which we introduced in section 2.2.3,
is roughly a measure of how much one word tells us about the other, anotion that we will make more precise shortly.
In information theory, mutual information is more often deÔ¨Åned as
holding between random variables ,n o t values of random variables as we
have deÔ¨Åned it here (see the standard deÔ¨Ånition in section 2.2.3). We willsee below that these two types of mutual information are quite diÔ¨Äerentcreatures.
When we apply this deÔ¨Ånition to the 10 collocations from table 5.6, we

p/CX /CX5.4 Mutual Information 179
chambre:chambre
house 31,950 12,004
:house 4793 848,330MI
4.12
553610
communes :communes
house 4974 38,980
:house 441 852,682 4.2 88405
Table 5.15 Correspondence of chambre andhouse andcommunes andhouse
in the aligned Hansard corpus. Mutual information gives a higher score to ( com-
munes ,house ), while the2test gives a higher score to the correct translation
pair ( chambre ,house ).
get the same ranking as with the ttest (see table 5.14). As usual, we use
maximum likelihood estimates to compute the probabilities, for example:
I¬ÑAyatollah;Ruhollah¬Ö¬Élog220
14307668
42
1430766820
1430766818:38
So what exactly is (pointwise) mutual information, I¬Ñx0;y0¬Ö, a measure of?
Fano writes about deÔ¨Ånition (5.12):
The amount of information provided by the occurrence of the event
represented by [ y0] about the occurrence of the event represented
by [x0] is deÔ¨Åned as [(5.12)].
For example, the mutual information measure tells us that the amount
of information we have about the occurrence of Ayatollah at positioniin
the corpus increases by 18.38 bits if we are told that Ruhollah occurs at
positioni¬Ç1. Or, since (5.12) and (5.13) are equivalent, it also tells us
that the amount of information we have about the occurrence of Ruhollah
at positioni¬Ç1 in the corpus increases by 18.38 bits if we are told that
Ayatollah occurs at position i. We could also say that our uncertainty is
reduced by 18.38 bits. In other words, we can be much more certain thatRuhollah will occur next if we are told that Ayatollah is the current word.
Unfortunately, this measure of ‚Äòincreased information‚Äô is in many cases
not a good measure of what an interesting correspondence between twoevents is, as has been pointed out by many authors. (We base our dis-cussion here mainly on (Church and Gale 1991b) and (Maxwell 1992).)Consider the two examples in table 5.15 of counts of word correspon-dences between French and English sentences in the Hansard corpus, an

p/CX /CX180 5 Collocations
aligned corpus of debates of the Canadian parliament (the table is simi-
lar to table 5.9). The reason that house frequently appears in translations
of French sentences containing chambre andcommunes is that the most
common use of house in the Hansard is the phrase House of Commons
which corresponds to Chambre de communes in French. But it is easy
to see that communes is a worse match for house than chambre since
most occurrences of house occur without communes on the French side.
As shown in the table, the 2test is able to infer the correct correspon-
dence whereas mutual information gives preference to the incorrect pair(communes ,house ).
We can explain the diÔ¨Äerence between the two measures easily if we
look at deÔ¨Ånition (5.12) of mutual information and compare the quanti-
tiesI¬Ñchambre;house¬ÖandI¬Ñcommunes;house¬Ö:
logP¬Ñhousejchambre¬Ö
P¬Ñhouse¬Ö¬Élog31950
31950¬Ç4793
P¬Ñhouse¬Ölog0:87
P¬Ñhouse¬Ö
<log0:92
P¬Ñhouse¬Ölog4974
4974¬Ç441
P¬Ñhouse¬Ö¬ÉlogP¬Ñhousejcommunes¬Ö
P¬Ñhouse¬Ö
The word communes in the French makes it more likely that house oc-
curred in the English than chambre does. The higher mutual information
value for communes reÔ¨Çects the fact that communes causes a larger de-
crease in uncertainty here. But as the example shows decrease in uncer-tainty does not correspond well to what we want to measure. In contrast,the
2is a direct test of probabilistic dependence, which in this context
we can interpret as the degree of association between two words andhence as a measure of their quality as translation pairs and collocations.
Table 5.16 shows a second problem with using mutual information for
Ô¨Ånding collocations. We show ten bigrams that occur exactly once inthe Ô¨Årst 1000 documents of the reference corpus and their mutual infor-mation score based on the 1000 documents. The right half of the tableshows the mutual information score based on the entire reference corpus(about 23,000 documents).
The larger corpus of 23,000 documents makes some better estimates
possible, which in turn leads to a slightly better ranking. The bigrams
marijuana growing andnew converts (arguably collocations) have moved
up and Reds survived (deÔ¨Ånitely not a collocation) has moved down. How-
ever, what is striking is that even after going to a 10 times larger corpus6 of the bigrams still only occur once and, as a consequence, have in-accurate maximum likelihood estimates and artiÔ¨Åcially inÔ¨Çated mutual

p/CX /CX5.4 Mutual Information 181
I1000w1w2w1w2Bigram I23000w1w2w1w2Bigram
16.95 5 1 1 Schwartz eschews 14.46 106 6 1 Schwartz eschews
15.02 1 19 1 fewest visits 13.06 76 22 1 FIND GARDEN
13.78 5 9 1 FIND GARDEN 11.25 22 267 1 fewest visits
12.00 5 31 1 Indonesian pieces 8.97 43 663 1 Indonesian pieces
9.82 26 27 1 Reds survived 8.04 170 1917 6 marijuana growing
9.21 13 82 1 marijuana growing 5.73 15828 51 3 new converts
7.37 24 159 1 doubt whether 5.26 680 3846 7 doubt whether
6.68 687 9 1 new converts 4.76 739 713 1 Reds survived
6.00 661 15 1 like oÔ¨Äensive 1.95 3549 6276 6 must think
3.81 159 283 1 must think 0.41 14093 762 1 like oÔ¨Äensive
Table 5.16 Problems for Mutual Information from data sparseness. The table
shows ten bigrams that occurred once in the Ô¨Årst 1000 documents in the ref-erence corpus ranked according to mutual information score in the Ô¨Årst 1000documents (left half of the table) and ranked according to mutual informationscore in the entire corpus (right half of the table). These examples illustrate thata large proportion of bigrams are not well characterized by corpus data (even forlarge corpora) and that mutual information is particularly sensitive to estimates
that are inaccurate due to sparseness.
information scores. All 6 are not collocations and we would prefer a
measure which ranks them accordingly.
None of the measures we have seen works very well for low-frequency
events. But there is evidence that sparseness is a particularly diÔ¨Écultproblem for mutual information. To see why, notice that mutual infor-mation is a log likelihood ratio of the probability of the bigram P¬Ñw
1w2¬Ö
and the product of the probabilities of the individual words P¬Ñw1¬ÖP¬Ñw2¬Ö.
Consider two extreme cases: perfect dependence of the occurrences of
the two words (they only occur together) and perfect independence (the
occurrence of one does not give us any information about the occurrenceof the other). For perfect dependence we have:
I¬Ñx;y¬Ö¬ÉlogP¬Ñxy¬Ö
P¬Ñx¬ÖP¬Ñy¬Ö¬ÉlogP¬Ñx¬Ö
P¬Ñx¬ÖP¬Ñy¬Ö¬Élog1
P¬Ñy¬Ö
That is, among perfectly dependent bigrams, as they get rarer, their mu-
tual information increases .
For perfect independence we have:
I¬Ñx;y¬Ö¬ÉlogP¬Ñxy¬Ö
P¬Ñx¬ÖP¬Ñy¬Ö¬ÉlogP¬Ñx¬ÖP¬Ñy¬Ö
P¬Ñx¬ÖP¬Ñy¬Ö¬Élog 1¬É0

p/CX /CX182 5 Collocations
Symbol DeÔ¨Ånition Current use Fano
I¬Ñx;y¬Ö logp¬Ñx;y¬Ö
p¬Ñx¬Öp¬Ñy¬Öpointwise mutual information mutual information
I¬ÑX;Y¬Ö E logp¬ÑX;Y¬Ö
p¬ÑX¬Öp¬ÑY¬Ömutual information average MI/expectation of MI
Table 5.17 DiÔ¨Äerent deÔ¨Ånitions of mutual information in (Cover and Thomas
1991) and (Fano 1961).
We can say that mutual information is a good measure of independence.
Values close to 0 indicate independence (independent of frequency). Butit is a bad measure of dependence because for dependence the scoredepends on the frequency of the individual words. Other things being
equal, bigrams composed of low-frequency words will receive a higher
score than bigrams composed of high-frequency words. That is the oppo-site of what we would want a good measure to do since higher frequencymeans more evidence and we would prefer a higher rank for bigrams forwhose interestingness we have more evidence. One solution that has beenproposed for this is to use a cutoÔ¨Ä and to only look at words with a fre-quency of at least 3. However, such a move does not solve the underlying
problem, but only ameliorates its eÔ¨Äects.
Since pointwise mutual information does not capture the intuitive no-
tion of an interesting collocation very well, it is often not used when it ismade available in practical applications (Fontenelle et al. 1994: 81) or it isredeÔ¨Åned asC¬Ñw
1w2¬ÖI¬Ñw1;w2¬Öto compensate for the bias of the origi-
nal deÔ¨Ånition in favor of low-frequency events (Fontenelle et al. 1994: 72,
Hodges et al. 1996).
As we mentioned earlier, the deÔ¨Ånition of mutual information used
here is common in corpus linguistic studies, but is less common in Infor-mation Theory. Mutual information in Information Theory refers to theexpectation of the quantity that we have used in this section:
expectation
I¬ÑX;Y¬Ö¬ÉEp¬Ñx;y¬Ölogp¬ÑX;Y¬Ö
p¬ÑX¬Öp¬ÑY¬Ö
The deÔ¨Ånition we have used in this chapter is an older one, termed point-
wise mutual information (see section 2.2.3, Fano 1961: 28, and Gallager1968). Table 5.17 summarizes the older and newer naming conventions.One quantity is the expectation of the other, so the two types of mutualinformation are quite diÔ¨Äerent.
The example of mutual information demonstrates what should be self-

p/CX /CX5.5 The Notion of Collocation 183
evident: it is important to check what a mathematical concept is a for-
malization of. The notion of pointwise mutual information that we have
used here(
logp¬Ñw1w2¬Ö
p¬Ñw1¬Öp¬Ñw2¬Ö
measures the reduction of uncertainty about
the occurrence of one word when we are told about the occurrence of theother. As we have seen, such a measure is of limited utility for acquiring
the types of linguistic properties we have looked at in this section.
Exercise 5.14 [¬´¬´]
Justeson and Katz‚Äôs part-of-speech Ô¨Ålter in section 5.1 can be applied to any of
the other methods of collocation discovery in this chapter. Pick one and modify
it to incorporate a part-of-speech Ô¨Ålter. What advantages does the modiÔ¨Åed
method have?
Exercise 5.15 [¬´¬´¬´ ]
Design and implement a collocation discovery tool for a translator‚Äôs workbench.
Pick either one method or a combination of methods that the translator canchoose from.
Exercise 5.16 [¬´¬´¬´ ]
Design and implement a collocation discovery tool for a lexicographer‚Äôs work-
bench. Pick either one method or a combination of methods that the lexicogra-pher can choose from.
Exercise 5.17 [¬´¬´¬´ ]
Many news services tag references to companies in their news stories. For ex-
ample, all references to the General Electric Company would be tagged with the
same tag regardless of which variant of the name is used (e.g., GE,General Elec-
tric,o rGeneral Electric Company ). Design and implement a collocation discovery
tool for Ô¨Ånding company names. How could one partially automate the processof identifying variants?
5.5 The Notion of Collocation
The notion of collocation may be confusing to readers without a back-
ground in linguistics. We will devote this section to discussing in moredetail what a collocation is.
There are actually diÔ¨Äerent deÔ¨Ånitions of the notion of collocation.
Some authors in the computational and statistical literature deÔ¨Åne a col-
location as two or more consecutive words with a special behavior, for
example Choueka (1988):
[A collocation is deÔ¨Åned as] a sequence of two or more consecutive
words, that has characteristics of a syntactic and semantic unit,

p/CX /CX184 5 Collocations
and whose exact and unambiguous meaning or connotation cannot
be derived directly from the meaning or connotation of its compo-nents.
Most of the examples we have presented in this chapter also assumed
adjacency of words. But in most linguistically oriented research, a phrasecan be a collocation even if it is not consecutive (as in the example knock
. . . door ). The following criteria are typical of linguistic treatments of
collocations (see for example Benson (1989) and Brundage et al. (1992)),
non-compositionality being the main one we have relied on here.
Non-compositionality. The meaning of a collocation is not a straight-
forward composition of the meanings of its parts. Either the meaningis completely diÔ¨Äerent from the free combination (as in the case of id-ioms like kick the bucket ) or there is a connotation or added element of
meaning that cannot be predicted from the parts. For example, white
wine,white hair andwhite woman all refer to slightly diÔ¨Äerent colors,
so we can regard them as collocations.
Non-substitutability. We cannot substitute other words for for the
components of a collocation even if, in context, they have the samemeaning. For example, we can‚Äôt say yellow wine instead of white wine
even though yellow is as good a description of the color of white wine
aswhite is (it is kind of a yellowish white).
Non-modiÔ¨Åability. Many collocations cannot be freely modiÔ¨Åed with
additional lexical material or through grammatical transformations.
This is especially true for frozen expressions like idioms. For example,
we can‚Äôt modify frog into get a frog in one‚Äôs throat intoto get an ugly
frog in one‚Äôs throat although usually nouns like frog can be modiÔ¨Åed
by adjectives like ugly. Similarly, going from singular to plural can
make an idiom ill-formed, for example in people as poor as church
mice.
A nice way to test whether a combination is a collocation is to translate
it into another language. If we cannot translate the combination word by
word, then that is evidence that we are dealing with a collocation. Forexample, translating make a decision into French one word at a time we
getfaire une d√©cision which is incorrect. In French we have to say prendre
une d√©cision . So that is evidence that make a decision is a collocation in
English.

p/CX /CX5.5 The Notion of Collocation 185
strength power
to build up ~ to assume ~
to Ô¨Ånd ~ emergency ~
to save ~ discretionary ~
to sap somebody‚Äôs ~ ~ over [several provinces]
brute ~ supernatural ~
tensile ~ to turn oÔ¨Ä the ~
t h e~t o[ d oX ] the ~ to [do X]
¬Üour staÔ¨Ä was¬áat full ~ the balance of ~
on the ~ of [your recommendation] Ô¨Åre ~
Table 5.18 Collocations in the BBICombinatory Dictionary of English for the
words strength andpower .
Some authors have generalized the notion of collocation even further
and included cases of words that are strongly associated with each other,
but do not necessarily occur in a common grammatical unit and with a
particular order, cases like doctor ‚Äìnurse orplane ‚Äìairport . It is prob-
ably best to restrict collocations to the narrower sense of grammaticallybound elements that occur in a particular order and use the terms associ-
association
ation andco-occurrence for the more general phenomenon of words that co-occurrence
are likely to be used in the same context.
It is instructive to look at the types of collocations that a purely lin-
guistic analysis of text will discover if plenty of time and person power
is available so that the limitations of statistical analysis and computertechnology need be of no concern. An example of such a purely linguisticanalysis is the
BBICombinatory Dictionary of English (Benson et al. 1993).
In table 5.18, we show some of the collocations (or combinations as thedictionary prefers to call them) of strength andpower that the diction-
ary lists.
8We can see immediately that a wider variety of grammatical
patterns is considered here (in particular patterns involving prepositions
and particles). Naturally, the quality of the collocations is also higherthan computer-generated lists ‚Äì as we would expect from a manuallyproduced compilation.
We conclude our discussion of the concept of collocation by going
through some subclasses of collocations that deserve special mention.
8. We cannot show collocations of strong andpowerful because these adjectives are not
listed as entries in the dictionary.

p/CX /CX186 5 Collocations
Verbs with little semantic content like make ,take anddoare called light light verbs
verbs in collocations like make a decision ordo a favor . There is hardly
anything about the meaning of make ,take ordothat would explain why
we have to say make a decision instead of take a decision anddo a fa-
vorinstead of make a favor , but for many computational purposes the
correct light verb for combination with a particular noun must be deter-
mined and thus acquired from corpora if this information is not availablein machine-readable dictionaries. Dras and Johnson (1996) examine oneapproach to this problem.
Verb particle constructions orphrasal verbs are an especially important
verb particle
constructions
phrasal verbspart of the lexicon of English. Many verbs in English like to tell oÔ¨Ä and
to go down consist of a combination of a main verb and a particle. These
verbs often correspond to a single lexeme in other languages ( r√©priman-
der,descendre in French). This type of construction is a good example of
a collocation with often non-adjacent words.
Proper nouns (also called proper names ) are usually included in the proper names
category of collocations in computational work although they are quite
diÔ¨Äerent from lexical collocations. They are most amenable to ap-proaches that look for Ô¨Åxed phrases that reappear in exactly the same
form throughout a text.
Terminological expressions or phrases refer to concepts and objects in
terminological
expressions technical domains. Although they are often fairly compositional (e.g., hy-
draulic oil Ô¨Ålter ), it is still important to identify them to make sure that
they are treated consistently throughout a technical text. For example,when translating a manual, we have to make sure that all instances ofhydraulic oil Ô¨Ålter are translated by the same term. If two diÔ¨Äerent trans-
lations are used (even if they have the same meaning in some sense), the
reader of the translated manual could get confused and think that twodiÔ¨Äerent entities are being described.
As a Ô¨Ånal example of the wide range of phenomena that the term col-
location is applied to, let us point to the many diÔ¨Äerent degrees of in-variability that a collocation can show. At one extreme of the spectrumwe have usage notes in dictionaries that describe subtle diÔ¨Äerences in us-
age between near-synonyms like answer andreply (diplomatic answer vs.
stinging reply ). This type of collocation is important for generating text
that sounds natural, but getting a collocation wrong here is less likelyto lead to a fatal error. The other extreme are completely frozen ex-pressions like proper names and idioms. Here there is just one way ofsaying things and any deviation will completely change the meaning of

p/CX /CX5.6 Further Reading 187
what is said. Luckily, the less compositional and the more important a
collocation, the easier it is to acquire it automatically.
5.6 Further Reading
See (Stubbs 1996) for an in-depth discussion of the British tradition of‚Äòempiricist‚Äô linguistics.
Thettest is covered in most general statistics books. Standard ref-
erences are (Snedecor and Cochran 1989: 53) and (Moore and McCabe1989: 541). Weinberg and Goldberg (1990: 306) and Ramsey and Schafer(1997) are more accessible for students with less mathematical back-
ground. These books also cover the 
2test, but not some of the other
more specialized tests that we discuss here.
One of the Ô¨Årst publications on the discovery of collocations was
(Church and Hanks 1989), later expanded to (Church et al. 1991). The au-thors drew attention to an emerging type of corpus-based dictionary (Sin-clair 1995) and developed a program of computational lexicography thatcombines corpus evidence, computational methods and human judge-
ment to build more comprehensive dictionaries that better reÔ¨Çect actual
language use.
There are a number of ways lexicographers can beneÔ¨Åt from automated
processing of corpus data. A lexicographer writes a dictionary entry afterlooking at a potentially large number of examples of a word. If the ex-amples are automatically presorted according to collocations and othercriteria (for example, the topic of the text), then this process can be made
much more eÔ¨Écient. For example, phrasal verbs are sometimes neglected
in dictionaries because they are not separate words. A corpus-based ap-proach will make their importance evident to the lexicographer. In addi-tion, a balanced corpus will reveal which of the uses are most frequentand hence most important for the likely user of a dictionary. DiÔ¨Äerencetests like thettest are useful for writing usage notes and for writing ac-
curate deÔ¨Ånitions that reÔ¨Çect diÔ¨Äerences in usage between words. Some
of these techniques are being used for the next generation of dictionaries
(Fontenelle et al. 1994).
Eventually, a new form of dictionary could emerge from this work,
a kind of dictionary-cum-corpus in which dictionary entry and corpusevidence support each other and are organized in a coherent whole. The
COBUILD dictionary already has some of these characteristics (Sinclair

p/CX /CX188 5 Collocations
1995). Since space is less of an issue with electronic dictionaries plenty
of corpus examples can be integrated into a dictionary entry for the in-terested user.
What we have said about the value of statistical corpus analysis for
monolingual dictionaries applies equally to bilingual dictionaries, at least
if an aligned corpus is available (Smadja et al. 1996).
Another important application of collocations is Information Retrieval
(IR). Accuracy of retrieval can be improved if the similarity between auser query and a document is determined based on common collocations(or phrases) instead of common words (Fagan 1989; Evans et al. 1991;Strzalkowski 1995; Mitra et al. 1997). See Lewis and Jones (1996) andKrovetz (1991) for further discussion of the question of using colloca-
tion discovery and
NLPin Information Retrieval and Nevill-Manning et al.
(1997) for an alternative non-statistical approach to using phrases in IR.Steier and Belew (1993) present an interesting study of how the treat-ment of phrases (for example, for phrase weighting) should change aswe move from a subdomain to a general domain. For example, invasive
procedure is completely compositional and a less interesting collocation
in the subdomain of medical articles, but becomes interesting and non-
compositional when ‚Äòexported‚Äô to a general collection that is a mixture of
many specialized domains.
Two other important applications of collocations, which we will just
mention, are natural language generation (Smadja 1993) and cross-language information retrieval (Hull and Grefenstette 1998).
An important area that we haven‚Äôt been able to cover is the discovery
of proper nouns, which can be regarded as a kind of collocation. Proper
nouns cannot be exhaustively covered in dictionaries since new people,
places, and other entities come into existence and are named all thetime. Proper nouns also present their own set of challenges: co-reference(How can we tell that
IBMand International Bureau Machines refer to the
same entity?), disambiguation (When does AMEX refer to the American Ex-
change, when to American Express?), and classiÔ¨Åcation (Is this new entitythat the text refers to the name of a person, a location or a company?).
One of the earliest studies on this topic is (Coates-Stephens 1993). Mc-
Donald (1995) focuses on lexicosemantic patterns that can be used ascues for proper noun detection and classiÔ¨Åcation. Mani and MacMillan(1995) and Paik et al. (1995) propose ways of classifying proper nounsaccording to type.
One frequently used measure for interestingness of collocations that

p/CX /CX5.6 Further Reading 189
we did not cover is the zscore , a close relative of the ttest. It is used in zscore
several software packages and workbenches for text analysis (Fontenelle
et al. 1994; Hawthorne 1994). The zscore should only be applied when
the variance is known, which arguably is not the case in most Statistical
NLPapplications.
Fisher‚Äôs exact test is another statistical test that can be used for judging
how unexpected a set of observations is. In contrast to the ttest and the
2test, it is appropriate even for very small counts. However, it is hard
to compute, and it is not clear whether the results obtained in practiceare much diÔ¨Äerent from, for example, the 
2test (Pedersen 1996).
Yet another approach to discovering collocations is to search for points
in the word stream with either low or high uncertainty as to what the next
(or previous) word will be. Points with high uncertainty are likely to be
phrase boundaries, which in turn are candidates for points where a col-location may start or end, whereas points with low uncertainty are likelyto be located within a collocation. See (Evans and Zhai 1996) and (Shimo-hata et al. 1997) for two approaches that use this type of information forÔ¨Ånding phrases and collocations.



