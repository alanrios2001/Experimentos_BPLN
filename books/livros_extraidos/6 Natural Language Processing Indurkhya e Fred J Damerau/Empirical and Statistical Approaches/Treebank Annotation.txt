8
Treebank Annotation
Eva Haji ˇcová
CharlesUniversity
Anne Abeillé
UniversitéParis7andCNRS
Jan Haji ˇc
CharlesUniversity
Jiˇrí Mírovský
CharlesUniversity
Zdeˇnka Urešová
CharlesUniversity8.1 Introduction ..........................................................1678.2 CorpusAnnotationTypes...........................................1688.3 MorphosyntacticAnnotation.......................................1698.4 Treebanks:Syntactic,Semantic,andDiscourseAnnotation ....169
MotivationandDeﬁnition •AnExample:ThePennTreebank •
AnnotationandLinguisticTheory •GoingBeyondtheSurfaceShapeof
theSentence
8.5 TheProcessofBuildingTreebanks ................................1768.6 ApplicationsofTreebanks ..........................................1778.7 SearchingTreebanks.................................................1808.8 Conclusions...........................................................181Acknowledgments ..........................................................182References....................................................................182
8.1 Introduction
Corpus annotation, whether lexical, morphological, syntactic, semantic, or any other, brings additionallinguistic information as an added value to a corpus. The annotation scenario might diﬀer considerablyamong corpora, but it is always based on some formalism that represents the desired level and area oflinguistic interpretation of the corpus. From the simple annotation of part-of-speech categories to theshallowsyntacticannotationtosemanticrolelabelingtothe“deep,”complexannotationofsemanticanddiscourse relations, there is usually some more or less sound linguistic theory behind the design of therepresentationused,oratleastcertainprinciplescommontoseveralsuchtheories.
Corpora have become popular resources for computationally minded linguists and computer science
expertsdevelopingapplicationsinNaturalLanguageProcessing(NLP).Linguiststypicallylookforvariousoccurrences of speciﬁc words or patterns to ﬁnd examples or counterexamples within the theories theybuildorworkwith,lexicographersusecorporaforcreatingdictionaryentriesbylookingforevidenceofuseofwordsinvarioussensesandcontexts,computationallinguiststogetherwithcomputerscientistsandstatisticians construct language models and build part-of-speech taggers, syntactic parsers and varioussemanticlabelerstobeusedinapplications,suchasmachinetranslation,informationretrieval,informa-tionextraction,questionansweringandsummarizationsystems,dialoguesystemsandmanymore.Often,annotatedcorporawerebuiltbylinguistswhowantedtoconfronttheirtheorywithreal-worldtexts.
Most of the work on annotated corpora concerns the domain of written texts, on which this chapter
is focused. However, it should be acknowledged that the growing interest in the speech community todevelop advanced models of spoken language has led to an increasing eﬀort to process corpora thatrepresentthespokenformoflanguage.ThisiswelldocumentedamongotherthingsbythecontributionsinthespecialissueofthejournalSpeechCommunicationpublishedin2001(BirdandHarrington2001),in
167

168 HandbookofNaturalLanguageProcessing
whichtopicssuchasannotationschemes,toolsforcreating,searching,andmanipulatingtheannotationsas well as future directions are discussed. Also, there is an increasing number of contributions at themostrecentInterspeechandotherspeech-relatedconferencesthattacklethetopicalissuesofannotationof spoken language, mostly of dialogues (see e.g., already the Tübingen corpus of spontaneous Japanesedialogues reported on in Kawata and Barteles 2000). Prosody, disﬂuencies, and dialogue acts (such asstatements,requests,etc.)havetobeannotated,too.
Inthischapter,afterintroducingtypesofcorpusannotationandbrieﬂymentioningunstructuredmor-
phosyntactically annotated corpora, we will focus on treebank annotation—the deﬁnition of treebanks,their properties, examples of existing treebanks, their relation to linguistic theory, and the process ofannotation and quality control. We will also refer the application of treebanks, and speciﬁcally discusssearchingforlinguisticinformationinthem.
8.2 Corpus Annotation Types
Annotation consists of pieces of information added to the language data. The data may have variousforms—itcanbeaudio,video,ortextualdata.Theaddedinformationcanbeexternal,suchastheauthor’sname,thedateofrecording/writing,orthetypeoffont—thistypeofannotationisoftencalled“metadata.”We are more interested in linguistic information, such as part of speech, clause boundary, word sense,syntacticanalysis,co-referenceannotation,etc.
Usually, three linguistic annotation phases (layers, or simply types) are distinguished: a morphosyn-
tactic layer, only dealing with morphosyntactic ambiguity (and part of speech and inﬂectional andmorphologicalannotation),alayerdealingwithsyntacticrelationsofdiﬀerentdegreeofdepth(orientedtoward constituency or dependency annotations), and a layer focused on diﬀerent aspects of semanticanddiscourserelationssuchaswordsensedisambiguation,anaphoricrelations,etc.
Amorphosyntactictagincludes(partof)thefollowinginformation(e.g.,fortheFrenchtoken la):
•Lemma(le)
•Partofspeech(determiner)
•Subcategory(deﬁnite)
•Inﬂection(femininesingular)
Asyntactictagincludes(partof)thefollowinginformation:
•Constituentboundaries(clause,NP, ...)
•Grammaticalfunctionofwordsorconstituents(Subject,Complement,Auxiliary, ...)
•Dependenciesbetweenwordsorconstituents(head/dependent)
Asemantictagincludes,amongotherthings,(partof)thefollowinginformation:
•Wordsenseforambiguouswords(interest-1(general),interest-2(banking), ...)
•Domain(orhyperonym)
•Pointertotheantecedentforpronounsoranaphoricelements
Adiscoursetagincludes(partof)thefollowinginformation:
•Discourserelation(cause,purpose,etc.)
•Temporalrelation(simultaneity,anteriority, ...)
•Discourseact(statement,request, ...)
Forsemanticanddiscourseannotations,thetagsetcanbeopen(iftheexpectedvalueisasegmentofthetext)andtheannotatedelementdoesnothavetobeawordbutasequenceofwordsorawholesentence(orutterance)(cf.CraggsandWood2005).
AschemeoftheannotationtypesisgiveninFigure8.1.

TreebankAnnotation 169
Text
Morpho-syntactic:
POS
lemma
inflection
...Syntactic:
phrase
functions
...Semantic:
word sense
anaphora
...Discourse:
dialog acts
temporal relations
...External
annotationLinguistic annotation
Italics
...
FIGURE8.1 Aschemeofannotationtypes(layers).
8.3 Morphosyntactic Annotation
The ﬁrst morphosyntactically tagged corpora were the Brown Corpus for English (Kucera and Francis
1967)andtheLancaster-Oslo-Bergen(LOB)corpus(Johansson1980).Corporataggedwithmorphosyn-
tacticannotationarenowavailableforvariouslanguages:theBritishNationalCorpusforBritishEnglish,
the Penn Treebank (Marcus et al. 1993) for American English, PAROLE and MULTEXT corpora for
variousEuropeanlanguages(VéronisandKhouri1995),andmanyothers.
Morphosyntactictagsets(thelistofsymbolsusedforcategoriesandinﬂections)canvaryfromadozen
(Marcusetal.1993)toseveralmillion(Oﬂazeretal.2003),withdiversepossibilitiesinbetween(seee.g.,
Hajič and Hladká 1998, Böhmová et al. 2003, Brants et al. 2003). They partly reﬂect the richness of the
language’smorphosyntax(withcaseoragreementsystemsyieldingnumerousfeaturestobeencoded).
In morphosyntactic annotation, information concerning the presence of so-called named entities
(names of persons, organizations, locations, etc.) can be included. For example, proper names are
distinguished from common names by special tags in the Penn Treebank and in the Negra Treebank,
and by special lemma suﬃxes in the Prague Dependency Treebank (PDT). However, the annotation of
namedentitiescanalsoberepresentedindependentlyofanymorphosyntacticannotation,asitisthecase
withpopularMUC-6data(MessageUnderstandingConferencefocusedonthenamedentityresolution
task,GrishmanandSundheim1996)orinŠevčíkováetal.(2007),inwhichmuchricherclassiﬁcationof
namedentitytypesareoﬀered(comparedtowhatisusuallystoredinmorphosyntactictags).
Problematic cases are often the same across languages. Not all morphosyntactic taggers deal with
compoundsoridiomsassuch.Somesequencesareambiguousbetweenacompoundandanoncompound
interpretation (e.g., sur cein French can either be the compound adverb ( =at once), or a preposition
(=on) followed by a determiner ( =this)). Most taggers usually prefer the compound interpretation.
Unknown (or misspelled) words, foreign words, and punctuation marks can be ignored or annotated
withspeciﬁctags.Propernameisoftenadefaulttagforallunknownwords.
8.4 Treebanks: Syntactic, Semantic, and Discourse Annotation
8.4.1 Motivation and Deﬁnition
Forsimplelinguisticqueries,morphosyntacticallyannotatedtextsdescribedintheprevioussectionenable
areductionofthe“noise”usuallyassociatedwithanswersdrawnfromrawtexts,andtheyalsoreducethe
necessity to formulate new, reﬁned, and more complex questions. For example, when one is interested
inFrenchcausatives,itisfrustratingtolistalltheinﬂectedformsoftheverb faireinasimplequery,and
many of the answers are not relevant because they involve the homonymous noun fait(which is also
part of a lot of compounds en fait,de fait,du fait que , etc.). Lemmatized tagged texts are thus helpful

170 HandbookofNaturalLanguageProcessing
but inquiries about subject inversion or agentless passives are impossible to perform on corpora taggedonly with parts-of-speech information. This is why people started adding phrase structure informationordependencyrelationtothecorpora,buildingnewtypesofcorporacommonlycalled“treebanks.”
Treebanks are structurally annotated corpora that represent (in addition to part of speech and other
morphological annotation) syntactic, semantic, and sometimes even intersentential relations. The wordtreerefers to the typical or base structure of the annotation, which corresponds to the notion of “tree”
asdeﬁnedintheformalgraphtheory.Theinterpretationsofedgesinthetreediﬀersubstantiallyamongvarioustreebanks,buttheyalmostalwaysrepresentsyntactic(ormoregenerally,structurallygrammatical)relationsasdeﬁnedintheannotationdesign.
Treebanksenablelinguiststoasknewquestions,aboutthewordorderorthecomplexityofvarioustypes
of phrases. Arnold et al. (2000), for example, use the Penn Treebank (Marcus et al. 1993) to determinewhich factors favor the noncanonical V PP NP order in English. One can also check psycholinguisticpreferences, in the sense that a highly frequent construction can be claimed to be preferred over a lessfrequentone.Forexample,PynteandColonna(2000)haveshownonexperimentalreadingteststhatifasequenceoftwonounsisfollowedbyarelativeclauseinFrench,therelativeclausetendstoattachtotheﬁrstnounifitislongandtothesecondnounifitisshort.Thisclaimcanbeeasilycheckedonatreebank,wheresuchacorrelationcanbemeasured(cf.Abeilléetal.2003).
Theﬁrsttreebankswere, for English, theIBM/LancasterTreebank(LeechandRoger1991), thePenn
Treebank (Marcus et al. 1993), and the Susanne corpus (Sampson 1995). At present, treebanks withdiﬀerentdegreesofcomplexityareavailableforseverallanguages,suchasBulgarian(Simovetal.2002),Chinese (Sinica Treebank: Chen et al. 2003, Penn Chinese Treebank: Xia et al. 2000), Czech (PDT,Böhmováetal.2003),Dutch(vanderBeeketal.2001),severaladditionaltreebanksforEnglish(ICE-GB:Nelson et al. 2001, Redwood Treebank: Oepen et al. 2002a,b, etc.), French (Abeillé et al. 2003), German(Negra: Brants et al. 2003), Italian (Bosco et al. 2000, Delmonte et al. 2007), Spanish (Civit and Martí2002,Morenoetal.2003),Swedish(Jäborg1986),Turkish(Oﬂazeretal.2003),tonamejustafew.
∗
8.4.2 An Example: The Penn Treebank
The Penn Treebank (Marcus et al. 1993) is currently the most cited and used treebank in the world.It originally consisted of over 4.5 million words of American English. Part of the corpus was anno-tated for part-of-speech information and, in addition, for skeletal syntactic structure. The POS tags(comprising 36 POS tags and 12 other tags for punctuation and currency symbols) were assigned ﬁrstautomatically and then revised by human annotators, and the same strategy (automatic preprocessingand manual correction) holds true for the syntactic annotation. The syntactic tagset (comprising 14tags) was similar to that used by the Lancaster Treebank Project (Leech and Roger 1991), with oneimportant diﬀerence: the Penn Treebank scenario allowed for addition of null elements in case of somespeciﬁc cases of surface deletions (such as “understood” subject of inﬁnitive or imperative, zero vari-ant ofthatin subordinate clauses, trace-marked positions where an wh-element is interpreted, and
marking positions where preposition is interpreted in the so-called pied-piping contexts). The recon-struction of some of these types of “null” elements was extremely important from the viewpoint of thefuture plans of adding predicate-argument structures (e.g., to be able to determine verb transitivity). Ina later version of the Penn Treebank, functional tags have been added to the syntactic labels (such as-SBJ,-OBJ;Marcusetal.1994).DatainthePennTreebankarestoredinseparateﬁlesfordiﬀerentlayersof annotation (morphological, syntactical) in Lisp-like format. A graphical representation of a sampletree from the Penn Treebank, representing the sentence A few fast-food outlets are giving it a try., is in
Figure8.2.
∗Foramorecomprehensiveanddetailedlist,seehttp://faculty/washington.edu/fxia/treebank.htm.

TreebankAnnotation 171
DT
AJJ
fewNN
fast-foodNNS
outletsVBP
areVP
VBG
giving
PRP
itDT
aNN
try.
.SBJ NP
NP NPVPS
FIGURE8.2 ExampleofaPennTreebanksentence.
8.4.3 Annotation and Linguistic Theory
As already stated in the Introduction to this chapter, one of the prerequisites for achieving a reliably
annotated corpus is to base the annotation scenario on a well-deﬁned linguistic theory. This attitude
S
NP-john
NP-cakesVP-wants
VP-to_eat
FIGURE 8.3 A simpliﬁed
constituency-based tree structure
forthesentence Johnwantstoeat
cakes.hasresultedinseveralannotationschemesbasedondiﬀerenttheoretical
approaches; if these approaches are consistent, then also the annota-
tion can be tested for its consistency. The confrontation of linguistic
hypotheses with actual data leads also to checking and enriching the
chosendescriptiveframework.
An ongoing debate, inspired by discussions in theoretical linguis-
tics, concerns the choice between constituency-based annotation and
dependency-based annotation. As an example, let us take the English
sentenceJohnwantstoeatcakes .Intermsofconstituency,asimpliﬁed
structure is given in Figure 8.3: the sentence is divided into two con-
stituents,thenounphraseNPandtheverbphraseVP,theverbphraseis
inturndividedintotwosmallerconstituents,etc.InFigure8.4,thereis
asimpliﬁeddependencystructureforthesamesentence,withtheverb
asthegovernorofthewholestructureandtheSUBj(ect)andOBJ(ject)
depending on it; the word cakesdepends as the OBJ(ect) on the verb
toeat. Wants
SUBJ-john OBJ-to_eat
OBJ-cakes
FIGURE 8.4 A simpli-
ﬁed dependency-based tree
structure for the sentence
Johnwantstoeatcakes .Bothtypesofannotationshavetheiradvantagesandtheirdrawbacks:con-
stituentsareeasytoreadandcorrespondtocommongrammaticalknowledge
(for major phrases) but they may introduce an arbitrary complexity (with
moreattachmentnodesthanneededandnumerousunaryphrases).Depen-
dency links are more ﬂexible and also correspond to common knowledge
(the grammatical functions) in the sense that syntactically and semantically
related nodes (words) are linked directly but consistent criteria have to be
determinedforthechoiceoftheheadinanygroup.

172 HandbookofNaturalLanguageProcessing
It is interesting to note that one of the hypotheses presented at the workshop “How to Treebank?”
held at the NAACL international conference in 2007∗was that given a rich enough phrase structure
as well as dependency structure annotation, they can be converted to the other type of representationsautomatically.Whichrepresentationtochooseisthensupposedtobeanempiricalissue.
From the range of theories based on phrase–structure formalisms, let us mention, for example, the
HPSG-based treebank for Bulgarian (BulTreeBank, Simov 2001, Simov et al. 2001, Slavcheva 2002),for Polish
†(Marciniak et al. 2003), the LinGO Redwoods HPSG Treebank for English‡(Oepen et al.
2002a,b, Toutanova and Manning 2002, Toutanova et al., 2002, Velldal et al. 2004), and the HPSG-oriented treebanks TuBa-E/S for English
§and TuBa-J/S for Japanese¶(Kawata and Barteles 2000). The
TuBa-E/S annotation scheme distinguishes three levels of syntactic constituency: the lexical level, thephrasal level, and the clausal level. In addition to constituent structure, annotated trees contain edgelabelsbetweennodes.Theseedgelabelsencodegrammaticalfunctions(asrelationsbetweenphrases)andthedistinction between heads and non-heads (as phrase-internal relations). The TuBa-J/S is a manuallyannotatedcorpusofspontaneousdialoguescontainingapprox.18,000sentences(160,000words)andtheannotation scheme (similar to that of the TuBa-E/S corpus) is enriched by the establishment of a labelassignedtotherootnodeanddeterminingthetypeofthesentence.Thisschemealsoincludesadditionaltagstocapturethespeciﬁcphenomenaforspeech.
Asanexampleofadependency-basedannotationscheme,letusmentionthePDT.ThePDT(seee.g.,
Hajič 1998, Böhmová et al. 2003) consists of continuous Czech texts (taken from the Czech NationalCorpus) analyzed on three levels of annotation (morphological, surface syntactic shape, and underlyingsyntactic structure). At present, the total number of documents annotated on all the three levels is3,168, amounting to 49,442 sentences and 833,357 (occurrences of) nodes. The PDT Version 1.0 (withthe annotation of the ﬁrst two levels) is available on CD-ROM as well as the present Version 2.0 (withthe annotation of the third, underlying level). One of the important distinctive features of the PDTannotationisthefactthatinadditiontothemorphemiclayerandtotheannotationofthesurfaceshapeof the sentences the scenario includes annotation on the underlying (tectogrammatical) layer (see, e.g.,Figure8.5).Theunderlyingsentencestructureiscapturedintheformofadependencytreerepresenting(oneof)the(literal)meaning(s)ofasentence.Onlyautosemanticwordsarerepresentedasnodesofthetree, function words having indices of node labels as their counterparts on this level (among these, thefunctorsrepresentthedependencyrelations,i.e.,argumentsandadjuncts,andthevaluesofgrammatemesrepresent morphological units such as tenses, numbers, modalities, etc.). New nodes (not present in themorphemic form of the sentence) are added to account for surface deletions. Each of the edges ofthe tree instantiates one type of dependency (more exactly, dependency can be understood as a set ofbinary relations, i.e., of arguments and adjuncts; certain technical adjustments have been necessary forincluding the relations of coordination, apposition, and parenthesis). In the valency frame of the headword(containedinitslexicalentry),itisspeciﬁedwhichargumentsandadjunctsareobligatorywiththisword. Each node of the dependency tree structure is labeled not only by its underlying function (e.g.,the function of an argument as Actor, Addressee, Patient, Eﬀect, Origin, or adjuncts such as one of thetypes of Locatives and of Temporal modiﬁcation, or Cause, Accompaniment, Manner, etc.), but also byone of the three values (c, t, f) of the attribute of information structure, namely contrastive contextuallybound node, contextually bound node, and contextually non-bound node, in that order (see Hajičováand Sgall 2001, Hajičová 2002, Veselá et al. 2004). Figure 8.5 presents an example of the annotation ofthe Czech sentence Česká opozice se nijak netají tím, že pokud se dostane k moci, nebude se deﬁcitnímu
rozpočtu nijak bránit. (lit.: Czech opposition Reﬂ. in-no-way keeps-back the-fact that in-so-far-as [it]
will-comeintopower,[it]will-notReﬂ.deﬁcitbudgetin-no-wayoppose.Englishtranslation: TheCzech
∗http://faculty.washington.edu/fxia/treebank/workshop07/agenda.htm
†http://nlp.ipipan.waw.pl/CRIT2
‡http://wiki.delph-in.net/moin/RedwoodsTop
§http://www.sfs.uni-tuebingen.de/en_tuebaes.shtml
¶http://www.sfs.uni-tuebingen.de/en_tuebajs.shtml

TreebankAnnotation 173
jak
MANN
f#Neg
RHEM
f
český
RSTR
f#Neg
RHEM
fjak
MANN
f
deficitní
RSTR
c#PersPron
ACT
tmoc
DIR3 .to
fopozice
ACT
c
rozpočet
PAT
tdostat_se
COND
f#PersPron
ACT
tt-ln94202-60-p3s2
root
tajit_se .enunc
PRED
f
bránit_se
PAT
f
FIGURE 8.5 A sample tree from the PDT for the sentence: Česká opozice se nijak netají tím, že pokud se dostane
k moci, nebude se deﬁcitnímu rozpočtu nijak bránit . (lit.: Czech opposition Reﬂ. in-no-way keeps-back the-fact that
in-so-far-as [it] will-come into power, [it] will-not Reﬂ. deﬁcit budget in-no-way oppose. English translation: The
Czechoppositiondoesnotkeepbackthatiftheycomeintopower,theywillnotopposethedeﬁcitbudget .)
opposition does not keep back that if they come into power, they will not oppose the deﬁcit budget .) There
arethreecomplementationsofthemainverb tajitse(keepback),namelyActor,MannerandPatient,and
anegativerhematiser,andthegoverningverbofthedependentclause bránitse(oppose)dependsonthe
mainverbasitsPatientandhasﬁvecomplementationsandnegationdependingonit;thearrowleading
from the reconstructed Actors to the node opozice(opposition) reﬂects the coreference relation. These
coreferencerelationsmay,ofcourse,crossthesentenceboundary.
Another example of a treebank that includes (some kind of) dependency information is the French
Treebank∗with morphosyntactic and constituent annotations (more or less compatible with various
syntacticframeworks)andalsoannotationsofgrammaticalfunctionsassociatedwithmajorconstituents
whichdependonaVerboraVerbalNoun(Abeilléetal.2003).SeeFigure8.6fora(simpliﬁed)graphical
displayofasamplesentencefromtheFrenchTreebank.
Also the treebanks of Scandinavian languages belong to the family of dependency treebanks, see
the Nordic Treebank Network,†which is related to treebanks in the Nordic countries developed in
cooperationwithseveralScandinavianuniversitiesandincludingthenationalcorporaofwrittenand/or
spoken language annotated manually or semiautomatically (see e.g., Nivre 2002 for Swedish, Bick 2003
and Kromann 2003 for Danish). Among the dependency-based treebanks the Turin University Italian
Treebankshouldbementioned(Bosco2000)aswellasthetreebanksofTurkish(Oﬂazeretal. 2003), of
Basque(Adurizetal.2003)andofGreek(Prokopidisetal.2005).
∗http://www.llf.cnrs.fr/Gens/Abeillé/French-Treebank-fr.php
†http://w3.msi.vxu.se/ ∼nivre/research/nt.html

174 HandbookofNaturalLanguageProcessing
SENT
VN(SUBJ)
CL CS NP VN
VAAP
PP
pN P
AD N C
Citoyens Les Tous Ouvertes Restent Publiques Fonctions Les Que Entendu Est I1 à .NC DAVVSsub(OBJ) PONCT
FIGURE8.6 AsampleFrenchtree.(Englishtranslation: Itisunderstoodthatthepublicfunctionsremainopentoall
thecitizens .)
Sie
PPER
3.Sg.Fem.Nom
sieCS
CJ
S
OA
CJCNP
CJ CDHD
SBOA
HDS
SBCD CJ
entwickelt
VVFIN
3.Sg.Pres.Ind
entwickelndruckt
VVFIN
3.Sg.Pres.Ind
druckenVerpackungen
NN
Fem.Akk.Pl
Verpackungund
KON
--
und.
$.
--
.Etiketten
NN
Neut.Akk.Pl
Etikettund
KON
--
und
FIGURE 8.7 Example from the Tiger corpus: complex syntactic and semantic dependency annotation. (English
translation: Itdevelopsandprintspackagingmaterialsandlabels .)
Ahybridsolution, chosenbysomeoftheprojects, istomaintainsomeconstituentswithdependency
relationsbetweenthem(cf.Brantsetal.2003,Chenetal.2003,KurohashiandNagao2003,Oﬂazeretal.
2003). In this case, the constituents are usually minimal phrases, called chunks, bunsetsu (Japanese), or
inﬂectiongroups(Turkish).Inadditiontotheconstituentstructure, annotatedtreescontainedgelabels
betweennodesencodinggrammaticalfunctionsandthedistinctionbetweenheadsandnon-heads.Fora
typicalcase,seeFigure8.7,whichisanexamplefromtheGermanTigerTreebank(Brantsetal.2003).
The choice of annotation depends both on the availability of syntactic studies for a given language
(formalized or not, theory oriented or not) and on the objective. Carroll et al. (2003) demonstrate how
diﬃcult it is to choose a reasonable annotation scheme for parser evaluation, when a variety of parsing
outputshavetobematchedwiththeannotatedcorpus.
8.4.4 Going Beyond the Surface Shape of the Sentence
The development of annotation schemes for large text corpora entered a new stage passing over from
scenarios with tags covering phenomena “visible” or “transparent” on the surface shape of the sentence
(be they of morphological or shallow syntactic character) to some kind of an underlying structure of

TreebankAnnotation 175
the sentence; moreover, not only intrasentential but also intersentential relations are paid attentionto. Naturally, underlying layer schemes also have to tackle ellipsis resolution, or in other words, thereconstructionoftheitemsdeletedonthesurfaceshapeofthesentences.
Theurgency of deep taggingwas emphasized, for example, byUszkoreit(2004)and some interesting
workinthisdirectionisdocumentedbytherecentdevelopmentofseveraltreebanks,forexample,PennPropBank based on the Penn Treebank for English; see Kingsbury and Palmer (2002) with a relatedprojectofNomBank
∗thetaskofwhichistomarkthesetsofargumentsthatco-occurwithnounsinthe
PropBankCorpus,justasPropBankrecordssuchinformationforverbs(Meyersetal.2004).Theﬁrstlargetreebank based on a consistent account of underlying dependency relations was the tectogrammaticallayerofthePDTforCzech(withthecurrentﬁrststepsintestingtheschemeforEnglish,German,orevenArabic),seeHajičová(2002),followedbytheTiger/NegraprojectforGerman
†(Brantsetal.2002)orthe
RedwoodTreebank(Oepenetal. 2002). Itshouldbenotedthatacommonfeatureofalltheseproposalsis an annotation scheme coming close to predicate argument structure. This is also a distinctive featureoftheFrameNetprojectofsemanticroleslabeling(seee.g.,Fillmoreetal.2002,2003,Palmeretal.2005)that has been originally developed for English but is being extended to other languages such as GermanwithintheSALSAproject(BurchardtandFrank2006),Bulgarian(BalabanovaandIvanova2002),Dutch(Monachesietal.2007),etc.However,itshouldbenotedthatFrameNetdoesnotlinktoanyreal-worldtext(s)orcorpora—itonlyextractsrelevantexamplestotheframesitconsistsof.
It is now commonly accepted in theoretical linguistics that one of the semantically relevant aspects
of sentences is their information structure (topic-focus articulation). It is a great challenge for corpusannotationprojectstodevelopascenariothatwouldreﬂectalsothisstructuring;forapossibility,seethetopic-focusannotationofthePDT(e.g.,Hajičová2003);foraratherrecentattempttoannotateaspokencorpusasfortheinformationstructure,seeCalhounetal.(2005).
A related issue, the tackling of which has to go beyond the boundaries of the sentence, or, in more
general terms, to take into account a broader context, is that of anaphora resolution, which means anestablishmentofanaphoric(coreference)linksbetweenindividualreferentialexpressions.Thisisawidelydiscussedissueintheoreticalwritingsbuttheworkonestablishingsuchlinksinlargercorporaisstillrare(e.g., seeaddingpronoun-antecedentlinksinFligelstone(1992), Tutinetal. (2000)orinthescenarioofthePDT).
Considerableattentionisnowbeingpaidtotheanalysisofintersententialrelationsleadingtoabuild-up
ofdiscoursetreebanks.ThebiggestandinasenseapioneeringcomprehensiveprojectisthatofthePennDiscourse Treebank
‡(PDTB); the ﬁrst initiative to turn attention to discourse relations and discourse
markers can be found in Webber and Joshi (1998) in relation to Joshi’s theory of the Lexicalized Tree-AdjoiningGrammar.Theprojecthasresultedinalarge-scalecorpusannotatedwithinformationrelatedto discourse structure, focusing on encoding coherence relations associated with discourse connectives.Theannotationsincludetheargumentstructureoftheconnectives,basicsensedistinctionsfordiscourseconnectives,andtheassignmentofattribution-relatedfeaturesforbothconnectivesandtheirarguments(more recently, see e.g., Prasad et al. 2007, Miltsakaki et al. 2008, Prasad et al. 2008, Pitler et al. 2008).Senses are set up hierarchically, distinguishing four classes (Temporal, Contingency, Comparison, andExpansion);theseclassesaredividedintoseveraltypesandsubtypes.Thehierarchicalstructurehelpstheinter-annotatoragreement.Experimentsarecarriedoutintheareasofstatisticsonthecorpus,automatictextsummarization,predictingdiscoursecoherence,andalsoinautomaticdiscourseannotation.
AsimilarlyorientedprojectisthatofanextensionoftheannotationsofthePDTbeyondtheboundaries
of sentences (see Mladová et al. 2008). The scenario is conceived of as based on the tectogrammaticalannotations, making use of some of the analyses present already there (a special functor is includedin the scenario for general, semantically non-distinguished intersentential relationships and also the
∗http://nlp.cs.nyu.edu/meyers/NomBank.html
†http://www.ims.uni-stuttgart.de/projekte/TIGER/TIGERCorpus
‡http://www.seas.upenn.edu/ ∼pdtb

176 HandbookofNaturalLanguageProcessing
intrasentential relationships of diﬀerent kinds of coordination and embedded clauses are being madeuseof).
Anotherstreamofsemanticannotation,goingoftenhandinhandwiththedeepsyntacticannotations,
concernswordsensedisambiguation.ThedevelopmentoftheoriginalWordNet(Fellbaum1998)anditslanguage-speciﬁc derivatives gave rise to great expectations for a progress in sense disambiguation andalsohadastrongimpactintheﬁeldofsemanticlexicons.AnattemptisbeingmadetointegratethetwosemanticlexicalresourcesinoneoftheprojectsofthePisaresearchcenter,namelytheItalWordNetandtheItalianSIMPLElexicon(Roventinietal.2002).
There is a great variety of annotation schemes focusing on some speciﬁc linguistic or extralinguistic
phenomena:someofthemareapparentlyeasiertohandle(suchastemporal,spatial,ormannerrelations),somearemorediﬃculttocaptureandthescenariosarestillinanexperimentalstage(suchastreatmentofopinions:good/badjudgments,true/falsebeliefs,speechacts,presuppositions,andmetaphors).
The range of these proposals only documents that there is a constant hunger for annotated corpora.
However, corpus annotation is a demanding task in many aspects: it is a time consuming and a veryexpensiveactivity,andthereforewaysarebeinginvestigatedhowtoachievealargeamountofannotateddata with least eﬀort. One such possibility is being explored by Hladká (Hajičová and Hladká 2008); inher project, she aims at a design, the implementation, and the evaluation of a game-playing system asan alternative way of generating linguistic data needed by the tasks of coreference resolution, namedentity recognition and document labeling. The system is designed to use the “Games with a Purpose”methodologyoriginallyproposedforimagelabelingandissupposedtobelanguageindependent.
8.5 The Process of Building Treebanks
Insomeoftheﬁrstprojects,corpusannotationwasdonefromscratchentirelybyhumans,forexample,inSweden(Jäborg1986), orfortheSusannecorpus(Sampson1995). PurelymanualannotationisdonebyMarciniaketal.(2003).Moreoften,theannotationisatleastpartiallyautomated;however,automaticannotation—evenifofhighquality—isnotalwaysdesirablesinceitisthehuman(linguistic)interpretationofanewmaterialthatiscrucialtothefutureuseofthetreebank,especiallyfortrainingstatisticalparsersandotheranalyzersfromtreebanks.
Automatictoolsforcorporaannotation(suchastaggers, parsers,etc.—seeChapter10andthesubse-
quent ones) exist for many languages, but obviously, they make mistakes. One could, in principle, runsomeautomaticpart-of-speechtaggerorlemmatizeronagivencorpus,andusetheresultingannotation.Whileitmightbeadequateforsearching,thequalityoftheresultingcorpusisnotguaranteed.Inanycase,thestate-of-the-artautomatictoolslearnonmanuallyannotatedcorporasothatmanualannotationplaysandwillalwaysplayanimportantroleinthewholeprocess.Insuchcorpora,annotationsaredevisedbyexperiencedlinguistsorgrammarians,fullydocumentedfortheenduser,andfullycheckedtominimizetheremainingerrors(introducedbyahumanannotatororreviewer).
Humanpost-checkingisalwaysnecessary,beitsystematic(asintheBrownCorpusforEnglish,inthe
PennTreebankorinthePDT)orpartial(asintheBritishNationalCorpus). Somecheckallannotationlevelsatthesametime(Brantsetal.2003,Chenetal.2003),otherschecktaggingandparsinginformationseparately (Penn Treebank, Abeillé et al. 2003, Böhmová et al. 2003). Semantic information is oftenannotated by hand. Large-scale annotation projects typically involve dozens of human annotators, andensuring coherence among them is a crucial matter as pointed out by Wallis (2003) for the ICE-GBproject,orBrantsetal.(2003)fortheNegraproject.
Several methods have been proposed to check the inter-annotator agreement, even for the semantic
annotationandthediscourseannotationthatarelessstandardizedthanthemorphosyntacticones.Theyare based on sophisticated statistical techniques; a simple percentage agreement is insuﬃcient becauseit does not discriminate how much agreement is obtained just by chance. Coeﬃcients S(Bennett et al.
1954), π(Scott1955), and κ(Cohen1960)allmeasuretheagreementbetweentwo annotatorsobtained

TreebankAnnotation 177
abovechance.The κ(kappa)coeﬃcientisthemostgeneralandthemostwidelyusedtoday
κ=p(A)−p(C)
1−p(C),
where
p(A)isthepercentage(orratio)wheretheannotatorshaveagreed
p(C)istheprobabilitythattheyagreedjustbychance
In fact, the other agreement coeﬃcients (S,π)only diﬀer in the way they estimate the level of a chance
agreementbetweenthetwoannotators.Generalizationsofthesecoeﬃcientsformorethantwoannotatorsalso exist. To take the chance agreement into account, it is necessary to have prior knowledge of thedistributionofthediﬀerentpossibleannotations,whichisdiﬃcultinnaturallanguage,especiallyfortaskssuchasanaphoraannotation,forwhichthereisnopriorlistoftags.Carletta(1996)hasproposedtouseaKcoeﬃcientofagreement, whichtakesintoaccountannotators’biases. Krippendorﬀ’s α(Krippendorﬀ
1980,2004)makesitpossibletodiﬀerentiatedegreesofdisagreement,sincesomedisagreementsmaybemoreseriousthanothers.Itisdiﬃculttointerpretvaluesofagreementcoeﬃcientsandthereisalackofconsensus on it. Overall, an agreement at least 0.8 is considered to ensure high annotation quality. Thenumberofpossibletagsandthenumberofannotatorscanplayacrucialroleincomputingtheagreementandsometimesacoeﬃcientabove0.7isgoodenough.ArsteinandPoesio(2008)giveanexcellentsurveyofmethodsformeasuringagreementamongcorpusannotators;seealso(EugenioandGlass2004).
Anattempttoproposeamethodforerrordetectionandcorrectionincorpusannotationispresented
by Dickinson, ﬁrst in his PhD dissertation in 2005
∗and then within the DECCA (Detection of Errors
andCorrectioninCorpusAnnotation†)project.Dickinson’smethodreliesontherecurrenceofidentical
strings with varying annotation to ﬁnd erroneous mark-up. The method can be most readily applied topositional annotation, such as part-of-speech annotation, but can be extended to structural annotation,bothfortreestructures(aswithsyntacticannotation)andforgraphstructures(withsyntacticannotationallowing discontinuous constituents, or crossing branches). The results indicate that errors are detectedwith85%accuracy(seeDickinson2006a,b,Boydetal.2007).
Mosttreebanksinvolvinghumanvalidationarelongandcostlyenterprises.Inordertominimizetime
andcost, somenew projectstendtofavor mergingdiﬀerentoutputs of automaticannotationtoolssuchas tagging with diﬀerent taggers and checking only the parts with conﬂicts, for example, in the FrenchMultitagproject,cf.Addaetal.(1999).
Manydataformatshavebeenemployedforencodingtreebanks.Thechoicedependsonthecomplexity
ofthetreebankanditsexpectedusage.Someformatscanbeeasilyreadbyhumans—CSV(CoNLLSharedTask), simpleusagesofSGML(PDT1.0), othersaremoreeasilyreadbycomputerprograms—Lisp-likebracketing style (Penn Treebank, PDT 1.0), XML (PDT 2.0, French Treebank), database storage (TigerTreebank). XML-basedstandardsfor encodingtextcorporahavebeenproposedandused, forexample,XCES(Ideetal.2000),AnnotationgGraphs(CieriandBird2001),orPML(PajasandŠtěpánek2008).
8.6 Applications of Treebanks
Corpusannotationisnotaself-containedtask:itserves,amongotherthings,as
1. AtrainingandtestingdataresourceforNLP.2. Aninvaluabletestforlinguistictheoriesonwhichtheannotationschemesarebased.3. Aresourceoflinguisticinformationforthebuild-upofgrammarsandlexicons.
∗http://ling.osu.edu/∼dickinso/papers/diss/
†http://decca.osu.edu/index.html

178 HandbookofNaturalLanguageProcessing
The main use of treebanks is in the area of NLP, most frequently and importantly statistical parsing.∗
Treebanks are used as the training data for supervised machine learning (which might include theautomatic extraction of grammars) and as test data for evaluating them. Recently, as corpora thatcombinesyntacticandsemanticannotationhavebecomemorewidelyavailable,parsersarealsotrainedjointly with semantic role labelers (for diﬀerent types of parsers and their evaluation, see e.g., Charniak1993, Charniak 1996, Collins 1997, Bod 1998, Carroll 1998, Xia et al. 2000, Bod 2003, Carroll et al.2003,ChenandVijay-Shanker2004,McDonaldandPereira2006,Nivre2006,Surdeanuetal.2008;forabroadandcomprehensivedescriptionofparsing,seeChapter11).Inessence,toﬁndthecorrectanalysis(the best parse) amounts to ﬁnding such a derivation tree that maximizes the probability (or “score” ingeneral)ofthatderivation(usuallytheproductoftheprobabilitiesorscoresoftherulesbeingused).Fordependency trees, the situation is analogous, except that edges and their probabilities (scores) are usedinstead of rules. The probabilities (or scores) are estimated from the treebank during the training phaseofthemachinelearningmethodused(andsmoothedaccordingly).Suchparsersarerobust—theydonotfail on real corpora, as grammar-based parsers often did in the past when written manually without aproperuseofscoringorprobabilities.Theycangivejustonebestresult,ortheycanprovidemoreresults,sortedaccordingtotheirprobability(orscore).
Treebanksserveonemoreimportantpurposewithregardtoparsing:theyareusedfortheirevaluation.
When performing such evaluation, one has to divide the corpus into a training and development part,whichisusedfortheextraction,estimation,smoothing,andanyother“tuning”oftheparser’sprobabilitiesor scores; and an evaluation part, which is used only for determining the parser’s accuracy after itsdevelopmentiscompletelyﬁnished.Suchadivisionisnecessarytosimulateareal-worldsituationwhentheparserisappliedtopreviouslyunseendata.Thetraining/evaluationdatadivisionistypicallyperformedseveral times so that the evaluation part is diﬀerent for every training/evaluation experiment (called the“cross-validation” of results), to avoid biases caused by using only a single section of the treebank forevaluation.
Nevertheless, treebanks tend to be consistent in their domain, and parser performance on out-of-
domain texts is usually worse than in an experiment that uses carefully simulated real-world but stillin-domain evaluation data. Parser adaptation and its relation to treebank annotation is thus subject tocurrentresearch. Forexample, thePennTreebank’s WallStreetJournal part, whichistraditionallyused
as training and evaluation material for statistical parsers, comes almost exclusively from the ﬁnancialdomain, despite an occasional article on a new book, ﬁlm or sports event; it is thus no wonder that across-treebankevaluationagainstanotherEnglishtreebankyieldssigniﬁcantlyworseresults.
†
Thetypeofparserfollowsthetreebankstyle(dependencyparsersaretrainedondependencytreebanks
andphrase-basedtreebanksareusedforparsersbasedoncontext-freegrammars),unlessthetreebankisconvertedﬁrsttoatreebankoftheothertype(foradiscussionhowandwhenissuchconversionpossible,seeSection8.4.3).
Itisalsopossibletomergetreebankswithotherannotateddata,suchaspredicate-argumentrelations
andvalency,namedentities,coreferenceannotation,etc.(providedtheyhavebeendoneonthesamedata).Suchcombinedresourcesareveryusefulforapplicationswhereparsingandothertypesofclassiﬁcationaretobeperformedsimultaneouslyorevenjointly.
‡
Totrainasystemthatperformswell,onehastoﬁndabalancebetweenthesizeofthetagset(richness
of information available in the annotated corpus) and the size of the corpus (number of words orsentences annotated). Relatively good performances are obtained with a small tagset (less than 50 tags)and a large corpus (more than 1 million words). Srinivas and Joshi (1999), training a shallow parser
∗Treebankscanalsobeused(andoftenare)fortrainingstatisticaltaggers,sincetheycommonlycontainpart-of-speechand
morphologicalannotationaswell.Forthedescriptionoftaggingapproaches,seeChapter10.
†See e.g., the CoNLL-2007 and CoNLL-2009 Shared Task out-of-domain adaptation results (http://nextens.uvt.nl/
depparse-wiki/AllScoresandhttp://ufal.mﬀ.cuni.cz/conll2009-st/results/results.php).
‡See again the CoNLL-2008 and CoNLL-2009 Shared Task descriptions at http://barcelona.research.yahoo.net/conll2008
andhttp://ufal.mﬀ.cuni.cz/conll2009-st

TreebankAnnotation 179
(called a supertagger) on the Penn Treebank, show how going from a training set of 8000 words toa training set of 1 million words improve the parser’s performance from 86% (of the words with thecorrect syntactic structure) to 92%. The size of the various tagsets (label inventories) is determined atthe treebank annotation time, but downsizing is always possible once the treebank is used as data for aparticulartrainingmethod.
Automaticallytrainedstatisticalparsersarenottheonly(evenifprevailing)useoftreebanks.Attemptstocombinemanualgrammardevelopmentwithsemiautomaticcorpusinspectionandgram-
marruleextractionarestillon.Rosénetal.(2006)noticethatthemanualsyntacticannotationofcorporaisagoodempiricalsourceforgrammardevelopment,asopposedtointrospectionandconstructedexam-ples, but an automatic syntactic annotation of corpora, which is fast and always consistent, requires afullyadequategrammar,whichinturnshouldideallybebasedonacorpus.Theauthorsproposetobreakthis seemingly vicious circle by an incremental approach that closely links grammar development andtreebankconstruction.
AsobservedbyCharniak(1996),treebankgrammars,asasimplelistofcontext-freerewriterules,are
often much larger than human-crafted ones (more than 10,000 rules for the Penn Treebank) and maydecreasetheeﬃciencyoftheparser. Thisiswhysomeauthors(ChenandVijay-Shanker2004, Xiaetal.2000) start with a linguistic model of grammar (LFG, HPSG, or TAG) that guides the type of pattern(tree-likeorrule-like)tobeextracted.
Otherapplicationsincludetextclassiﬁcation,wordsensedisambiguation,multilingualtextalignment,
andindexation.Fortextcategorization,Biber(1988)workswithrichlyannotatedtexts,andusescriteriasuch as the relative proportion of adjectives among categories (as a good discriminator for formal vs.informalspeech),andtherelativeproportionofpronominalsubjectsamongallsubjects(asadiscriminatorfor speech vs. written language). Malrieu and Rastier (2001) duplicate such criteria on other languagessuchasFrench.
The ﬁrst corpus annotated with word senses was SemCor (Landes et al. 1998), a subset of the Brown
CorpusannotatedwithsensesfromWordNet.Itwasdevelopedtogetherwith(andforthepurposeof)animprovedWordNet(Version1.6).NewwordsensesidentiﬁedinthedatawereaddedintotheWordNetduringtheannotation.
InthePDT,twomajorword-sense-relatedannotationexperimentstookplace:in2006,asmallportion
ofthePDT2.0wasannotatedwithsenses(synsets)fromtheCzechWordNet.Theannotationproceededword-after-word, but unlike in the case of SemCor, words that had no meaning in the Czech WordNetwere skipped, that is, the annotation lexicon was not modiﬁed during the annotations. Each word wasannotated individually. The other annotation took place later, and added the identiﬁcation and sense-annotationofmulti-wordexpressionsinthePDT2.0.Multi-wordnamedentitieswereannotatedaswell.This later project was similar to the SemCor one in the handling of the annotation lexicon: the projectstarted with a lexicon containing multi-word expressions compiled from several dictionaries, but newexpressions(andmeaningsofexistingexpressions)wereaddedastheywereidentiﬁedinthedata.
For verb sense disambiguation, it is important to know the context of each occurrence, since it is a
goodguideforsemanticinterpretation( canasamodalcanbedistinguishedfrom canasatransitiveverb,
etc.).Forautomaticwordsenseclassiﬁcation,parsedtextsarealsobeingused,forexample,byMerloandStevenson(2001).
For text indexing or terminology extraction, too, some syntactic structure is necessary, at least for
spotting the major noun phrases. Knowing that an NP is in argument position (subject or object) maymakeitabettercandidateforindexingthanNPsonlyoccurringinadjunctphrases.
(Manually) treebanked texts are usually much smaller than raw texts. While the latter are usually
availableinquasi-inﬁnitequantity(especiallyviavariousWebsitesintheworldaswellasfromestablishedlanguagedatapublishers,suchastheLinguisticDataConsortium
∗andELDA†),theformeroftenrequire
∗http://www.ldc.upenn.edu
†http://www.elda.org

180 HandbookofNaturalLanguageProcessing
human post-correction, without which they do not perform well enough for many languages. Somesearches for individual forms or patterns may yield poor results. Another obstacle is that treebanks arenot readable as such and require speciﬁc search and viewing tools. This may be why they are still moreusedbycomputationallinguiststhanbyotherlinguists.
It is quite understandable that together with the rapid increase of the number of languages for which
annotated corpora are being developed, an agreement on some standards is felt as a priority, importantalsoforthepossibilityofnationalorinternationalcooperation. Amongtheexistingstandards, therearesuch that have been consensually agreed in multilingual initiatives such as EAGLES/ISLE, or de factostandardssuchas(Euro)WordNetorPAROLE/SIMPLE.Thetrendtowardstandardizationbringsaboutseveralimportantissuestobediscussed.Oneofthemisthepossibility/impossibilityofestablishingsome“theoryneutral”annotationscheme.“Theoryneutral,”ofcourse,doesnotmean“withoutanytheoreticalbackground”; it is our ﬁrm conviction that a reliable and meaningful scheme of annotation must bebacked by a solid, empirically veriﬁed, and theoretically sound linguistic framework. “Theory neutral”may only be understood as an attempt to develop an annotation scenario on some underlying level ofannotation that would be applicable to any language, or at least to languages that are typologically closetoeachother(seealsoNivre2003).
Anotherissueconnectedwiththestandardizationeﬀortsisthatofthetranslatabilityofoneannotation
scheme to another; this feature is recently referred to as an interoperability of annotation schemes. Thetask is very important especially for an evaluation of annotated corpora for most diﬀerent languagesand its feasibility can be, for example, documented by the eﬀorts to translate the Penn PropBank(developed from the Penn Treebank 2) argument structures into the dependency based underlying(tectogrammatical) structures of the PDT and vice versa (Žabokrtský and Kučerová 2002) and also thecomparative studies carried out for these two approaches and for the UMC Lexical Database basedprimarily on Levin’s (1993) classiﬁcation of verb frames. Another attempt of a similar kind is thedescription of an algorithm translating the Penn Treebank into a corpus of Combinatory CategorialGrammarnormal-formderivations(HockenmeierandSteedman2002),thetooldescribedinDaumetal.(2004)forconvertingphrasetreebankstodependencytreesorthediscussionoftheportabilityofmethodsandresultsovertreebanksindiﬀerentlanguagesandannotationformatsinBoscoandLombardo(2006).
8.7 Searching Treebanks
The ability to search treebanks is crucial for linguists and important for computer scientists, albeit thelatter use it mainly for inspecting the corpus and ﬁnding features important for building appropriatestatisticalmodelsthattheylearnfromthemautomatically.
Linear corpora (plain or tagged) can be very large (billions of tokens) and search tools for them have
to be optimized to work with such extremely large data. Manatee/Bonito
∗is a client-server application
that uses regular expressions and Boolean expressions to create complex queries on linearly annotatedtexts.Thesearchresultscanbeprocessedfurthertoobtainfrequencylistsandotherstatisticaldata.TheStuttgartCorpusWorkbench
†isacollectionoftoolsforsearchingplainortaggedtexts.Itusesasimilar
querylanguagesuchasManatee/Bonitoandalsocanfurtherprocessthesearchresults.
Most corpora referred to here are static resources. A recent line of research is to develop dynamic
treebanks, whichareparsedcorporadistributedwithallannotationtools, inordertobeenlargedatwillbytheuser(cf.Oepenetal.2002).
Atreebankquerylanguageisonlyasgoodasthelistoflinguisticphenomenaitoﬀerstobeusedeasily
(oratall)inthesearches.Ithasbeennoted(Kallmeyer2000,Cassidy2002,LaiandBird2004,Birdetal.2006, Mírovský 2008a) that the standard XML query languages (such as XQuery that in turn builds on
∗http://www.textforge.cz/products
†http://www.stanford.edu/dept/linguistics/corpora/cas-tut-cqp.html

TreebankAnnotation 181
XPath,ClarkandDeRose1999)cannotdealwithsomeofthelinguisticphenomenaatall,oronlyinawaythatisunacceptablefortheusers.InBirdetal.(2005),threeexpressivefeaturesimportantforlinguisticsqueriesarelisted:immediateprecedence,subtreescoping,andedgealignment.
Manysearchtoolsfortreebankshavebeendevelopedsofar.TGrep(Pito1994)isatraditionalline-based
searchtooldevelopedprimarilyforthePennTreebank(Marcusetal.1993).Itcanbeusedforanytreebankwhere each node is labeled with only one symbol—either a nonterminal or a leaf with an atomic token.Regularexpressionscanbeusedformatchingnodesymbols.TGrep2(Rohde2005)isasequeltoTGrep.ItisalmostcompletelybackwardcompatiblewithTGrepbutbringsanumberofnewfeatures,suchasfulllogicalexpressionsonrelationshipsandpatterns,co-indexing(andhandlescyclicallinks)anduser-deﬁned“macros.”TigerSearch(Lezius2002)isagraphicallyorientedsearchtoolfortheTigerTreebank(Brantsetal.2002).ThequerylanguageallowsforBooleanfeature-valuepairexpressions,immediateprecedence,and immediate dominance of nodes, and on the highest level, Boolean expressions over node relations(withoutnegation).TrEd(Pajas2007)hasprimarilybeenusedforthemanualannotationofthePDTandother similar treebanks with some perl-based general search language. TrEd now contains a structuredandfast,client-server,end-user-orientedextension“Tree_Query,”whicheﬃcientlyimplements(bothinonline-andbatchmodes)mostoftheknownlinguisticqueryrequirementsonanyPML-encodedcorpus(Pajas and Štěpánek 2008). Netgraph (Mírovský 2008b) is a powerful, graphically oriented client-serverbasedsearchtool,primarilydevelopedalsoforthePDT2.0.Itusesmeta-attributes,nodeco-indexing,andarithmeticandlogicalrelationstoexpresssomeofthenecessaryfeaturesthatarenoteasilyexpressiblebyimmediaterelationsinqueries.Viqtorya(SteinerandKallmeyer2002)isasearchtooldevelopedfortheTübingenTreebanks(Hinrichsetal.2000).Ithasagraphicalinterface,butwithoutavisualdepictionofthequery.Aﬁrstorderlogicwithoutquantiﬁcationischosenasaquerylanguage,withsomerestrictions.AnotherquerylanguagedevelopedfortheTübingenTreebanksistheFinitestructurequery(fsq,Kepser2003).Itusesthefullﬁrst-orderlogic(withquantiﬁcation),withLISP-likesyntax.
8.8 Conclusions
Treebanking is a highly complex issue and many questions still remain to be discussed and resolved. Atthe2007NAACLworkshopontreebankingmentionedearlier,thefollowingthreegeneraltopicsfollowedbylanguage-speciﬁcissueswerediscussedasbeingtopicalforthepresent-state-of-the-art:
1. Lessons learned from the Penn Treebank methodology. (What semantics is to be annotated?
What information was missing in the underlying Penn Treebank? What information was therebut represented badly? What methodology is appropriate for semantic annotation? What are theadvantagesofaphrase-structureand/oradependencytreebankforparsingassuchandespeciallyforsemanticannotation?)
2. Grammar formalisms and transformations between formalisms (including the pros and cons for
buildingatreebankforgrammarsinaparticularformalismvs.buildingageneralpurposetreebankandextractinggrammarsfromtheTreebank).
3. Treebanks as training data for parsers, tackling such issues as whether a more reﬁned tagset for
parsingispreferable,whichcategoriesareusefulandwhicharenot,orwhataretheadvantagesanddisadvantagesofautomaticpreprocessingofthedatatobetreebanked.
Given the current state of syntactic knowledge, some annotation choices may be arbitrary. What ismost important is consistency (similar cases must be handled similarly) and explicitness (a detaileddocumentationmustaccompanytheannotatedcorpus).AsnotedbyG.Sampson(1995),fortheSusanneCorpus, the size of the documentation can be bigger than the corpus itself. Without consistency anyannotated corpus becomes useless; at the same time, any annotation (except in case of a fully automaticannotationwhich,regretfully,seemstobefartobeachievedwithsomereasonablerichnessofannotationlabelsandcategories)involvessomehumaninterventionandassuchisopenforinconsistencies.Therefore,

182 HandbookofNaturalLanguageProcessing
the agreement between annotators should be carefully watched and measured, in order to make theannotationguidelinesmoreexplicitandunambiguous.
Thanks to treebanks, NLP technologies such as automatic tagging, parsing, and other annotation
of (mostly) written texts has made tremendous progress during the past 10–20 years. Part-of-speechtagging seems to be close to its current limits, reaching the level of human performance (as deﬁned bytheinterannotatoragreement).Parsing,“deep”parsing,semanticrolelabeling,machinetranslation,andotherNLPtechnologiesarestillareasofvividresearchandexperimentation.ItisexpectedthattheﬁndingsaccumulatedduringtheseexperimentswillinﬂuencefuturetreebankannotationprojectstoservebetterNLPtechnologyneeds.Similarinﬂuencemightcomefromthetheoreticalside:newannotationschemeswillthensupport,intheareasofsyntaxandsemantics,(hopefully)moreconsistent,moreadequate,andmoreexplanatorylinguistictheoriesthantheydotoday.
Acknowledgments
TheauthorsacknowledgethesupportoftheCzechMinistryofEducation(grantsMSM-0021620838andME838),theCzechGrantAgency(projectunderthegrant405/09/0729),andtheGrantAgencyofCharlesUniversityinPrague(projectGAUK52408/2008).WearegratefultoBarboraVidováHladkáandZdeněkŽabokrtský for reading and commenting upon the ﬁrst draft of the chapter and for providing us withuseful information and recommendations we used in the relevant places of the text, as well as to PavelStraňák for his additions in the paragraphs on word sense disambiguation and named entities. ThanksareduetothetworeviewersofthechapterSteveBirdandAdamMeyersformosthelpfulcomments.
References
Abeillé, A., Clément, L., and F. Toussenel. 2003. Building a treebank for French. In Treebanks: Building
andUsingParsedCorpora,ed.A.Abeillé,pp.165–188.Dordrecht,theNetherlands:Kluwer.
Adda, G., Mariani, J., Paroubek, P., Rajman, M., andJ.Lecomte. 1999. L’actionGRACEd’évaluationde
l’assignationdepartiesdudiscourspourlefrançais. Langues2(2):119–129.
Aduriz,I.,Aranzabe,M.,Arriola,J.etal.2003.MethodologyandstepstowardstheconstructionofEPEC,
acorpusofwrittenBasquetaggedatmorphologicalandsyntacticlevelsfortheautomaticprocessing.InProceedingsoftheCorpusLinguistics2003Conference ,Lancaster,U.K.,eds.D.Archer,P.Rayson,
A.Wilson,andT.McEnery,pp.10–11.UCRELtechnicalpaper(16).UCREL,LancasterUniversity.
Arnold, J. E., Wasow, T., Losongco, A., and R. Ginstrom. 2000. Heaviness vs. newness: The eﬀects of
structuralcomplexityanddiscoursestatusonconstituentordering, Language 76:28–55.
Arstein R. and M. Poesio. 2008. Inter-coder agreement for computational LinguisticsInter-Coder
agreementforcomputationallinguistics. ComputationalLinguistics 34(4):555–596.
Balabanova,E.andK.Ivanova.2002.Creatingamachine-readableversionofBulgarianvalencedictionary
(A case study of CLaRK system application). In Proceedings of TLT 2002 , Sozopol, Bulgaria, eds.
E.HinrichsandK.Simov,pp.1–12.
Bennett, E. M., Alpert, R., and A. C. Goldstein. 1954. Communications through limited questioning.
PublicOpinionQuarterly 18(3):303–308.
Biber,D.1988. VariationAcrossSpeechandWriting .Cambridge,U.K.:CambridgeUniversityPress.
Bick, E. 2003. Arboretum, a Hybrid Treebank for Danish. In Proceedings of TLT 2003 , Växjö, Sweden,
eds.J.NivreandE.Hinrich,pp.9–20.
Bird,S.,Chen,Y.,Davidson,S.,Lee,H.,andY.Zheng.2006.DesigningandevaluatinganXPathdialectfor
linguisticqueries.In Proceedingsofthe22ndInternationalConferenceonDataEngineering (ICDE),
Atlanta,GA,pp.52–61.

TreebankAnnotation 183
Bird, S., Chen, Y., Davidson, S., Lee, H., and Y. Zheng. 2005. Extending Xpath to support linguistic
queries.In ProceedingsoftheWorkshoponProgrammingLanguageTechnologiesforXML (PLAN-X
2005),SanFrancisco,CA,pp.35–46.
Bird, S. and J. Harrington. 2001. Editorial to the special issue of Speech Communication. Speech
AnnotationandCorpusTools 33:1–4.
Bod,R.1998. BeyondGrammar .Stanford,CA:CSLIPublications.
Bod, R. 2003. Extracting grammars from treebanks. In Treebanks: Building and Using Parsed Corpora ,
ed.A.Abeillé,pp.333–350.Dordrecht,theNetherlands:Kluwer.
Böhmová, A., Hajič, J., Hajičová, E., and B. Hladká. 2003. The Prague dependency treebank: A 3-level
annotationscenario.In Treebanks:BuildingandUsingParsedCorpora ,ed.A.Abeillé,pp.103–128.
Dordrecht,theNetherlands:Kluwer.
Bosco,C.2000.AricherannotationschemaforanItaliantreebank.In ProceedingsofESSLLI-2000Student
Session,ed.C.Pilière,Birmingham,U.K.,pp.22–33.
Bosco, C. and V. Lombardo. 2006. Comparing linguistic information in treebank annotations. In
ProceedingsofLREC2006,Genova,Italy,pp.1770–1775.
Bosco,C.,Lombardo,V.,Vassallo,D.,andL.Lesmo.2000.BuildingatreebankforItalian:Adata-driven
annotationschema.In ProceedingsofLREC2000,Athens,Greece,pp.99–105.
Boyd,A.,Dickinson,M.,andD.Meurers.2007.Increasingtherecallofcorpusannotationerrordetection.
InProceedingsofTLT2007 ,Bergen,Norway,NEALTProceedingsSeries,Vol.1,pp.19–30.
Brants,S.,Dipper,S.,Hansen,S.,Lezius,W.,andG.Smith.2002.TheTIGERtreebank.In Proceedingsof
TLT2002,Sozopol,Bulgaria,eds.Hinrichs,E.andSimov,K.,pp.24–41.
Brants, T., Skut, W., and H. Uszkoreit. 2003. Syntactic annotation of a German newspaper corpus.
InTreebanks: Building and Using Parsed Corpora , ed. A. Abeillé, pp. 73–88. Dordrecht, the
Netherlands:Kluwer.
Burchardt, A. and A. Frank. 2006. Approximating textual entailment with LFG and FrameNet frames.
InProceedingsoftheSecondPASCALRecognisingTextualEntailmentChallengeWorkshop ,Venice,
Italy,ed.B.MagniniandI.Dagan,pp.92–97.
Calhoun, S., Nissim, M., Steedman, M., and J. Brenier. 2005. A Framework for annotating information
structure in discourse. In Frontiers in Corpus Annotation II: Pie in the Sky. Proceedings of the
Workshop,ACL2005,AnnArbor,MI,pp.45–52.
Carletta, J. 1996. Assessing agreement on classiﬁcation tasks: The kappa statistics. Computational
Linguistics 22(2):249–254.
Carroll,J.1998.Evaluation:Parsing. ELSNews:TheNewsletteroftheEuropeanNetworkinLanguageand
Speech7(3):8.
Carroll, J., Minnen, G., and T. Briscoe. 2003. Parser evaluation with a grammatical relation annotation
scheme.In Treebanks:BuildingandUsingParsedCorpora ,ed.A.Abeillé,pp.299–316.Dordrecht,
theNetherlands:Kluwer.
Cassidy, S. 2002. XQuery as an annotation query language: A use case analysis. In Proceedings of LREC
2002,LasPalmas,CanaryIslands,Spain,pp.2055–2060.
Charniak,E.1993. StatisticalLanguageLearning .Cambridge,MA:MITPress.
Charniak, E. 1996. Tree-bank Grammars. In Proceedings of the 13th National Conference on Artiﬁcial
Intelligence ,MenloPark,CA,pp.1031–1036.
Chen, J. and V. K. Shanker. 2004. Automated extraction of TAGs from the Penn Treebank. In New
DevelopmentsinParsingTechnology,Text,SpeechAndLanguageTechnology,Vol.23,eds.H.Bunt,J.Carroll,andG.Satta,pp.73–89.Norwell,MA:KluwerAcademicPublishers.
Chen, K., Huang, C., Chen, F., Lao, C., Chang, M., and C. Chen. 2003. Sinica treebank: Design criteria,
representationalissuesandimplementation.In Treebanks:BuildingandUsingParsedCorpora ,ed.
A.Abeillé,pp.231–248.Dordrecht,theNetherlands:Kluwer.
Cieri,C.andS.Bird.2001.Annotationgraphsandserversandmulti-modalresources:Infrastructurefor
interdisciplinary education, research and development. In Proceedings of the ACL 2001 Workshop

184 HandbookofNaturalLanguageProcessing
onSharingToolsandResources,Toulouse,France,Vol.15,pp.23–30,July07,2001. AnnualMeeting
oftheACL.AssociationforComputationalLinguistics,Morristown,NJ.
Civit, M. and M. A. Martí. 2002. Design principles for a Spanish treebank. In Proceedings of TLT 2002 ,
Sozopol,Bulgaria,eds.E.HinrichsandK.Simov,pp.61–77.
ClarkJ.andS.DeRose.1999.XMLpathlanguage(XPath).http://www.w3.org/TR/xpath.Cohen,J.1960.Acoeﬃcientofagreementfornominalscales. EducationalandPsychologicalMeasurement
20(1):37–46.
Collins, M. 1997. Three generative, lexicalized models for statistical parsing. In Proceedings of the 35th
Annual Meeting of the Association for Computational Linguistics and Eighth Conference of theEuropeanChapteroftheAssociationforComputationalLinguistics , Somerset, NJ,eds. P.R.Cohen
andW.Wahlster,pp.16–23.
Craggs, R. and M. M. Wood. 2005. Evaluating discourse and dialogue coding schemes. Computational
Linguistics 31(3):289–296.
Daum,M.,Foth,K.,andW.Menzel.2004.Automatictransformationofphrasetreebankstodependency
trees.InProceedingsofLREC2004,Lisbon,Portugal,pp.1149–1152.
Delmonte,R.,Bristot,A.,andS.Tonelli.2007.VIT—VeniceItaliantreebank:Syntacticandquantitative
features.In ProceedingsofTLT2007 ,Bergen,Norway,pp.43–54.
Dickinson, M. 2006a. Rule equivalence for error detection. In Proceedings of TLT 2006 , Prague, Czech
Republic,pp.187–198.
Dickinson,M.2006b.Fromdetectingerrorstoautomaticallycorrectingthem.In Proceedingsofthe11th
Conference of the European Chapter of the Association for Computational Linguistics (EACL-06 ),
Trento,Italy,pp.265–272.
Eugenio B. Di and M. Glass. 2004. The kappa statistic: A second look. Computational Linguistics 30(1):
95–101.
Fellbaum,C.(ed.).1998. WordNet:AnElectronicLexicalDatabase .Cambridge,MA:MITPress.
Fillmore, C. J., Baker, C. F., and H. Sato. 2002. Seeing arguments through transparent structures.
InProceedingsofLREC2002,LasPalmas,CanaryIslands,Spain,pp.787–791.
Fillmore, Ch. J., Johnson, Ch. R., and M. R. L. Petruck. 2003. Background to Framenet. International
JournalofLexicography 16(3):235–250.
Fligelstone, S. 1992. Developing a scheme for annotating text to show anaphoric relations. In New
Directions in English Language Corpora , ed. G. Leitner, pp. 53–170. Berlin, Germany: Mouton de
Gruyter.
Grishman, R. and B. Sundheim. 1996. Design of the MUC-6 evaluation. In Annual Meeting of the
ACL—ProceedingsofaWorkshoponHeldatVienna ,Vienna,VA,pp.413–422.
Hajič, J. 1998. Building a syntactically annotated corpus: The Prague dependency treebank. In Issues of
ValencyandMeaning.StudiesinHonourofJarmilaPanevová ,ed.E.Hajičová,pp.106–132.Prague,
CzechRepublic:Karolinum,CharlesUniversityPress.
Hajič, J.andB.Hladká. 1998. Tagginginﬂectivelanguages: Predictionofmorphologicalcategoriesfora
rich, structured tagset. In Proceedings of the 36th Annual Meeting of the Association for Computa-
tional Linguistics and 17th International Conference on Computational Linguistics ,M o n t r e a l ,Q C ,
pp.483–490.Montreal,QC:AssociationforComputationalLinguistics.
Hajičová,E.2002.Theoreticaldescriptionoflanguageasabasisofcorpusannotation:ThecaseofPrague
dependencytreebank. PragueLinguisticCirclePapers 4:111–127.
Hajičová, E. 2003. Topic-focus articulation in theCzech national corpus. In Language and Function: To
theMemoryofJanFirbas ,ed.J.Hladký,pp.185–194.Amsterdam,theNetherlands:JohnBenjamins.
Hajičová, E. and P. Sgall. 2001. Topic-focus and salience. In Proceedings of 39th Annual Meeting of
the Association for Computational linguistics , Toulouse, France, pp. 276–281. Toulouse, France:
AssociationforComputationalLinguistics.
Hajičová,E.andB.V.Hladká.2008.Whatdoessentenceannotationsayaboutdiscourse?In Proceedings
ofthe18thInternationalCongressofLinguists ,Seoul,SouthKorea,Vol.2,pp.125–126.Seoul,South
Korea:TheLinguisticSocietyofKorea.

TreebankAnnotation 185
Hinrichs,E.W.,Bartels,J.,Kawata,Y.,Kordoni,V.,andH.Telljohann.2000.TheTuebingentreebanksfor
spokenGerman,English,andJapanese.In Verbmobil:FoundationsofSpeech-to-SpeechTranslation ,
ed.W.Wahlster,pp.550–574.Berlin,Germany:Springer-Verlag.
Hockenmeier, J. and M. Steedman. 2002. Acquiring compact lexicalized grammars from a cleaner
treebank.In ProceedingsofLREC2002,LasPalmas,Spain,pp.1974–1981.
Ide, N., Bonhomme, P., and L. Romary. 2000. XCES: An XML-based standard for linguistc corpora. In
ProceedingsofLREC2000,Athens,Greece,pp.825–830.
Jäborg, J. 1986. SynTag Dokumentation. Manual för syntaggning . Göteborgs University, Institute för
spräkvetenskapligdatabehandling,Gothenburg:Sweden.
Johansson,S.1980.TheLOBcorpusofBritishEnglishtexts:Presentationandcomments. ALLCJournal
1(1):25–36.
Kallmeyer,L.2000.Onthecomplexityofqueriesforstructurallyannotatedlinguisticdata.In Proceedings
ofACIDCA’2000,pp.105–110.Tunisia.
Kawata, Y. and J. Barteles. 2000. Stylebook for Japanese Treebank in Verbmobil . Technical Report 240,
Verbmobil,Eberhard-Karls-Universität,Tübingen,Germany.
Kepser, S. 2003. Finite structure query—A tool for querying syntactically annotated corpora. In
ProceedingsofEACL2003,Budapest,Hungary,pp.179–186.
Kingsbury, P. and M. Palmer. 2002. From TreeBank to PropBank. In Proceedings of LREC 2002,L a s
Palmas,CanaryIslands,Spain,pp.1989–1993.
Krippendorﬀ, K. 1980. Content Analysis: An Introduction to Its Methodology , Chapter 12. Beverly Hills,
CA:Sage.
Krippendorﬀ,K.2004.Reliabilityincontentanalysis:Somecommonmisconceptionsandrecommenda-
tions.HumanCommunicationResearch 30(3):411–433.
Kromann,M.T.2003.TheDanishdependencytreebankandtheDTAGtreebanktool.In Proceedingsof
TLT2003,Växjö,Sweden,pp.217–220.
Kucera,H.andW.Francis.1967. ComputationalAnalysisofPresentDayAmericanEnglish .Providence,
RI:BrownUniversityPress.
Kurohashi, S. and M. Nagao. 2003. Building a Japanese parsed corpus while improving the parsing
system. In Treebanks: Building and Using Parsed Corpora , ed. A. Abeillé, pp. 249–260. Dordrecht,
theNetherlands:Kluwer.
Lai,C.andS.Bird.2004.Queryingandupdatingtreebanks:Acriticalsurveyandrequirementsanalysis.
InProceedingsoftheAustralasianLanguageTechnologyWorkshop ,Sydney,NSW,pp.139–146.
Landes,S.,LeacockC.,andR.I.Tengi.1998.Buildingsemanticconcordances.In WordNet:AnElectronic
LexicalDatabase ,ed.C.Fellbaum,Cambridge,MA:MITPress.
Leech,G.andG.Roger.1991.Runningagrammarfactory,theproductionofsyntacticallyanalyzedcor-
poraor“treebanks”.In EnglishComputerCorpora,pp.15–32.MoutondeGruyter,Berlin,Germany.
Levin, B. 1993. English Verb Classes and Alternations. Chicago IL London, U.K.: University of Chicago
Press.
Lezius,W.2002. EinSuchwerkzeugfürsyntaktischannotierteTextkorpora.PhDthesisIMS,Universityof
Stuttgart,Stuttgart,Germany.
Malrieu, D.andF.Rastier. 2001. Genresetvariationsmorpho-syntaxiques. Traitementautomatiquedes
langues:linguistiquedecorpus,ed.DailleB.andRomaryR.,42(2):547–577.
Marciniak, M., Mykowiecka, A., Przepiorkowski, A., and A. Kupsc. 2003. An HPSG-annotated test
suite for polish. Building and Using Parsed Corpora , ed. A. Abeillé, pp. 129–146. Dordrecht, the
Netherlands:Kluwer.
Marcus,M.,Santorini,B.,andM.A.Marcinkiewicz.1993.BuildingalargeannotatedcorpusofEnglish:
ThePenntreebank. ComputationalLinguistics 19(2):313–330.
Marcus, M., Kim, G., Marcinkiewicz, M. A. et al. 1994. The Penn treebank: Annotating predicate
argument structure. In Proceedings of the Human Language Technology Workshop , Princeton, NJ,
pp.114–119.Princeton,NJ:MorganKaufmannPublishersInc.

186 HandbookofNaturalLanguageProcessing
McDonald, R. and F. Pereira. 2006. Online learning of approximate dependency parsing algorithms. In
Proceedings of the 11th Conference of the European Chapter of the Association for ComputationalLinguistics:EACL2006 ,Trento,Italy,pp.81–88.
Merlo, P. and S. Stevenson. 2001. Automatic verb classiﬁcation based on statistical distribution of
argumentstructure, ComputationalLinguistics 27(3):373–408.
Meyers, A., Reeves, R., Macleod, C. et al. 2004. Annotating noun argument structure for NomBank. In
ProceedingsofLREC2004,Lisbon,Portugal,pp.803–806.
Miltsakaki,E.,Robaldo,L.,Lee,A.,andA.Joshi.2008.SenseannotationinthePenndiscourseTreebank,
ComputationalLinguisticsandIntelligentTextProcessing.LectureNotesinComputerScience 4919:
275–286.
Mírovský, J.2008a. PDT2.0requirements onaquerylanguage. In Proceedings of ACL 2008, Columbus,
OH,pp.37–45.
Mírovský, J. 2008b. Netgraph—Making searching in treebanks easy. In Proceedings of the Third Inter-
national Joint Conference on Natural Language Processing (IJCNLP 2008 ), Hyderabad, India,
pp.945–950,January8–10,2008.
Mladová, L., Zikánová, Š., and E. Hajičová. 2008. From sentence to discourse: Building an annota-
tion scheme for discourse based on Prague Dependency Treebank. In Proceedings of LREC 2008,
Marrakech,Morocco,pp.1–7.
Monachesi,P.,Stevens,G.,andJ.Trapman.2007.Addingsemanticroleannotationtoacorpusofwritten
Dutch. In Proceedings of the Linguistic Annotation Workshop (LAW-07 ), Prague, Czech Republic,
pp.77–84.Stroudsburg,PA:AssociationforComputationalLinguistics.
Moreno, A., Lopez, S., and F. Sanchez. 2003. Developing a syntactic annotation scheme and tools for a
Spanish Treebank. In Treebanks: Building and Using Parsed Corpora , ed. A. Abeillé, pp. 149–164.
Dordrecht,theNetherlands:Kluwer.
Nelson, G., Wallis, S., and B. Aarts. 2001. Exploring Natural Language: Working with the British
ComponentoftheInternationalCorpusofEnglish.Amsterdam,theNetherlands:J.Benjamins.
Nivre, J. 2002. What kinds of trees grow in Swedish soil? A comparison of four annotation schemes for
Swedish.In ProceedingsofTLT2002 ,Sozopol,Bulgaria,eds.Hinrichs,E.andK.Simov,pp.123–138.
Nivre, J. 2003. Theory-supporting treebanks. In Proceedings of the Second Workshop on Treebanks and
LinguisticTheories (TLT2003),VäxjöUniversityPress,Växjö,Sweden,ed.J.NivreandE.Hinrichs,
pp.117–128.
Nivre,J.2006. InductiveDependencyParsing.Text,Speech,andLanguageTechnologySeries,eds.N.Ide
andJ.Véronis,Dordrecht,theNetherlands:Springer,Vol.34,p.216,ISBN1-4020-4888-2.
Oepen, S., Flickinger, D., Toutanova, K., and Ch. D. Manning. 2002a. LinGO Redwoods: A rich and
dynamictreebankforHPSG.In ProceedingsofTLT2002 ,Sozopol,Bulgaria,pp.139–149.
Oepen,S.,Toutanova,K.,Shieber,S.,Manning,Ch.,Flickinger,D.,andT.Brants.2002b.TheLinGORed-
woodstreebank:Motivationandpreliminaryapplications.In Proceedingsofthe19thInternational
ConferenceonComputationalLinguistics (COLING2002),Taipei,Taiwan,pp.1253–1257.
Oﬂazer,K.,Bilge,S.,Hakkani-Tür,D.Z.,andT.Gökhan.2003.BuildingaTurkishtreebank.In Treebanks:
BuildingandUsingParsedCorpora,ed.A.Abeillé,pp.261–277.Dordrecht,theNetherlands:Kluwer.
Pajas,P.2007.TrEdUser’smanual.http://ufal.mﬀ.cuni.cz/ ∼pajas/tred.
Pajas,P.andJ.Štěpánek.2008:Recentadvancesinafeature-richframeworkfortreebankannotation.In
The 22nd International Conference on Computational Linguistics—Proceedings of the Conference ,
pp.673–680.TheColing2008OrganizingCommittee,Manchester,U.K.,ISBN978-1-905593-45-3.
Palmer,M.,Kingsbury,P.,andD.Gildea.2005.Thepropositionbank:Anannotatedcorpusofsemantic
roles.ComputationalLinguistics 31(1):71–106.
Pitler, E., Raghupathy, M., Mehta, H., Nenkova, A., Lee, A., and A. Joshi. 2008. Easily identiﬁable dis-
courserelations.In ProceedingsofCOLING2008:CompanionVolume:PostersandDemonstrations,
Manchester,U.K.
Pito,R.1994.TGrepManualPage.http://www.ldc.upenn.edu/ldc/online/treebank.

TreebankAnnotation 187
Prasad,R.,Dinesh,N.,LeeA.etal.2008.ThePennDiscourseTreebank2.0.In ProceedingsofLREC2008,
Marrakech,Morocco,pp.2961–2968.
Prasad, R., Dinesh, N., Lee, A., Joshi, A., and B. Webber. 2007. Attribution and its Annotation in the
Penn Discourse TreeBank. Traitement Automatique des Langues, Special Issue on Computational
ApproachestoDocumentandDiscourse 47(2):43–64.
Prokopidis, P., Desypri, E., Koutsombogera, M., Papageorgiou, H., and S. Piperidin. 2005. Theoretical
andpracticalissuesintheconstructionofaGreekdependencytreebank.In ProceedingsofTLT2005 ,
UniversitatdeBarcelona,Barcelona,Spain,eds.M.Civit,S.Kübler,andM.A.Martí,pp.149–160.
Pynte,J.andS.Colonna.2000.Decouplingsyntacticparsingfromvisualinspection:Thecaseofrelative
clause attachment in French. In Reading as a Perceptual Process , eds. A. Kennedy, R. Radach,
D.Heller,andJ.Pynte,pp.529–547.Oxford,U.K.:Elsevier.
Rohde,D.2005.TGrep2usermanual.http://www-cgi.cs.cmu.edu/∼dr/TGrep2/tgrep2.pdf.Rosén, V., De Smedt, K., and P. Meurer. 2006. Towards a toolkit linking treebanking and grammar
development.In ProceedingsofTLT2006 ,Prague,CzechRepublic,pp.55–66.
Roventini, A., Ulivieri, M., and N. Calzolari. 2002. Integrating two semantic lexicons, SIMPLE and
ItalWordNet:Whatcanwegain?In ProceedingsofLREC2002,LasPalmas,CanaryIslands,Spain,
pp.1473–1477.
Sampson,G.1995. EnglishfortheComputer.Oxford,U.K.:OxfordUniversityPress.
Scott, W. A. 1955. Reliability of content analysis: The case of nominal scale coding. Public Opinion
Quarterly 19(3),321–325.
Ševčíková,M.,Žabokrtský,Z.,andO.Krůza.2007.NamedentitiesinCzech:Annotatingdataanddevel-
opingNEtagger.In Proceedingsofthe10thInternationalConferenceonText,SpeechandDialogue,
Pilsen, Czech Republic, pp. 188–195. Lecture Notes In Computer Science. Pilsen, Czech Republic:
Springer.
Simov,K.2001.GrammarextractionfromanHPSGcorpus.In ProceedingsoftheRANLP2001Conference,
TzigovChark,Bulgaria,pp.285–287.
Simov, K., Osenova, P., Slavcheva, M. et al. 2002. Building a linguistically interpreted corpus for Bul-
garian: The Bultreebank project. In Proceedings of LREC 2002, Las Palmas, Canary Islands, Spain,
pp.1729–1736.
Simov,K.,Popova,G.,andP.Osenova.2001.HPSG-basedsyntactictreebankofBulgarian(BulTreeBank).
InProceedingsoftheCorpusLinguistics2001Conference ,Lancaster,U.K.,p.561.
Slavcheva, M. 2002. Segmentation layers in the group of the predicate: A case study of Bulgarian within
theBulTreeBankframework.In ProceedingsofTLT2002 ,Sozopol,Bulgaria,pp.199–210.
Srinivas,B.andA.Joshi.1999.Supertagging:Anapproachtoalmostparsing. ComputationalLinguistics
25(2):237–266.
Steiner, I. and L. Kallmeyer. 2002. VIQTORYA—A visual tool for syntactically annotated corpora. In
ProceedingsofLREC2002,LasPalmas,CanaryIslands,Spain,pp.1704–1711.
Surdeanu, M., Johansson, R., Meyers, A., Marquez, L., andJ.Nivre. 2008. TheCoNLL-2008 sharedtask
on joint parsing of syntactic and semantic dependencies. In Proceedings of the 12th Conference on
ComputationalNaturalLanguageLearning (CoNLL-2008),Manchester,U.K.
Toutanova, K. and Ch. D. Manning. 2002. Feature selection for a rich HPSG grammar using decision
trees. InProceedings of the Sixth Conference on Natural Language Learning (CoNLL 2002 ), Taipei,
Taiwan,pp.1–7.
Toutanova, K., Manning, Ch. D., and S. Oepen. 2002. Parse disambiguation for a rich HPSG grammar.
InProceedingsofTLT2002 ,Sozopol,Bulgaria,pp.253–263.
Tutin,A.,Trouilleux,F.,Clouzot,C.,andE.Gaussier.2000.Buildingalargecorpuswithanaphoriclinks
in French: Some methodological issues. In Actes de Discourse Anaphora and Reference Resolution
Colloquium,Lancaster,U.K.
Uszkoreit, H. 2004. New chances for deep linguistic processing. In Proceedings of 19th International
ConferenceonComputationalLinguistics:COLING-2002 ,Taipei,Taiwan,pp.15–27.

188 HandbookofNaturalLanguageProcessing
van der Beek, L., Bouma, G., Malouf, R., and G. van Noord. 2001. The Alpino dependency treebank. In
Computational Linguistics in the Netherlands CLIN 2001, pp. 8–22. Amsterdam, the Netherlands:Rodopi.
Velldal,E.,Oepen,S.,andD.Flickinger.2004.Paraphrasingtreebanksforstochasticrealizationranking.
InProceedingsofTLT2004 ,Tuebingen,Germany,pp.149–160.
Véronis,J.andL.Khouri.1995.Étiquetagegrammaticalmultilingue:leprojetMULTEXT. TAL36(1–2):
233–248.
Veselá,K.,Havelka,J.,andE.Hajičová.2004.Annotators’agreement:Thecaseoftopic-focusarticulation.
InProceedingsofLREC2004,Lisbon,Portugal,pp.2191–2194.
Wallis, S. 2003. Completing parsed corpora: From correction to evolution. In Treebanks: Building and
UsingParsedCorpora,ed.A.Abeillé,pp.61–71.Dordrecht,theNetherlands:Kluwer.
Webber, B. and A. Joshi. 1998. Anchoring a lexicalized tree-adjoining grammar for discourse. In Pro-
ceedingsofACL/COLINGWorkshoponDiscourseRelationsandDiscourseMarkers ,Montreal,QC,
pp.86–92.
Xia,F.,Palmer,M.,Xue,N.etal.2000.DevelopingguidelinesandensuringconsistencyforChinesetext
annotation.In ProceedingsofLREC2000,Athens,Greece,pp.3–10.
Žabokrtský, Z. and I. Kučerová. 2002. Transforming Penn treebank phrase trees into (Praguian)
tectogrammaticaldependencytrees. ThePragueBulletinofMathematicalLinguistics 78:77–94.

