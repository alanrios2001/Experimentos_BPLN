7
Corpus Creation
Richard Xiao
EdgeHillUniversity7.1 Introduction ..........................................................1477.2 CorpusSize............................................................1487.3 Balance,Representativeness,andSampling.......................1497.4 DataCaptureandCopyright........................................1537.5 CorpusMarkupandAnnotation...................................1557.6 MultilingualCorpora................................................1597.7 MultimodalCorpora.................................................1617.8 Conclusions...........................................................161References....................................................................162
7.1 Introduction
A corpus can be deﬁned as a collection of machine-readable authentic texts (including transcripts ofspoken data) that is sampled to be representative of a particular natural language or language variety(McEnery et al. 2006: 5), though “representativeness” is a ﬂuid concept (see Section 7.3). Corpora playan essential role in natural language processing (NLP) research as well as a wide range of linguisticinvestigations.TheyprovideamaterialbasisandatestbedforbuildingNLPsystems.Ontheotherhand,NLPresearchhascontributedsubstantiallytocorpusdevelopment(seeDipper2008foradiscussionoftherelationship between corpus linguistics and computational linguistics), especially in corpus annotation,forexample,part-of-speechtagging(seeChapter10),syntacticparsing(seeChapters8and11),semantictagging(seeChapters5and14),aswellasthealignmentofparallelcorpora(seeChapter16).
There are thousands of corpora in the world, but most of them are created for speciﬁc research
projects and are not publicly available. Xiao (2008) provides a comprehensive survey of a wide range ofwell-known and inﬂuential corpora in English and many other languages, while a survey of corpora forless-studied languages can be found in Ostler (2008). Since corpus creation is an activitythattakestimeand costs money, it is certainly desirable for readers to use such ready-made corpora to carry out theirwork. Unfortunately, however, this is not always feasible or possible. As a corpus is always designed fora particular purpose, the usefulness of a ready-made corpus must be judged with regard to the purposeto which a user intends to put it. Consequently, while there are many corpora readily available, it isoftenthecasethatreaderswillﬁndthattheyarenotabletoaddresstheirresearchquestionsusingready-made corpora. In such circumstances, one must build one’s own corpus. This chapter covers principalconsiderations involved in creating such DIY (“do-it-yourself”) corpora as well as the issues that comeupinmajorcorpuscreationprojects.
This chapter discusses core issues in corpus creation such as corpus size, representativeness, balance
and sampling, data capture and copyright, markup and annotation, as well as peripheral issues such asmultilingualandmultimodalcorpora.
147

148 HandbookofNaturalLanguageProcessing
7.2 Corpus Size
One must be clear about one’s research question (or questions) when planning to build a DIY corpus.Thishelpsyoutodeterminewhatmaterialyouwillneedtocollect.Forexample,ifyouwishtocompareBritish English and American English, you will need to collect spoken and/or written data produced bynative speakers of the two regional varieties of English; if you are interested in how Chinese speakersacquireFrenchasasecondlanguage,youwillthenneedtocollecttheFrenchdataproducedbyChineselearners to create a learner corpus; if you are interested in how the English language has evolved overcenturies, you will need to collect samples of English produced in diﬀerent historical periods to build ahistoricalordiachroniccorpus.Readersarereminded,though,thatmanycorporaofthesekindsarenowalready available (see Xiao 2008 for a recent survey). Having developed an understanding of the type ofdata you need to collect, and having made sure that no ready-made corpus of such material exists, oneneedstoﬁndasourceofdata.Assumingthatthedatacanbefound,onethenhastoaddressthequestionofcorpussize.
How large a corpus do you need? There is no easy answer to this question. The size of the corpus
neededdependsuponthepurposeforwhichitisintendedaswellasanumberofpracticalconsiderations.In the early 1960s, when the processing power and storage capacity of computers were quite limited,a one-million-word corpus such as the Brown corpus (i.e., the Brown University Standard Corpus ofPresent-day American English, see Kucěra and Francis 1967) appeared to be as large a corpus as onecould reasonably build. With the increase in computer power and the availability of machine-readabletexts, however, a corpus of this size is no longer considered large, and in comparison with today’s giantcorpora like the 100-million-word British National Corpus (BNC, see Aston and Burnard 1998) andthe 524-million-word Bank of English (BoE, Collins 2007) it appears somewhat small. An interestingdiscussionofcorpussizeanddesigncanbefoundinKellerandLapata(2003),whocomparesimilaritiesand diﬀerences in the frequencies for bigrams (i.e., two-word clusters) obtained from the BNC andtheWeb.
The availability of suitable data, especially in machine-readable form, seriously aﬀects corpus size. In
building a balanced corpus according to ﬁxed proportions (see Section 7.3), for example, the lack of
data for one text type may accordingly restrict the size of the samples of other text types taken. This isespeciallythecaseforparallelcorpora,asitiscommonfortheavailabilityoftranslationstobeunbalancedacross text types for many languages. For example, it will be much easier to ﬁnd Chinese translationsof English news stories than English translations of Chinese literary texts. While it is often possible totransfer paper-based texts into electronic form using OCR (optical character recognition) software, theprocess costs time and money and is error-prone. Hence, the availability of machine-readable data isoftenthemainlimitingfactorincorpuscreation.
AnotherfactorthatpotentiallylimitsthesizeofaDIYcorpusiscopyright(seeSection7.4forfurther
discussion). Unless the proposed corpus contains entirely out-of-date or copyright-free data, simplygathering available data and using it in a freely available corpus may expose the corpus creator to legalaction. When one seeks copyright clearance, one can face frustration—the construction of the corpus isyour priority, not the copyright holder’s. They may simply ignore you. Their silence cannot be taken asconsent.Copyrightclearanceinbuildingalargecorpusnecessitatesmucheﬀort,trouble,andfrustration.
Nomatterhowimportantlegalconsiderationsmayseem,oneshouldnotlosesightoftheparamount
importanceoftheresearchquestion.Thisquestioncontrolsallofyourcorpus-buildingdecisions,includ-ingthedecisionregardingcorpussize.Eveniftheconditionsdiscussedaboveallowforalargecorpus,itdoesnotmeanthatalargecorpusiswhatyouwant.First,thesizeofthecorpusneededtoexplorearesearchquestionisdependentonthefrequencyanddistributionofthelinguisticfeaturesunderconsiderationinthatcorpus(cf.McEneryandWilson2001:80).AsLeech(1991:8–29)observes,sizeisnotall-important.Small corpora may contain suﬃcient examples of frequent linguistic features. To study features such asthe number of present and past tense verbs in English, for example, a sample of 1000 words may prove

CorpusCreation 149
suﬃcient (Biber 1993). Second, small specialized corpora serve a very diﬀerent yet important purposefromlargemulti-million-wordcorpora(ShimazumiandBerber-Sardinha1996).Itisunderstandablethatcorpora for lexical studies are much larger than those for grammatical studies, because when studyinglexis one is interested in the frequency of the distribution of a word (see Baroni 2009for a discussion ofdistributionsintext),whichcanbemodeledascontrastingwithallothersofthesamecategory(cf.Santos1996:11). In contrast, corpora employed in quantitative studies of grammatical devices can be relativelysmall(cf.Biber1988;Givon1995),becausethesyntacticfreezingpointisfairlylow(Hakulinenetal.1980:104). Third, corporathatneedextensivemanualannotation(e.g., pragmaticannotation)arenecessarilysmall. Fourth, many corpus tools set a ceiling on the number of concordances that can be extracted, forexample, WordSmith version 3.0 can extract a maximum of 16,868 concordances (versions 4.0 and 5.0donothavethislimit).Thismakesitinconvenientforafrequentlinguisticfeaturetobeextractedfromaverylargecorpus.Evenifthiscanbedone,fewresearcherscanobtainusefulinformationfromhundredsof thousands of concordances (cf. Hunston 2002: 25). The data extracted deﬁes manual analysis by asoleresearcherbyvirtueofthesheervolumeofexamplesdiscovered.Ofcourse,IdonotmeanthatDIYcorpora must necessarily be small. A corpus small enough to produce only a dozen concordances of alinguisticfeatureunderconsiderationwillnotbeabletoprovideareliablebasisforquantiﬁcation,thoughitmayactasaspurtoqualitativeresearch.
Itisimportanttonote,however,thatcorpussizeisanissueofongoingdebateincorpuscreation.Some
corpus linguists have argued that size matters (e.g., Krishnamurthy 2000; Sinclair 2004; Granath 2007).Largecorporaarecertainlyofadvantageinlexicographyandinthestudyofinfrequentlinguisticstructures(e.g., Keller and Lapata 2003). Also, NLP and language engineering can have diﬀerent requirements forcorpora from those used in linguistic research as discussed above. Corpora used in NLP and languageengineeringtendtobedomain-orgenre-speciﬁcspecializedcorpora(e.g.,thosecomposedofnewspapersor telephone-based transactional dialogues), data for which are often easier to collect in large amountsthan for balanced corpora. Furthermore, larger corpora are more reliable in statistical modeling, whichisessentialinnaturallanguageprocessingandlanguageengineering.Inaword,thepointIwishtomakeis that the optimum size of a corpus is determined by the research question the corpus is intended toaddressaswellaspracticalconsiderations.
7.3 Balance, Representativeness, and Sampling
Oneofthecommonlyaccepteddeﬁningfeaturesofacorpus,whichdistinguishesacorpusfromanarchive(i.e., a random collection of texts), is representativeness . A corpus is designed to represent a particular
language or language variety whereas an archive is not. What does representativeness mean in corpuslinguistics?AccordingtoLeech(1991:27),acorpusisthoughttoberepresentativeofthelanguagevarietyit is supposed to represent if the ﬁndings based on its contents can be generalized to the said languagevariety. Biber (1993: 243) deﬁnes representativeness from the viewpoint of how this quality is achieved:“Representativeness refers to the extent to which a sample includes the full range of variability in apopulation.”Acorpusisessentiallyasampleofalanguageorlanguagevariety(i.e.,population).Samplingisentailedinthecreationofvirtuallyanycorpusofalivinglanguage.Inthisrespect,therepresentativenessof most corpora is to a great extent determined by two factors: the range of genres,domains,a n d media
includedinacorpus(i.e., balance)andhowthetextchunksforeachgenreareselected(i.e., sampling).
Thecriteriausedtoselecttextsforinclusioninacorpusareprincipallyexternaltothetextsthemselves
and dependent upon the intended use for the corpus (Aston and Burnard 1998: 23). The distinctionbetween external and internal criteria corresponds to Biber’s (1993: 243) situational vs. linguistic per-spectives. External criteria are deﬁned situationally irrespective of the distribution of linguistic featureswhereas internal criteria are deﬁned linguistically, taking into account the distribution of such features.Internal criteria have sometimes been proposed as a measure of corpus representativeness (e.g., Otlo-getswe 2004). In my view, it is problematic; indeed it is circular, to use internal criteria such as the

150 HandbookofNaturalLanguageProcessing
distributionofwordsorgrammaticalfeaturesastheprimaryparametersfortheselectionofcorpusdata.A corpus is typically designed to study linguistic distributions. If the distribution of linguistic featuresis predetermined when the corpus is designed, there is no point in analyzing such a corpus to discovernaturally occurring linguistic feature distributions. The corpus has been skewed by design. As such, Iagree with Sinclair (2005) when he says that the texts or parts of texts to be included in a corpus shouldbeselectedaccordingtoexternalcriteriasothattheirlinguisticcharacteristicsare,initiallyatleast,inde-pendent of the selection process. This view is also shared by many other scholars including Atkins et al.(1992: 5–6) and Biber (1993: 256). Yet, once a corpus is created by using external criteria, the results ofcorpusanalysiscanbeusedasfeedbacktoimprovetherepresentativenessofthecorpus.InBiber’s(1993:256)words,“thecompilationofarepresentativecorpusshouldproceedinacyclicalfashion.”
Inadditiontotextselectioncriteria,Hunston(2002:30)suggeststhatanotheraspectofrepresentative-
ness is change over time: “Any corpus that is not regularly updated rapidly becomes unrepresentative.”Therelevanceofpermanenceincorpusdesignactuallydependsonhowweviewacorpus,thatis,whethera corpus should be viewed as a static or dynamic language model. The static view typically applies to asamplecorpus whereasadynamicviewappliestoa monitorcorpus.Amonitorcorpusisprimarilydesigned
totrackchangesfromdiﬀerentperiods(cf.Hunston2002:16).Itisparticularlyusefulintrackingrelativelyrapid language change, such as the development and the life cycle of neologisms. Monitor corpora areconstantly(e.g.,annually,monthly,orevendaily)supplementedwithfreshmaterialandkeepincreasingin size. For example, the Bank of English (BoE) has increased in size progressively since its inception inthe1980s(Hunston2002:15)andisaround524millionwordsatpresent.Incontrast,asamplecorpusisdesignedtorepresentastaticsnapshotofaparticularlanguagevarietyataparticulartime.Staticsamplecorpora,ifresampled,mayalsoallowthestudyofslowerpacedlanguagechangeovertime.Forexample,theLOB(Lancaster-Oslo-BergenCorpusofBritishEnglish,Johanssonetal.1978)andBrowncorporaaresupposedtorepresentwrittenBritishandAmericanEnglishintheearly1960s;andtheirrecentupdates,Freiberg-LOB(FLOB,seeHundtetal.1998)andFreiberg-Brown(Frown,seeHundtetal.1999)corpora,represent written British and American English in the early 1990s respectively. Sample corpora such asthesemakeitpossibletotracklanguagechangeovertheinterveningthreedecades.
In addition to the distinction between sample and monitor corpora, representativeness has diﬀerent
meanings for generalandspecialized corpora. Corpora of the ﬁrst type typically serve as a basis for an
overall description of a language or language variety. The BNC corpus, for example, is supposed torepresent modern British English as a whole. In contrast, a specialized corpus tends to be speciﬁc to aparticulardomain(e.g.,medicineorlaw)orgenre(e.g.,newspapertextoracademicprose).Forageneralcorpus, it is understandable that it should cover, proportionally, as many text types as possible so thatthe corpus is maximally representative of the language or language variety it is supposed to represent.Evenaspecializedcorpus,forexample,onedealingwithtelephonecallstoanoperatorserviceshouldbebalanced by including within it a wide range of types of operator conversations (e.g., line fault, requestfor an engineer call out, number check, etc.) between a range of operators and customers (cf. McEneryetal.2001)sothatitcanbeclaimedtorepresentthisvarietyoflanguage.
Whilebothgeneralandspecializedcorporashouldberepresentativeofalanguageorlanguagevariety,
they have diﬀerent criteria for representativeness. The representativeness of a general corpus dependsheavilyonsamplingfromabroadrangeofgenreswhereastherepresentativenessofaspecializedcorpus,at the lexical level at least, can be measured by the degree of closure(McEnery and Wilson 2001: 166)
orsaturation (Belica 1996: 61–74) of the corpus. Closure/saturation for a particular linguistic feature
(e.g., size of lexicon) of a variety of language (e.g., computer manuals) means that the feature appearsto be ﬁnite or is subject to very limited variation beyond a certain point. To measure the saturation of acorpus, the corpus is ﬁrst divided into segments of equal size based on its tokens. The corpus is said tobesaturatedatthelexicallevelifeachadditionofanewsegmentyieldsapproximatelythesamenumberof new lexical items as the previous segment, that is, when the curve of lexical growth is asymptotic,or ﬂattening out. The notion of saturation is claimed to be superior to such concepts as balance for itsmeasurability(Teubert2000).Itshouldbenoted,however,thatsaturationisonlyconcernedwithlexical

CorpusCreation 151
features.Whileitmaybepossibletoadaptsaturationtomeasurefeaturesotherthanlexicalgrowth,therehavebeenfewattemptstodothistodate(thoughseeMcEneryandWilson2001:176–183forastudyofpart-of-speechandsentencetypeclosure).
Itappears,then,thattherepresentativenessofacorpus,especiallyageneralcorpus,dependsprimarily
onhowbalancedthecorpusis;inotherwords,therangeoftextcategoriesincludedinthecorpus.Aswithrepresentativeness,theacceptablebalanceofacorpusisdeterminedbyitsintendeduses.Hence,ageneralcorpus that contains both written and spoken data (e.g., the BNC) is balanced; so are written corporasuchasBrownandLOB,andspokencorporasuchastheCambridgeNottinghamCorpusofDiscourseinEnglish(CANCODE).Abalancedcorpususuallycoversawiderangeoftextcategoriesthataresupposedto be representative of the language or language variety under consideration. These text categories aretypicallysampledproportionallyforinclusioninacorpussothat“itoﬀersamanageablysmallscalemodelofthelinguisticmaterialwhichthecorpusbuilderswishtostudy”(Atkinsetal.1992:6).
Balance appears to be a more important issue for a static sample corpus than for a dynamic monitor
corpus.Ascorporaofthelattertypeareupdatedfrequently,itisusually“impossibletomaintainacorpusthatalsoincludestextofmanydiﬀerenttypes,assomeofthemarejusttooexpensiveortimeconsumingtocollectonaregularbasis”(Hunston2002:30–31).Thebuildersofmonitorcorporaappeartofeelthatbalancehasbecomelessofapriority—sheersizeseemstohavebecomethebasisofthecorpus’sauthority,under theimplicitandarguably unwarranted assumption thatacorpus will ineﬀectbalanceitselfwhenitreachesasubstantialsize.
Whilebalanceandrepresentativenessareimportantconsiderationsincorpusdesign, theydependon
the research question and the ease with which data can be captured and thus must be interpreted inrelativeterms.Inotherwords,acorpusshouldonlybeasrepresentativeaspossibleofthelanguagevarietyunderconsideration.Forexample,ifonewantsacorpusthatisrepresentativeofgeneralEnglish,acorpusrepresentative of newspapers will not do; if one wants a corpus representative of newspapers, a corpusrepresentativeof TheTimes willnotdo.Corpusbalanceandrepresentativenessareﬂuidconceptsthatlink
directlytoresearchquestions.Theresearchquestiononehasinmindwhenbuilding(orthinkingofusing)acorpusdeﬁnestherequiredbalanceandrepresentativeness.Anyclaimofcorpusbalanceislargelyanactoffaithratherthanastatementoffactas,atpresent,thereisnoreliablescientiﬁcmeasureofcorpusbalance.Rather the notion relies heavily on intuition and best estimates. Another argument supporting a looseinterpretationofbalanceandrepresentativenessisthatthesenotions perseareopentoquestion(cf.Hun-
ston2002: 28–30). ToachievecorpusrepresentativenessalongthelinesoftheBrowncorpusmodelonemustknowhowofteneachgenreisusedbythelanguagecommunityinthe samplingperiod.Yetitisunre-
alistic to determine the correlation of language production and reception in various genres (cf. Hausser1999: 291; Hunston 2002: 29). The only solution to this problem is to treat corpus-based ﬁndings withcaution.Itisadvisabletobaseyourclaimsonyourcorpusandavoidunreasonablegeneralizations.Like-wise,conclusionsdrawnfromaparticularcorpusmustbetreatedasdeductionsratherthanfacts(cf.alsoHunston2002:23).Withthatsaid,however,IentirelyagreewithAtkinsetal.(1992:6),whocommentthat:
Itwouldbeshort-sightedindeedtowaituntilonecanscientiﬁcallybalanceacorpusbeforestartingtouseone,andhastytodismisstheresultsofcorpusanalysisas“unreliable”or“irrelevant”becausethecorpususedcannotbeprovedtobe‘balanced.’
Given that language is inﬁnite whereas a corpus is ﬁnite in size, sampling is unavoidable in corpus cre-
ation.Unsurprisingly,corpusrepresentativenessandbalancearecloselyassociatedwithsampling.Giventhat we cannot exhaustively describe natural language, we need to sample it in order to achieve a levelof balance and representativeness that matches our research question. Having decided that sampling isinevitable, there are important decisions that must be made about how to sample so that the resultingcorpusisasbalancedandrepresentativeaspracticallypossible.
As noted earlier, with few exceptions, a corpus is typically a sample of a much larger population.
A sample is assumed to be representative if what we ﬁnd for the sample also holds for the general

152 HandbookofNaturalLanguageProcessing
population(cf.ManningandSchütze1999:119).Inthestatisticalsense,samplesarescaleddownversionsofalargerpopulation(cf.Váradi2000).Theaimofsamplingtheory“istosecureasamplewhich,subjectto limitations of size, will reproduce the characteristics of the population, especially those of immediateinterest,ascloselyaspossible”(Yates1965:9).
In order to obtain a representative sample from a population, the ﬁrst concern to be addressed is to
deﬁnethesamplingunit andtheboundariesofthepopulation.Forwrittentext,forexample,asampling
unit may be a book, a periodical, or a newspaper. The population is the assembly of all sampling unitswhile the list of sampling units is referred to as a sampling frame . The population from which samples
for the pioneering Brown corpus were drawn, for instance, was all written English text published in theUnitedStatesin1961whileitssamplingframewasalistofthecollectionofbooksandperiodicalsintheBrownUniversityLibraryandtheProvidenceAthenaeum.FortheLOBcorpus,thetargetpopulationwasall written English text published in the United Kingdom in 1961 while its sampling frame included theBritish National Bibliography Cumulated Subject Index 1960–1964 for books and Willing’s Press Guide
1961forperiodicals.
In corpus design, a population can be deﬁned in terms of language production, language reception,
or language as a product. The ﬁrst two designs are basically demographically oriented as they use thedemographicdistribution(e.g.,age,sex,socialclass)oftheindividualswhoproduce/receivelanguagedatato deﬁne the population while the last design is organized around text category/genre of language data.As noted earlier, the Brown and LOB corpora were created using the criterion of language as a productwhiletheBNCdeﬁnesthepopulationprimarilyonthebasisofbothlanguageproductionandreception.However,itcanbenotoriouslydiﬃculttodeﬁneapopulationorconstructasamplingframe,particularlyfor spoken language, for which there are no ready-made sampling frames in the form of catalogues orbibliographies.
Once the target population and the sampling frame are deﬁned, diﬀerent sampling techniques can
be applied to choose a sample that is as representative as possible of the population. A basic samplingmethod is simple random sampling. With this method, all sampling units within the sampling frame
are numbered and the sample is chosen by use of a table of random numbers. As the chance of anitem being chosen correlates positively with its frequency in the population, simple random samplingmay generate a sample that does not include relatively rare items in the population, even though theycan be of interest to researchers. One solution to this problem is stratiﬁed random sampling,w h i c h
ﬁrst divides the whole population into relatively homogeneous groups (so-called strata) and then sam-ples each stratum at random (see Evert 2006 for a discussion of random sampling in corpus creation).In the Brown and LOB corpora, for example, the target population for each corpus was ﬁrst groupedinto 15 text categories such as news reportage, academic prose, and diﬀerent types of ﬁction; sampleswere then drawn from each text category. Demographic sampling, which ﬁrst categorizes samplingunits in the population on the basis of speaker/writer age, sex and social class, is also a type of strat-iﬁed sampling. Biber (1993) observes that a stratiﬁed sample is never less representative than a simplerandomsample.
Afurtherdecision tobe madein samplingrelatesto sample size. For example, withwrittenlanguage,
shouldwesamplefulltexts(i.e.,wholedocuments)ortextchunks?Iftextchunksaretobesampled,shouldwesampletextinitial,middle,orendchunks?Fulltextsamplesarecertainlyusefulintextlinguistics,yettheymaypotentiallyconstituteachallengeindealingwithvexatiouscopyrightissues.Also,givenitsﬁniteoverall size, the coverage of a corpus including full texts may not be as balanced as a corpus includingtextsegmentsofconstantsize.Asaresult,“thepeculiarityofanindividualstyleortopicmayoccasionallyshow through into the generalities” (Sinclair 1991: 19). Aston and Burnard (1998: 22) argue that thenotionof“completeness”maysometimesbe“inappropriateorproblematic.”Assuch,unlessacorpusiscreatedtostudysuchfeaturesastextualorganization,orcopyrightholdershavegrantedyoupermissiontousefulltexts,itisadvisabletosampletextsegments.AccordingtoBiber(1993:252),frequentlinguisticfeaturesarequitestableintheirdistributionsandhenceshorttextchunks(e.g.,2000runningwords)areusually suﬃcient for the study of such features while rare features are more varied in their distribution

CorpusCreation 153
andthusrequirelargersamples(Baroni2009).Inselectingsamplestobeincludedinacorpus,however,attentionmustalsobepaidtoensurethattextinitial,middle,andendsamplesarebalanced.
Another sampling issue, which particularly relates to stratiﬁed sampling, is the proportion and the
number of samples for each text category. The numbers of samples across text categories should beproportional to their frequencies and/or weights in the target population in order for the resultingcorpus to be considered as representative. Nevertheless, it has been observed that, as with deﬁning atarget population, such proportions can be diﬃcult to determine objectively (cf. Hunston 2002: 28–30).Furthermore,thecriteriausedtoclassifytextsintodiﬀerentcategoriesorgenresareoftendependentonintuitions.Assuch,therepresentativenessofacorpus,asnoted,shouldbeviewedasastatementofbeliefratherthanfact.IntheBrowncorpus,forexample,apanelofexpertsdeterminedtheratiosbetweenthe15 text categories. As for the number of samples required for each category, Biber (1993) demonstratesthatten2000-wordsamplesaretypicallysuﬃcient.
The above discussion suggests that in creating a balanced, representative corpus, stratiﬁed random
sampling is to be preferred over simple random sampling while diﬀerent sampling methods shouldbe used to select diﬀerent types of data. For written texts, a text typology established on the basis ofexternalcriteriaishighlyrelevantwhileforspokendatademographicsamplingisappropriate.However,context-governed sampling must complement samples obtained from demographic sampling so thatsomecontextuallygovernedlinguisticvariationscanbeincludedintheresultingcorpus.
7.4 Data Capture and Copyright
For pragmatic reasons noted in Section 7.2, electronic data is preferred over paper-based material inbuilding DIY corpora. The World Wide Web (WWW) is an important source of machine-readabledata for many languages. For example, digital text archives mounted on the Web such as Oxford TextArchive (http://ota.ahds.ac.uk/) and Project Gutenberg (http://www.gutenberg.org/catalog/) as well asthe digital collections of some university libraries (e.g., http://lib.virginia.edu/digital/collections/text/,http://onlinebooks.library.upenn.edu/)providelargeamountsofpubliclyaccessibleelectronictexts.
The web pages on the Internet normally use Hypertext Markup Language (i.e., HTML) to enable
browserslikeInternetExplorerorNetscapetodisplaythemproperly.Whilethetags(includedinangledbrackets)aretypicallyhiddenwhenatextisdisplayedinabrowser,theydoexistinthesourceﬁleofawebpage. Hence, an important step in building DIY corpora using web pages is tidying up the downloadeddatabyconvertingwebpagestoplaintext,ortosomedesiredformat,forexample,XML(seeSection7.5).Inthissection,IwillintroducesomeusefultoolstohelpreaderstodownloaddatafromtheInternetandcleanupthedownloadeddatabyremovingorconvertingHTMLtags.Thesetoolsareeitherfreewareorcommercialproductsavailableataﬀordableprices.
Whileitispossibletodownloaddatapagebypage,whichisrathertimeconsuming,thereareanumber
oftoolsthatfacilitatedownloadingallofthewebpagesonaselectedWebsiteinonego(e.g.,Grab-a-Siteor HTTrack), or more usefully, downloading related web pages (e.g., containing certain key words) atonego.TheWordSmithTools(versions4.0and5.0),forexample,incorporatestheWebGetterfunctionthathelpsuserstobuildDIYcorpora.WebGetterdownloadsrelatedWebpageswiththehelpofasearchengine (Scott 2003: 87). Users can specify the minimum ﬁle length or word number (small ﬁles maycontain only links to a couple of pictures and nothing much else), required language and, optionally,requiredwords.Webpagesthatsatisfytherequirementsaredownloadedsimultaneously(cf.Scott2003:88–89).TheWebGetterfunction,however,doesnotremovetheHTMLmarkuporconvertittoXML.Thedownloaded data needs to be tidied up using other tools before they can be loaded into a concordancerorfurtherannotated.
Another tool worth mentioning is the freeware Multilingual Corpus Toolkit (MLCT, see Piao et al.
2002).TheMLCTrunsinJavaRuntimeEnvironment(JRE)version1.4orabove,whichisfreelyavailableon the Internet. In addition to many other functions needed for multilingual language processing (e.g.,

154 HandbookofNaturalLanguageProcessing
markup, part-of-speech tagging, and concordancing), the system can be used to extract texts from theInternet.Onceawebpageisdownloaded,itiscleanedup.Oneweaknessoftheprogramisthatitcanonlydownload one web page at a time. Yet this weakness is compensated for by another utility that convertsall of the web pages in a ﬁle folder (e.g., the web pages downloaded using the Webgetter function ofWordSmithversion4.0)toadesiredtextformatinonego.AnotherattractionoftheMLCTisthatitcanmarkuptextualstructure(e.g.,paragraphsandsentences)automatically.
Finally, the BootCaT Toolkit provides a suite of utilities that allow the user to bootstrap specialized
corpora and terms from the Web on the basis of a small set of terms as input (Baroni and Bernardini2004).ReadersinterestedintheWebascorpuscanrefertoKilgarriﬀandGrefenstette(2003),BaroniandBernardini(2006),andHundtetal.(2007),andrefertoKellerandLapata(2003)foracomparisonofthefrequenciesobtainedfromtheWebandabalancedcorpussuchastheBNC.
A major issue in data collection is copyright. While it is possible to use copyright-free material in
corpus creation, such data are usually old and a corpus consisting entirely of such data is not usefulif one wishes to study contemporary English, for example. Such corpora are even less useful in NLPresearch, which tends to focus on current language use. Simply using copyrighted material in a corpuswithout the permission of the copyright holders may cause unnecessary trouble. In terms of purposes,corporaaretypicallyoftwotypes:forcommercialpurposesorfornon-proﬁt-makingacademicresearch.It is clearly unethical and illegal to use the data of other copyright holders to make money solely foroneself.Creatorsofcommercialcorporausuallyreachanagreementwithcopyrightholdersastohowtheproﬁtwillbeshared.Publishersascopyrightholdersarealsousuallywillingtocontributetheirdatatoacorpus-building project if they can beneﬁt from the resulting corpus (e.g., the British National Corpus,theLongmanCorpusNetwork,andtheCambridgeInternationalCorpus).
In creating DIY corpora for use in non-proﬁt-making research, you might think that you need not
worry about copyright if you are not selling your corpus to make a proﬁt. Sadly, this is not the case.Copyright holders may still take you to the court. They may, for example, suﬀer a loss of proﬁt becauseyouruseoftheirmaterialdiminishestheirabilitytosellit:whybuyabookwhenyoucanreaditforfreeinacorpus(cf.alsoAmsler2002)?Copyrightissuesincorpuscreationarecomplexandunavoidable.Whilecorpuslinguistshavebroughtthemupperiodicallyfordiscussion,thereisasyetnosatisfactorysolutiontotheissueofcopyrightincorpuscreation.
The situation is complicated further by variation in copyright law internationally. According to the
copyright law of EU countries, the term of copyright for published works in which the author owns thecopyright is the author’s lifetime plus 70 years. Under U.S. law, the term of copyright is the author’slifetime plus 50 years; but for works published before 1978, the copyright term is 75 years if the authorrenewedthecopyrightafter28years.
One is able to make some use of copyrighted text without getting clearance, however. Under the
convention of “fair dealing” in copyright law, permission need not be sought for short extracts notexceeding 400 words from prose (or a total of 800 words in a series of extracts, none exceeding 300words);acitationfromapoemshouldnotexceed40linesoronequarterofthepoem.SoonecanresorttousingsmallsamplestobuildperfectlylegalDIYcorporaonthegroundsoffairusage. Butthesizesofsuchsamplesaresosmallastojeopardizeanyclaimofbalanceorrepresentativeness.
I maintain that the fair use doctrine as it applies to citations in published works should operate
diﬀerentlywhenitappliestocorpuscreationsoastoallowcorpuscreatorstobuildcorporaquicklyandlegally.Thelimitedreproductionofcopyrightedworks,forinstance,inchunksof3000wordsorone-thirdofthewholetext(whicheverisshorter)shouldbeprotectedunderfairusefornon-proﬁt-makingresearchandeducationalpurposes.Apositionstatementalongtheselineshasbeenproposedbythecorpususingcommunity articulating the point of view that distributing minimal citations of copyrighted texts andallowingthepublicindirectaccesstoprivatelyheldcollectionsofcopyrightedtextsforstatisticalpurposesareanecessarypartofcorpuslinguisticsresearchandshouldbeinherentlyprotectedasfairuse,particularlyinnon-proﬁt-makingresearchcontexts(seeCooper2003).Thisaimisnotalegalrealityyet,however.Itwillundoubtedlytaketimeforabalancebetweencopyrightandfairuseforcorpusbuildingtodevelop.

CorpusCreation 155
So, what does one do about copyright? My general advice is: if you are in doubt, seek permission. It
is usually easier to obtain permission for samples than for full texts, and easier for smaller samples thanfor larger ones. If you show that you are acting in good faith, and only small samples will be used innon-proﬁt-makingresearch,copyrightholdersaretypicallypleasedtograntyoupermission.Ifsomedorefuse,yourememberitistheirrighttodosoandmoveontotryothercopyrightholdersuntilyouhaveenoughdata.
ItappearseasiertoseekcopyrightclearanceforWebpagesontheInternetthanformaterialcollected
from printed publications. It has been claimed (Spoor 1996: 67) that a vast majority of the documentspublished on the Internet are not protected by copyright, and that many authors of texts are happy tobe able to reach as many people as possible. However, readers should bear in mind that this may notbe the case. For example, Cornish (1999: 141) argues that probably all material available on the Web iscopyrighted,andthatdigitalpublicationsshouldbetreatedthesamewayasprintedworks.
Copyrightlawisgenerallyformulatedtopreventsomeonefrommakingmoneyfromsellingintellectual
propertybelongingtootherpeople.Unlessyouaremakingmoneyusingtheintellectualpropertyofotherpeople,oryouaresomehowcausingalossofincometothem,itisquiteunlikelythatcopyrightproblemswill arise when building a corpus. Yet copyright law is in its infancy. Diﬀerent countries have diﬀerentrules, and it has been argued that with reference to corpora and copyright there is very little which isobviouslylegalorillegal(cf.Kilgarriﬀ2002).Myﬁnalwordofadviceis:proceedwithcaution.
7.5 Corpus Markup and Annotation
DatacollectedusingasamplingframeasdiscussedinSection7.3formsarawcorpus.Yetsuchdatatypicallyneeds to be processed before use. For example, spoken data needs to be transcribed from audio/videorecordings;writtentextsmayneedtoberenderedmachinereadable,iftheyarenotalready,bykeyboardingorOCRscanning.Beyondthisbasicprocessing,however,liesanotherformofpreparatorywork—corpusmarkup.Inaddition,inordertoextractlinguisticinformationfromacorpus,suchinformationmustﬁrstofallbeencodedinthecorpus,aprocessthatistechnicallyknownas“corpusannotation.”
Corpus markup is a system of standard codes inserted into a document stored in electronic form
to provide information about the text itself (i.e., text metadata) and govern formatting, printing orother processing (i.e., structural organization). While metadata markup can be embedded in the samedocument or stored in a separate but linked document (see below for further discussion of embeddingvs. stand-alone annotation), structural markup has to be embedded in the text. Both types of markupsare important in corpus creation for at least three reasons. First, the corpus data basically consists ofsamplesofusedlanguage.Thismeansthattheseexamplesoflinguisticusagearetakenoutofthecontextinwhichtheyoriginallyoccurredandtheircontextualinformationislost.Burnard(2002)comparessuchout-of-contextexamplestoalaboratoryspecimenandarguesthatcontextualinformation(i.e.,metadataor “data about data”) is needed to restore the context and to enable us to relate the specimen to itsoriginalhabitat.Incorpuscreation,therefore,itisimportanttorecoverasmuchcontextualinformationas practically possible to alleviate or compensate for such a loss. Second, while it is possible to grouptextsand/ortranscriptsofsimilarqualitytogetherandnametheseﬁlesconsistently(e.g.,ashappenswiththe LOB and Brown corpora), ﬁlenames can provide only a tiny amount of extra-textual information(e.g., texttypesforwrittendataandsociolinguisticvariablesofspeakersforspokendata)andnotextualinformation (e.g., paragraph/sentence boundaries and speech turns) at all. Yet such data are of greatinterest to linguists as well as NLP researchers and thus should be encoded, separately from the corpusdataperse,inacorpus.Markupaddsvaluetoacorpusandallowsforabroaderrangeofresearchquestions
tobeaddressedasaresult.Finally,preprocessingwrittentexts,andparticularlytranscribingspokendata,alsoinvolvesmarkup.Forexample,inwrittendata,whengraphics/tablesareremovedfromtheoriginaltexts,placeholdersmustbeinsertedtoindicatethelocationsandtypesofomissions;quotationsinforeignlanguagesshouldalsobemarkedup.Inspokendata,pausingandparalinguisticfeaturessuchaslaughter

156 HandbookofNaturalLanguageProcessing
needtobemarkedup.Corpusmarkupisalsoneededtoinserteditorialcomments,whicharesometimesnecessary in preprocessing written texts and transcribing spoken data. What is done in corpus markuphasaclearparallelinexistinglinguistictranscriptionpractices.Markupisessentialincorpuscreation.
Havingestablishedthatmarkupisimportantincorpuscreation,wecannowmoveontodiscussmarkup
schemes. Itgoeswithoutsayingthatextra-textualandtextualinformationshouldbekeptseparatefromthecorpusdata(textsortranscripts)proper.Yettherearediﬀerentschemesonemayusetoachievethisgoal. One of the earliest markup schemes was COCOA. COCOA references consist of a set of attributenamesandvaluesenclosedinangledbrackets,asin <AWILLIAMSHAKESPEARE >,whereA(author)
istheattributenameandWILLIAMSHAKESPEAREistheattributevalue.COCOAreferences,however,only encode a limited set of features such as authors, titles, and dates (cf. McEnery and Wilson 2001:35). Recently, a number of more ambitious metadata markup schemes have been proposed, includingfor example, the Dublin Core Metadata Initiative (DCMI, see Dekkers and Weibel 2003), the OpenLanguageArchivesCommunity(OLAC,seeBirdandSimons2000),theISLEMetadataInitiative(IMDI,seeWittenburgetal.2002),theTextEncodingInitiative(TEI,seeSperberg-McQueenandBurnard2002),andtheCorpusEncodingStandard(CES,seeIdeandPriest-Dorman2000).DCMIprovides15elementsused primarily to describe authored Web resources. OLAC is an extension of DCMI, which introducesreﬁnementstonarrowdownthesemanticscopeofDCMIelementsandaddsanextraelementtodescribethelanguage(s)coveredbytheresource.IMDIappliestomultimediacorpora(seeSection7.7)andlexicalresources as well. From even this brief review it should be clear that there is currently no widely agreedstandard way of representing metadata, though all of the current schemes do share many features andsimilarities.PossiblythemostinﬂuentialschemesincorpusbuildingareTEIandCES,henceIwilldiscussbothoftheseinsomedetailhere.
TheTextEncodingInitiative(TEI)wassponsoredbythreemajoracademicassociationsconcernedwith
humanitiescomputing:theAssociationforComputationalLinguistics(ACL),theAssociationforLiteraryandLinguisticComputing(ALLC),andtheAssociationforComputersandtheHumanities(ACH).Theaim of the TEI guidelines is to facilitate data exchange by standardizing the markup or encoding ofinformation stored in electronic form. In TEI, each individual text (referred to as “document”) consistsof two parts: header (typically providing text metadata) and body (i.e., the text itself), which are in turncomposedofdiﬀerent“elements.”InaTEIheader(taggedas <teiHeader >),forexample,therearefour
principalelements(seeBurnard2002):
•A ﬁle description (tagged as <ﬁleDesc>) containing a full bibliographic description of an
electronicﬁle.
•Anencodingdescription(taggedas <encodingDesc >),whichdescribestherelationshipbetween
anelectronictextandthesourceorsourcesfromwhichitwasderived.
•A text proﬁle (tagged as <proﬁleDesc>), containing a detailed description of non-bibliographic
aspects of a text, speciﬁcally the languages and sublanguages used, the situation in which it wasproduced,theparticipantsandtheirsetting.
•A revision history (tagged as <revisionDesc>), which records the changes that have been made
toaﬁle.
Eachelementmaycontainembeddedsub-elementsatdiﬀerentlevels.Ofthese,however,only <ﬁleDesc>
isrequiredtobeTEI-compliant;alloftheothersareoptional.Hence,aTEIheadercanbeverycomplex,or it can be very simple, depending upon the document and the degree of bibliographic control sought.ThebodypartofaTEIdocumentisalsoconceivedasbeingcomposedofelements.Inthiscase,anelementcanbeanyunitoftext, forexample, chapter, paragraph, sentence, orword. Formalmarkupinthebody(i.e., structural markup) is by far rarer than in the header (for metadata markup). It is primarily used toencodetextualstructuressuchasparagraphsandsentences.NotethattheTEIschemeappliestoboththemarkupofmetadataandtextualstructureaswellastheannotationofinterpretativelinguisticanalysis.
TheTEIschemecanbeexpressedusinganumberofdiﬀerentformallanguages.Theﬁrsteditionsused
the Standard Generalized Markup Language (SGML); the more recent editions (i.e., TEI P4, 2002 and

CorpusCreation 157
TEI P5, 2007) can be expressed in the Extensible Markup Language (XML). SGML and XML are verysimilar, both deﬁning a representation scheme for texts in electronic form, which is device and systemindependent. SGML is a very powerful markup language, but associated with this power is complexity.XML is a simpliﬁed subset of SGML intended to make SGML easy enough for use on the Web. Hence,while all XML documents are valid SGML documents, the reverse is not true. Nevertheless, there aresome important surface diﬀerences between the two markup languages. End tags can optionally be leftout in SGML but they cannot in XML. An attribute name (i.e., generic identiﬁer) in SGML may or maynotbecasesensitive,butitisalwayscasesensitiveinXML.Unlessitcontainsspacesordigits,anattributevalueinSGMLmaybegivenwithoutdouble(orsingle)quoteswhereasquotesaremandatoryinXML.
AstheTEIguidelinesareexpresslydesignedtobeapplicableacrossabroadrangeofapplicationsand
disciplines,treatingnotonlytextualphenomena,theyaredesignedformaximumgeneralityandﬂexibility(cf. Ide 1998). As such, about 500 elements are predeﬁned in the TEI guidelines. While these elementsmake TEI very powerful and suitable for the general purpose encoding of electronic texts, they also addcomplexity to the scheme. In contrast, the Corpus Encoding Standard (CES) is designed speciﬁcally fortheencodingoflanguagecorpora.CESisdescribedas“simpliﬁed”TEIinthatitincludesonlythesubsetof the TEI tagset relevant to corpus-based work. While it simpliﬁes the TEI speciﬁcations, CES alsoextendstheTEIguidelinesbyaddingnewelementsnotcoveredinTEI,specifyingtheprecisevaluesforsomeattributes, markingrequired/recommended/optional elements, andexplicatingdetailedsemanticsforelementsrelevanttolanguageengineering(e.g.,sentence,word,etc.)(cf.Ide1998).
CEScoversthreeprincipaltypesofmarkups:(1)document-widemarkup,whichusesmoreorlessthe
sametagsasforTEItoprovideabibliographicdescriptionofthedocument,encodingdescription,etc.;(2)grossstructuralmarkup,whichencodesstructuralunitsoftext(suchasvolume,chapter,etc.)downtothelevelofparagraph(butalsoincludingfootnotes,titles,headings,tables,ﬁgures,etc.)andspeciﬁesnormal-izationtorecommendedcharactersetsandentities; (3)markupforsub-paragraphstructures, includingsentences,quotations,wordabbreviations,names,dates,termsandcitedwords,etc.(seeIde1998).
CES speciﬁes a minimal encoding level that corpora must achieve to be considered standardized in
termsofdescriptiverepresentationaswellasgeneralarchitecture.ThreelevelsoftextstandardizationarespeciﬁedinCES:(1)themetalanguagelevel,(2)thesyntacticlevel,and(3)thesemanticlevel.Standardiza-tionatthemetalanguagelevelregulatestheformofthesyntacticrulesandthebasicmechanismsofmarkupschemes. Users can use a TEI-compliant Document Type Deﬁnition (DTD) to deﬁne tag names as wellas “document models” that specify the relations among tags. As texts may still have diﬀerent documentstructuresandmarkupsevenwiththesamemetalanguagespeciﬁcations,standardizationatthesyntacticlevel speciﬁes precise tag names and syntactic rules for using the tags. It also provides constraints oncontent.However,thedatasenderandthedatareceivercaninterpreteventhesametagnamesdiﬀerently.Forexample,a <title>elementmaybeintendedbythedatasendertoindicatethenameofabookwhile
thedatareceiverisundernoobligationtointerpretitassuch,becausetheelementcanalsoshowaperson’srank,honor,andoccupation,etc.Thisiswhystandardizationatthesemanticlevelisuseful. InCES,the<h.title> elementonlyreferstothenameofadocument.CESseekstostandardizeatthesemanticlevelfor
thoseelementsmostrelevanttolanguageengineeringapplications,inparticular,linguisticelements.Thethree levels of standardization are designed to achieve the goal of universal document interchange. LiketheTEIscheme,CESnotonlyappliestocorpusmarkup,italsocoversencodingconventionsforthelin-guisticannotationoftextandspeech,currentlyincludingmorpho-syntactictagging(i.e.,part-of-speechtagging,seeChapter10)andparalleltextalignmentinparallelcorpora(seeChapter16).
CES was developed and recommended by the Expert Advisory Groups on Language Engineering
Standards (EAGLES) as a TEI-compliant application of SGML that could serve as a widely acceptedset of encoding standards for corpus-based work. CES is available in both SGML and XML versions.The XML version, referred to as XCES, has also developed support for additional types of annotationand resources, including discourse/dialogue, lexicons, and speech (Ide et al. 2000). On the other hand,while metalanguages such as SGML and XML usually follow the system of attribute names laid out inimplementationstandardssuchasTEIandCES,thismaynotbenecessarilythecase.

158 HandbookofNaturalLanguageProcessing
Closelyrelatedtocorpusmarkupisannotation,butthetwoarediﬀerent.Asannotationissoimportant
in corpus creation and NLP research that speciﬁc types of annotation merit in-depth discussions inseparate chapters (e.g., Chapters 8, 10, and 14), here I will only discuss annotation brieﬂy. Corpusannotation can be deﬁned as the process of “adding such interpretative, linguistic information to anelectronic corpus of spoken and/or written language data” (Leech 1997: 2). While annotation deﬁnedin a broad sense may refer to the encoding of both textual/contextual information and interpretativelinguisticanalysis,asshownbytheconﬂationofthetwooftenfoundintheliterature,thetermisusedinanarrowsensehere,referringsolelytotheencodingoflinguisticanalysessuchaspart-of-speechtaggingandsyntacticparsinginacorpustext.
Corpus annotation, as used in a narrow sense, is fundamentally distinct from markup, though the
distinctionisnotacceptedbyallandthetwotermsaresometimesusedinterchangeablyintheliterature.Corpusmarkupprovidesrelativelyobjectivelyveriﬁableinformationregardingthecomponentsofacor-pusandthetextualstructureofeachtext.Incontrast,corpusannotationisconcernedwithinterpretativelinguisticinformation.“Bycallingannotation‘interpretative,’wesignalthatannotationis,atleastinsomedegree, the product of the human mind’s understanding of the text” (Leech 1997: 2). For example, thepartofspeechofawordmaybeambiguousandhenceismorereadilydeﬁnedascorpusannotationthancorpusmarkup.Ontheotherhand,thesexofaspeakerorwriterisnormallyobjectivelyveriﬁableandassuchisamatterofmarkup,notannotation.
Corpus annotationcanbeundertakenatdiﬀerentlevelsandmaytakevariousforms. For example, at
thephonologicallevel,corporacanbeannotatedforsyllableboundaries(phonetic/phonemicannotation)orprosodicfeatures(prosodicannotation);atthemorphologicallevelcorporacanbeannotatedintermsofpreﬁxes, suﬃxesandstems(morphologicalannotation); atthelexicallevel, corporacanbeannotatedforparts-of-speech(POStagging),lemmas(lemmatization),andsemanticﬁelds(semanticannotation);atthesyntacticlevel,corporacanbeannotatedwithsyntacticanalysis(parsing,treebanking,orbracketing);at the discoursal level, corpora can be annotated to show anaphoric relations (coreference annotation),pragmatic information like speech acts (pragmatic annotation) or stylistic features such as speech andthought presentation (stylistic annotation). Of these the most widespread type of annotation is part-of-speechtagging(seeChapter10),whichhasbeensuccessfullyappliedtomanylanguages;syntacticparsingis also developing rapidly (see Chapters 8 and 11) while some types of annotation (e.g., discoursal andpragmaticannotations)arepresentlyrelativelyundeveloped.
I have so far assumed that the process of annotation leads to information being mixed in the original
corpus text or so-called base document when it is applied to a corpus (i.e., the annotation becomesso-calledembeddedannotation).However,theCorpusEncodingStandardrecommendstheuseof“stand-alone annotation,” whereby the annotation information is retained in separate SGML/XML documents(withdiﬀerentDocumentTypeDeﬁnitions)andlinkedtotheoriginalandotherannotationdocumentsin hypertext format. In contrast to embedded annotation, stand-alone annotation has a number ofadvantages(Ide1998):
•Itprovidescontroloverthedistributionofbasedocumentsforlegalpurposes.
•Itenablesannotationtobeperformedonbasedocumentsthatcannoteasilybealtered(e.g., theyareread-only).
•Itavoidsthecreationofpotentiallyunwieldydocuments.
•Itallowsmultipleoverlappinghierarchies.
•It allows for alternative annotation schemes to be applied to the same data (e.g., diﬀerent POStagsets).
•It enables new annotation levels to be added without causing problems for existing levels ofannotationorsearchtools.
•Itallowsannotationatoneleveltobechangedwithoutaﬀectingotherlevels.
Stand-alone annotation is in principle ideal and is certainly technically feasible (see Thompson andMcKelvie 1997). It may also represent the future standard for certain types of annotation. In addition,

CorpusCreation 159
thestand-alonearchitecturecanfacilitatemultilevelormultilayerannotationsaswell(seeDipper2005).Presently, however, there are two problems associated with stand-alone annotation. The ﬁrst issueis related to the complexity of corpus annotation. As noted earlier, annotation may have multipleforms in a corpus. While some of these readily allow for the separation of annotation codes from basedocuments (e.g., lemmatization, part-of-speech tagging, and semantic annotation), others may involvemuch more complexity in establishing links between codes and annotated items (e.g., coreference andstylistic annotations). Even if such links can be established, they are usually prone to error. The secondissueispurelypractical. AsfarasIamaware, thecurrentlyavailablecorpusexplorationtools, includingthe latest versions of WordSmith (versions 4.0 and 5.0) and Xaira (Burnard and Todd 2003), have allbeendesignedforusewithembeddedannotation.Stand-aloneannotation,whileappealing,isonlyusefulwhenappropriatesearchtoolsareavailableforuseonstand-aloneannotatedcorpora.
7.6 Multilingual Corpora
I have so far assumed in this chapter that a corpus only involves one language. Corpora of this kindare monolingual. But there are also corpora that cover more than one language, which are referred toas multilingual corpora. In this section, I will shift my focus to the multilingual dimension of corpuscreation.
Witheverincreasinginternationalexchangeandacceleratedglobalization,translationandcontrastive
studies are more popular than ever. As part of this new wave of research on translation and contrastivestudies,multilingualcorporasuchasparallelandcomparablecorporaareplayinganincreasinglypromi-nent role. As Aijmer and Altenberg (1996: 12) observe, parallel and comparable corpora “oﬀer speciﬁcusesandpossibilities”forcontrastiveandtranslationstudies:
•Theygivenewinsightsintothelanguagescompared—insightsthatarenotlikelytobegainedfromthestudyofmonolingualcorpora.
•They can be used for a range of comparative purposes and increase our knowledge of language-speciﬁc,typologicalandculturaldiﬀerences,aswellasofuniversalfeatures.
•They illuminate diﬀerences between source texts and translations, and between native andnonnativetexts.
•They can be used for a number of practical applications, for example, in lexicography, languageteaching,andtranslation.
In addition to these beneﬁts of multilingual resources in linguistic research, we can also add to thelist the fact that aligned parallel corpora are indispensable to the development of NLP applicationssuch as computer-aided translation and machine translation (see Chapters 17 and 18) and multilingualinformationretrievalandextraction(seeChapters19and21).
Amultilingualcorpusinvolvestextsofmorethanonelanguage. Ascorporathatcovertwolanguages
areconventionallyknownas“bilingual,”multilingualcorpora,inanarrowsense,mustinvolvemorethantwolanguages,though“multilingual”and“bilingual”areoftenusedinterchangeablyintheliterature,andalso in this chapter. A multilingual corpus can be a parallel corpus, or a comparable corpus. Given thatcorporainvolvingmorethanonelanguagearearelativelynewphenomenon,withmostrelatedresearchhailingfromtheearly1990s, itisunsurprisingtodiscoverthatthereissomeconfusionsurroundingtheterminologyusedinrelationtothesecorpora.
It can be said that terminological confusion in multilingual corpora centers on two terms: “parallel”
and “comparable.” For some scholars (e.g., Aijmer and Altenberg 1996; Granger 1996: 38), corporacomposedofsourcetextsinonelanguageandtheirtranslationsinanotherlanguage(orotherlanguages)are “translation corpora” while those comprising diﬀerent components sampled from diﬀerent nativelanguages using comparable sampling techniques are called “parallel corpora.” For others (e.g., Baker1993:248,1995,1999;Barlow1995,2000:110;Hunston2002:15;McEneryandWilson1996:57;McEnery

160 HandbookofNaturalLanguageProcessing
et al. 2006), corpora of the ﬁrst type are labeled “parallel” while those of the latter type are comparablecorpora. As argued in McEnery and Xiao (2007a: 19–20), while diﬀerent criteria can be used to deﬁnediﬀerent types of corpora, they must be used consistently and logically. For example, we can say thata corpus is monolingual, bilingual, or multilingual if we take the number of languages involved as thecriterion for deﬁnition. We can also say that a corpus is a translation or a non-translation corpus if thecriterionofcorpuscontentisused.Butifwechoosetodeﬁnecorpustypesbythecriterionofcorpusform,we must use the terminology consistently. Then we can say a corpus is parallel if the corpus containssource texts and translations in parallel, or it is a comparable corpus if its components or subcorporaare comparable by applying the same sampling frame. It is illogical, however, to refer to corpora of theﬁrsttypeastranslationcorporabythecriterionofcontentwhilereferringtocorporaofthelattertypeascomparablecorporabythecriterionofform.
Additionally,aparallelcorpus,inmyterms,canbeeitherunidirectional(e.g.,fromEnglishintoChinese
orfromChineseintoEnglishalone),orbidirectional(e.g.,containingbothEnglishsourcetextswiththeirChinese translations as well as Chinese source texts with their English translations), or multidirectional(e.g., the same piece of text with its Chinese, English, French, Russian, and Arabic versions). In thissense, texts that are produced simultaneously in diﬀerent languages (e.g., UN regulations) also belongto the category of parallel corpora. A parallel corpus must be aligned at a certain level (for instances,at document, paragraph, sentence, or word level) in order to be useful. The automatic alignment ofparallel corpora is not a trivial task for some language pairs, though alignment is generally very reliablefor many closely related European language pairs (cf. McEnery et al. 2006: 50–51; see Chapter 16 forfurtherdiscussion).
Another complication in terminology involves a corpus that is composed of diﬀerent variants of the
samelanguage.Thisisparticularlyrelevanttotranslationstudiesbecauseitisaverycommonpracticeinthisresearchareatocompareacorpusoftranslatedtexts—thatIcalla“translationalcorpus”—andacorpusconsisting of comparably sampled non-translated texts in the same language (see Xiao and Yue 2009).Theyformamonolingualcomparablecorpus.Tous,amultilingualcomparablecorpussamplesdiﬀerentnativelanguages,withitscomparabilitylyinginthematchingorcomparablesamplingtechniques,similarbalance (i.e., coverage of genres and domains) and representativeness, and similar sampling period (seeSection7.3).Bymydeﬁnition,corporacontainingdiﬀerentregionalvarietiesofthesamelanguage(e.g.,theInternationalCorpusofEnglish,ICE)arenotcomparablecorporabecauseallcorpora,asaresourceforlinguisticresearch,have“alwaysbeenpre-eminentlysuitedforcomparativestudies”(Aarts1998:ix),eitherintralinguallyorinterlingually.TheBrown,LOB,Frown,andFLOBcorporaarealsousedtypicallyforcomparinglanguagevarietiessynchronicallyanddiachronically.Corporasuchasthesecanbelabeledas“comparativecorpora.”Theyarenot“comparablecorpora”assuggestedintheliterature(e.g.,Hunston2002:15).
Having clariﬁed some terminological confusion in multilingual corpus research, it is worth pointing
outthedistinctionsdiscussedherearepurelyforthesakeofclariﬁcation.Inreality,therearemultilingualcorpora that are a mixture of parallel and comparable corpora. For example, in spite of its name,the English–Norwegian Parallel Corpus (ENPC) can be considered as a combination of a parallel andcomparablecorpus.Iwillnotdiscussthestateoftheartofmultilingualcorpusresearchhere.InterestedreadersareadvisedtorefertoMcEneryandXiao(2007b).
Multilingual corpora often involve a writing system that relies heavily on non-ASCII characters.
Characterencodingisrarelyanissueincorpuscreationforalphabeticallanguages(e.g.,English)thatuseASCIIcharacters.However,evenlanguagesthatuseasmallnumberofaccentedLatincharactersmayhaveencountered encoding problems. For monolingual corpora of many other languages that use diﬀerentwritingsystems,especiallyformultilingualcorporathatcontainawiderangeofwritingsystems,encodingis all the more important if one wants to display the corpus properly or facilitate data interchange. Forexample, Chinese can be encoded using GB2312 (Simpliﬁed Chinese), Big5 (Traditional Chinese), orUnicode (UTF-8, UTF-7 or UTF-16). Both GB2312 and Big5 are 2-byte encoding systems that requirelanguage-speciﬁcoperatingsystemsorlanguage-supportpacksiftheChinesecharactersencodedaretobe

CorpusCreation 161
displayedproperly.Languagespeciﬁcencodingsystemssuchasthesemakedatainterchangeproblematic.It is also quite impossible to display a document containing both simpliﬁed and traditional Chinesecharactersusingtheseencodingsystems.AsMcEneryetal.(2000)note,themaindiﬃcultyinbuildingamultilingualcorpusofAsianlanguagesistheneedtostandardizethelanguagedataintoasinglecharacterset. Unicode is recommended as a solution to this problem (see McEnery and Xiao 2005). Unicode istruly multilingual in that it can display characters from a very large number of writing systems. Fromthe Unicode Standard version 1.1 onward, Unicode is fully compatible with ISO 10646-1 (UCS). ThecombinationofUnicodeandXMLisageneraltrendincorpuscreation(seeXiaoetal.2004).Assuch,itistobewelcomed.
7.7 Multimodal Corpora
The corpora discussed so far in this chapter, whether spoken or written, have been assumed to be text-based;thatis,spokenlanguageistreatedasifitiswritten.Inthistext-basedapproachtocorpuscreation,audio/videorecordingsofspokendataaretranscribed,withthetranscriptpossiblyalsoincludingvaryinglevelsofdetailsofspokenfeatures(e.g.,turnoverlaps)andparalinguisticfeatures(e.g.,laughter).Corpusanalysis is then usually undertaken on the textual transcript without reference to the original recordingunlessoneisengagedinprosodicorphoneticresearch.
As noted in Section 7.5, a corpus is essentially a collection of samples of used language, which have
been likened to a laboratory specimen out of its original habitat (Burnard 2005). While corpus markupcan help to restore some contextual information, a large part of such information is lost, especially intranscripts of video clips. As Kress and van Leeuwen (2006: 41) observe, “a spoken text is never justverbal,butalsovisualcombiningwithmodessuchasfacialexpressions,gesture,postureandotherformsofself-presentation,”thelatterofwhichcannotbecapturedandtranscribedeasily,ifatall.Consequently,“eventhemostdetailed,faithfulandsympathetictranscriptioncannothopetocapture”spokenlanguage(Carter2004: 26). Assuch, therehasrecentlybeenanincreasinginterestinmultimodal corpora. Inthiskind of corpora, annotated transcripts are aligned with digital audio/video clips with the help of timestamps, which not only renders the corpus searchable with the help of transcripts but also allows theuser to access the segments of recordings corresponding to the search results. There are a number ofexistingmultimodalcorporaincluding,forexample,theNottinghamMulti-ModalCorpus(NMMC,seeAdolphs and Carter 2007), the Singapore Corpus of Research in Education (SCoRE, see Hong 2005),Padova Multimedia English Corpus (see Ackerley and Coccetta 2007), and the Spoken Chinese CorpusofSituatedDiscourse(SCCSD,seeGu2002).
Multimodalcorporaandmultimodalconcordancersarestillintheirinfancy(Baldry2006:188).They
are technically more challenging to develop than purely text-based corpora and corpus tools. However,given the special values of such corpora, and the advances of technologies (e.g., those that help to trackand annotate gestures), multimodal corpora will become more common and more widely used in thenearfuture.
7.8 Conclusions
Thischapterhasfocusedoncorpuscreation,coveringthemajorfactorsthatmustbetakenintoaccountin this process. I have discussed both core issues relating to corpus design (e.g., corpus size, representa-tiveness, and balance) as well as corpus processing (e.g., data collection, markup, and annotation), andperipheralissuessuchasmultilingualandmultimodalcorpora.
One important reason for using corpora is to extract linguistic information present in those corpora.
Butitisoftenthecasethatinordertoextractsuchinformationfromacorpus,alinguisticanalysismustﬁrstbeencodedinthecorpus.Suchannotationaddsvaluetoacorpusinthatitconsiderablyextendsthe

162 HandbookofNaturalLanguageProcessing
range of research questions that a corpus can readily address. In this chapter, I have discussed corpusannotationinverygeneralterms.Thechapterthatfollowswillexploreannotationingreaterdepth.
References
Aarts, J. (1998) Introduction. In S. Johansson and S. Oksefjell (eds.), Corpora and Cross-Linguistic
Research,pp.ix–xiv.Amsterdam,theNetherlands:Rodopi.
Ackerley,K.andCoccetta,F.(2007)Enrichinglanguagelearningthroughamultimediacorpus. ReCALL
19(3):351–370.
Adolphs, S. and Carter, R. (2007) Beyond the word: New challenges in analyzing corpora of spoken
English.EuropeanJournalofEnglishStudies 11(2):133–146.
Aijmer, K. and Altenberg, B. (1996) Introduction. In K. Aijmer, B. Altenberg and M. Johansson (eds.),
Languageincontrast. PapersfromSymposiumonText-BasedCross-LinguisticStudies ,Lund,Sweden,
March1994,pp.10–16.Lund,Sweden:LundUniversityPress.
Amsler,R.(2002)Legalaspectsofcorporacompiling.In CorporaListArchiveon1stOctober2002 .URL:
http://helmer.hit.uib.no/corpora/2002-3/0256.html.
Aston,G.andBurnard,L.(1998) TheBNCHandbook.Edinburgh,U.K.:EdinburghUniversityPress.
Atkins, S., Clear, J., and Ostler, N. (1992) Corpus design criteria. Literary and Linguistic Computing
7(1):1–16.
Baker, M.(1993)Corpuslinguisticsandtranslationstudies: Implicationsandapplications. InM.Baker,
G. Francis, and E. Tognini-Bonelli (eds.), Text and Technology: In Honour of John Sinclair,
pp.233–352.Amsterdam,theNetherlands:Benjamins.
Baker, M.(1995)Corporaintranslationstudies: Anoverviewandsomesuggestionsfor futureresearch.
Target7:223–243.
Baker,M.(1999)Theroleofcorporaininvestigatingthelinguisticbehaviourofprofessionaltranslators.
InternationalJournalofCorpusLinguistics 4:281–298.
Baldry,A.P.(2006)Theroleofmultimodalconcordancersinmultimodalcorpuslinguistics.InT.D.Royce
and W. L. Bowcher (eds.), New Directions in the Analysis of Multimodal Discourse , pp. 173–214.
London,U.K.:Routledge.
Barlow,M.(1995) AGuidetoParaConc .Huston,TX:Athelstan.
Barlow, M. (2000) Parallel texts and language teaching. In S. Botley, A. McEnery, and A. Wilson (eds.),
MultilingualCorporainTeachingandResearch ,pp.106–115.Amsterdam,theNetherlands:Rodopi.
Baroni, M. (2009) Distributions in text. In A. Lüdeling and M. Kytö (eds.), Corpus Linguistics: An
InternationalHandbook (Vol.2),pp.803–822.Berlin,Germany:MoutondeGruyter.
Baroni, M. and Bernardini, S. (2004) BootCaT: Bootstrapping corpora and terms from the Web. In
M.Lino,M.Xavier,F.Ferreire,R.Costa,andR.Silva(eds.), ProceedingsoftheFourthInternational
ConferenceonLanguageResourcesandEvaluation (LREC)2004,Lisbon,Portugal,May24–30,2004.
Baroni, M. and Bernardini, S. (eds.). (2006) Wacky! Working Papers on the Web as Corpus . Bologna,
Italy:GEDIT.
Belica, C. (1996) Analysis of temporal change in corpora. International Journal of Corpus Linguistics
1(1):61–74.
Biber,D.(1988) VariationAcrossSpeechandWriting .Cambridge,U.K.:CambridgeUniversityPress.
Biber,D.(1993)Representativenessincorpusdesign. LiteraryandLinguisticComputing 8(4):243–257.
Bird,S.andSimons,G.(2000) WhitePaperonEstablishinganInfrastructureforOpenLanguageArchiving .
URL:http://www.language-archives.org/docs/white-paper.html.
Burnard,L.(2002) ValidationManualforWrittenLanguageResources .URL:http://www.oucs.ox.ac.uk/rts/
elra/D1.xml.
Burnard,L.(2005)Metadataforcorpuswork.InM.Wynne(ed.), DevelopingLinguisticCorpora:AGuide
toGoodPractice ,pp.30–46.Oxford,U.K.:AHDS.

CorpusCreation 163
Burnard,L.andTodd,T.(2003)Xara:AnXMLawaretoolforcorpussearching.InD.Archer,P.Rayson,
A.Wilson,andA.McEnery(eds.), ProceedingsofCorpusLinguistics2003 ,Lancaster,U.K.,pp.142–
144.Lancaster,U.K.:LancasterUniversity.
Carter, R. (2004) Grammar and spoken English. In C. Coﬃn, A. Hewings, and K. O’Halloran (eds.),
ApplyingEnglishGrammar:CorpusandFunctionalApproaches ,pp.25–39.London,U.K.:Arnold.
Collins(2007) CollinsEnglishDictionary (9thed.).Toronto,Canada:HarperCollins.
Cooper, D. (2003) Legal aspects of corpora compiling. In Corpora List Archive on 19th June 2003 .U R L :
http://helmer.aksis.uib.no/corpora/2003-1/0596.html.
Cornish,G.P.(1999) Copyright:InterpretingtheLawforLibraries,ArchivesandInformationServices (3rd
ed.).London,U.K.:LibraryAssociationPublishing.
Dekkers, M. and Weibel, S. (2003) State of the Dublin core metadata initiative. D-Lib Magazine 9(4).
URL:http://www.dlib.org/dlib/april03/weibel/04weibel.html.
Dipper, S. (2005) XML-based stand-oﬀ representation and exploitation of multi-level linguistic
annotation.In ProceedingsofBerlinerXMLTage2005 (BXML2005),Berlin,Germany,pp.39–50.
Dipper,S.(2008)Theory-drivenandcorpus-drivencomputationallinguistics,andtheuseofcorpora.In
A.LudelingandM.Kyto(eds.), CorpusLinguistics:AnInternationalHandbook (Vol.1),pp.68–96.
Berlin,Germany:MoutondeGruyter.
Evert,S.(2006)Howrandomisacorpus?Thelibrarymetaphor. ZeitschriftfürAnglistikundAmerikanistik
54(2):177–190.
Givon,T.(1995) FunctionalismandGrammar .Amsterdam,theNetherlands:JohnBenjamins.
Granath, S. (2007) Size matters—Or thus can meaningful structures be revealed in large corpora. In
R. Facchinetti (ed.), Corpus Linguistics 25 Years On , pp. 169–185. Amsterdam, the Netherlands:
Rodopi.
Granger, S. (1996) From CA to CIA and back: An integrated approach to computerized bilingual
and learner corpora. In K. Aijmer, B. Altenberg, and M. Johansson (eds.), Language in contrast.
Symposium on Text-based Cross-linguistic Studies, Lund, Sweden , March 1994, pp. 38–51. Lund,
Sweden:LundUniversityPress.
Gu, Y. (2002) Towards an understanding of workplace discourse. In C. N. Candlin (ed.), Research
and Practice in Professional Discourse , pp. 137–86. Hong Kong: City University of Hong Kong
Press.
Hakulinen, A., Karlsson, F., and Vilkuna, M. (1980) Suomen tekstilauseiden piirteitä: kvantitatiivinen
tutkimus.DepartmentofGeneralLinguistics,UniversityofHelsinki,Helsinki,Finland,Publications
No.6.
Hausser,H.(1999) FunctionsofComputationalLinguistics .Berlin,Germany:Springer-Verlag.
Hong,H.(2005)SCORE:AmultimodalcorpusdatabaseofeducationdiscourseinSingaporeschools.In
ProceedingsofCorpusLinguistics2005 .http://www.corpus.bham.ac.uk/pclc/ScopeHong.pdf
Hundt, M., Sand, A., and Siemund, R. (1998) Manual of Information to Accompany the Freiburg-LOB
CorpusofBritishEnglish (‘FLOB’).URL:http://khnt.hit.uib.no/icame/manuals/ﬂob/INDEX.HTM.
Hundt, M., Sand, A., and Skandera, P. (1999) Manual of Information to Accompany the Freiburg-
Brown Corpus of American English (‘Frown’). URL: http://khnt.hit.uib.no/icame/manuals/frown/
INDEX.HTM.
Hundt,M.,Biewer,C.,andNesselhauf,N.(eds.).(2007) CorpusLinguisticsandtheWeb.Amsterdam,the
Netherlands:Rodopi.
Hunston,S.(2002) CorporainAppliedLinguistics.Cambridge,U.K.:CambridgeUniversityPress.
Ide,N.(1998)Corpusencodingstandard:SGMLguidelinesforencodinglinguisticcorpora.In LREC-1998
Proceedings ,Granada,Spain,pp.463–470.
Ide,N.andPriest-Dorman,G.(2000) CorpusEncodingStandard—DocumentCES1.URL:http://www.cs.
vassar.edu/CES/.
Ide,N.,Patrice,B.,andRomaryL.(2000)XCES:AnXML-basedencodingstandardforlinguisticcorpora.
InLREC-2000Proceedings ,Athens,Greece,pp.825–830.

164 HandbookofNaturalLanguageProcessing
Johansson, S., Leech, G., and Goodluck, H. (1978) Manual of Information to Accompany the Lancaster-
Oslo/Bergen Corpus of British English, for Use with Digital Computers . Oslo, Norway: University
ofOslo.
Keller,F.andLapata,M.(2003)UsingtheWebtoobtainfrequenciesforunseenbigrams. Computational
Linguistics 29(3):459–484.
Kilgarriﬀ, A. (2002) Legal aspects of corpora compiling. In Corpora List Archive on 1st October 2002 .
URL:http://helmer.hit.uib.no/corpora/2002-3/0253.html.
Kilgarriﬀ,A.andGrefenstette,G.(eds.).(2003)SpecialIssueonWebasCorpus. ComputationalLinguistics
29(3):333–502.
Kress,G.andvanLeeuwen,T.(2006) ReadingImages:TheGrammarofVisualDesign (2nded.).London,
U.K.:Routledge.
Krishnamurthy, R. (2000) Size matters: Creating dictionaries from the world’s largest corpus. In Pro-
ceedings of KOTESOL 2000: Casting the Net: Diversity in Language Learning ,T a e g u ,K o r e a ,
pp.169–180.
Kucěra,H.andFrancis,W.(1967) ComputationalAnalysisofPresent-DayEnglish .Providence,RI:Brown
UniversityPress.
Leech,G.(1991)Thestateofartincorpuslinguistics.InK.AijmerandB.Altenberg(eds.), EnglishCorpus
Linguistics ,pp.8–29.London,U.K.:Longman.
Leech,G.(1997)Introducingcorpusannotation.InR.Garside,G.Leech,andA.McEnery(eds.), Corpus
Annotation,pp.1–18.London,U.K.:Longman.
Manning,C.andSchütze,H.(1999) FoundationsofStatisticalNaturalLanguageProcessing .Cambridge,
MA:MITPress.
McEnery,A.andWilson,A.(1996/2001) CorpusLinguistics (2nded.2001).Edinburgh,U.K.:Edinburgh
UniversityPress.
McEnery, A. and Xiao, R. (2005) Character encoding in corpus construction. In M. Wynne (ed.),
DevelopingLinguisticCorpora:AGuidetoGoodPractice,pp.47–58.Oxford,U.K.:AHDS.
McEnery,A.andXiao,R.(2007a)Parallelandcomparablecorpora:Whatishappening?InM.Rogersand
G.Anderman(eds.), IncorporatingCorpora:TheLinguistandtheTranslator ,pp.18–31.Clevedon,
U.K.:MultilingualMatters.
McEnery, A. and Xiao, R. (2007b) Parallel and comparable corpora: The state of play. In Y. Kawaguchi,
T.Takagaki,N.Tomimori,andY.Tsuruga(eds.), Corpus-BasedPerspectivesinLinguistics,pp.131–
145.Amsterdam,theNetherlands:JohnBenjamins.
McEnery,A.,Baker,P.,Gaizauskas,R.,andCunningham,H.(2000)EMILLE:BuildingacorpusofSouth
Asianlanguages. Vivek:AQuarterlyinArtiﬁcialIntelligence 13(3):23–32.
McEnery, A., Baker, P., and Cheepen, C. (2001) Lexis, indirectness and politeness in operator calls. In
C.MeyerandP.Leistyna(eds.), CorpusAnalysis:LanguageStructureandLanguageUse .Amsterdam,
theNetherlands:Rodopi.
McEnery,A.,Xiao,R.,andTono,Y.(2006) Corpus-BasedLanguageStudies:AnAdvancedResourceBook .
London,U.K.:Routledge.
Ostler,N.(2008)Corporaoflessstudiedlanguages.InA.LudelingandM.Kyto(eds.), CorpusLinguistics:
AnInternationalHandbook (Vol.1),pp.457–484.Berlin,Germany:MoutondeGruyter.
Otlogetswe, T. (2004) The BNC design as a model for a Setswana language corpus. In Proceeding of the
Seventh Annual CLUK Research Colloquium, pp. 93–198. University of Birmingham, Edgbaston,U.K.,January6–7,2004.
Piao,S.,Wilson,A.,andMcEnery,A.(2002)Amultilingualcorpustoolkit. PaperPresentedattheFourth
NorthAmericanSymposiumonCorpusLinguistics,Indianapolis,IN,November1–3,2002.
Santos,D.(1996)TenseandaspectinEnglishandPortuguese:Acontrastivesemanticalstudy.PhDthesis,
UniversidadeTecnicadeLisboa,Lisbon,Portugal.
Scott,M.(2003) WordSmithToolsManual .URL:http://www.lexically.net/wordsmith/version4/.

CorpusCreation 165
Shimazumi,M.andBerber-Sardinha,A.(1996)Approachingtheassessmentofperformanceunit(APU)
archiveofschoolchildren’swritingfromthepointofviewofcorpuslinguistics. PaperPresentedat
theTALC’96Conference,LancasterUniversity,Lancaster,U.K.,August11,1996.
Sinclair,J.(1991) CorpusConcordanceCollocation .Oxford,U.K.:OxfordUniversityPress.
Sinclair,J.(2004) TrusttheText:Language,CorpusandDiscourse.London,U.K.:Routledge.
Sinclair, J. (2005) Corpus and Text: Basic Principles. In M. Wynne (ed.), Developing Linguistic Corpora:
AGuidetoGoodPractice ,pp.1–20.Oxford,UK:AHDS.
Sperberg-McQueen,C.M.andBurnard,L.(eds.).(2002) TEIP4:GuidelinesforElectronicTextEncoding
andInterchange (XMLVersion).Oxford,U.K.:TextEncodingInitiativeConsortium.
Spoor, J. (1996) The copyright approach to copying on the Internet: (Over)stretching the reproduction
right? In H. Hugenholtz (ed.), The Future of Copyright in a Digital Environment , pp. 67–80.
Dordrecht,theNetherlands:KluwerLawInternational.
Teubert, W. (2000) Corpus linguistics—A partisan view. International Journal of Corpus Linguistics
4(1):1–16.
Thompson, H. and McKelvie, D. (1997) Hyperlink semantics for standoﬀ markup of read-only docu-
ments. In Proceedings of SGML Europe’97 , Barcelona, Spain, May 1997. URL: http://www.ltg.ed.
ac.uk/∼ht/sgmleu97.html.
Váradi, T. (2000) Corpus linguistics—linguistics or language engineering? In T. Erjavec and J. Gross
(eds.),InformationSocietyMulti-ConferenceProceedingsLanguageTechnologies ,pp.1–5.Ljubljana,
Slovenia,October17–18,2000.
Wittenburg, P., Peters, W., and Broeder, D. (2002) Metadata proposals for corpora and lexica. In
LREC-2002Proceedings ,LasPalmas,Spain,pp.1321–1326.
Xiao,R.(2008)Well-knownandinﬂuentialcorpora.InA.LüdelingandM.Kyto(eds.), CorpusLinguistics:
AnInternationalHandbook (Vol.1),pp.383–457.Berlin,Germany:MoutondeGruyter.
Xiao, R. and Yue, M. (2009) Using corpora in translation studies: The state of the art. In P. Baker (ed.),
ContemporaryApproachestoCorpusLinguistics ,pp.237–262.London,U.K.:Continuum.
Xiao, R., McEnery, A., Baker, P., and Hardie, A. (2004) Developing Asian language corpora: Standards
and practice. In Proceedings of the Fourth Workshop on Asian Language Resources , Sanya, Hainan
Island,pp.1–8,March25,2004.
Yates,F.(1965) SamplingMethodsforCensusesandSurveys (3rded.).London,U.K.:CharlesGriﬃnand
CompanyLimited.



