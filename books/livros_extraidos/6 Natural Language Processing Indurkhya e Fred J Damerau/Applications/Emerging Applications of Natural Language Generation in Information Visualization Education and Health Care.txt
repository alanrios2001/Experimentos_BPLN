23
Emerging Applications
of Natural Language
Generation in
Information
Visualization,
Education, and
Health Care
Barbara Di Eugenio
UniversityofIllinoisatChicago
Nancy L. Green
UniversityofNorthCarolinaGreensboro23.1 Introduction ..........................................................55723.2 MultimediaPresentationGeneration..............................55823.3 LanguageInterfacesforIntelligentTutoringSystems............562
CIRCSIM-Tutor •AUTOTUTOR •ATLAS-ANDES,WHY2-ATLAS,
andWHY2-AUTOTUTOR •BrieﬂyNoted
23.4 ArgumentationforHealth-CareConsumers......................568Acknowledgments ..........................................................570References....................................................................570
23.1 Introduction
Inthischapter,wepresentapplicationsofNaturalLanguageGeneration(NLG)thatwebelieveareamongthemostnovelandexcitingofthelastfewyears.Ingeneral,NLGendowsasoftwareapplicationwiththeabilitytopresentinformationtotheuservianaturallanguage(NL).Asforanytaskinvolvinginformationpresentation, twoorthogonaldimensions needtobeconsidered: thepurposefor whichtheinformationis presented, and the way it is presented. To us, the most far reaching NLG applications of today try tohelp the user acquire information that is of high value to the individual, but also more in general, tosociety: hence, we focus on applications of NLG in education and health care. Across the world, andespecially in the more industrialized countries, there is a keen interest in using technology to supportbotheducationandhealthcare,andtoassesswhetherandhowtechnologycanimprovetheoutcomesofboth. Technology is also seen as a tool to help level the playing ﬁeld, addressing educational and healthdisparities in disadvantaged groups, and in a larger context, in poorer areas of the world. The type ofsystemwewilldiscusshasthepotentialtocontributetobetterlearningandbetterhealthinactualusers.
557

558 HandbookofNaturalLanguageProcessing
Clearly, whenever information is presented to a user, the question arises, regarding which modalities
should be used to present that information. Whereas we focus on the generation of textual and verbalinformationintheeducationandhealth-careapplicationswewilldiscuss, nowadaysitisextremelyrarethat only language is used in an interface. While there are interactive systems that are purely textual,such as document search or document summarization, it has been shown over and over that diﬀerentmedia have diﬀerent aﬀordances and can provide the user with diﬀerent perspectives on the presentedinformation,e.g.,see(Oviatt1999;ShneidermanandPlaisant2004).Hence,wewilldescribewhatwecallsecond-generation multimedia presentation systems, which generate text that summarizes informationas a complement to visual displays. Some of these second-generation multimedia presentation systemsarewithintherealmofeducationandhealthcarethemselves,althoughtheymaynotaﬀectuserbehaviordirectly(e.g.,inSection23.2,wepresentCLEF,thatsummarizesapatient’shealthhistoryforthehealth-careprovider).Buteveniftheydonot,itiseasytoenvisionthatthistypeofmultimediapresentationwillbecome more and more important in deploying systems that can eﬀectively interact with users, whereeﬀectivenessismeasuredinconcreteoutcomesoflearningandimprovedhealth.
The last point about eﬀectiveness is not just made in the abstract. One common aspect across all the
applicationswewillpresentisthattheyhavebeenevaluatedwithusers.Insomecasestheuserstudiesareconﬁnedtopaidsubjectsinthelaboratory,whileinothersapplicationsareevaluatedwithrealusers(e.g.,in Section 23.4, we present STOP, which generates personalized letters to help people stop smoking).Evaluation with users distinguishes this type of research from much other research in NLP, where theevaluation is conﬁned to testing the system on predeﬁned test sets, very often considered standard bythecommunity.EvaluatingNLGsystemswithuserstudiesowesmuchtoHumanComputerInteraction,whichinturnowesthisstyleofevaluationtothecontrolledexperimentalparadigmcomingfromcognitivepsychology,ortotherandomizedclinicaltrialapproachusedinthehealthdisciplines.
Thischapterisorganizedasfollows.Weﬁrstdiscusstechniquesusedbysecond-generationmultimedia
presentation systems. Then, we turn to NL interfaces for Intelligent Tutoring Systems (ITSs), a speciﬁctype of educational application. Finally, we discuss the generation of argumentation addressed to thehealth-careconsumer.
23.2 Multimedia Presentation Generation
Document planning, the ﬁrst stage of generation in an idealized NLG pipeline architecture (Reiter andDale 2000), includes content selection and document structuring tasks. Content selection (or contentdetermination) is the selection of relevant information from a knowledge source. Interleaved with orfollowingcontentselection,documentstructuringistheorganizationandorderingoftheselectedcontent.
Inthe1980sand1990s, theﬁrstgenerationofresearchonintelligentmultimediapresentationgener-
ation focused mostly on document structuring, and speciﬁcally, on multimedia presentation planning,media allocation, generation of referring expressions, and media coordination. To summarize each ofthese issues, ﬁrst, in research on multimedia presentation planning two contrasting approaches wereexplored: (1) use of presentation planning knowledge sources in which the structuring of content andits allocation to text or graphics is prespeciﬁed by system developers, and (2) generation of media-independent presentation plans whose parts can be realized as text or graphics. In the latter approach,a media allocation module is used to decide how best to allocate content in the presentation plan toa media-speciﬁc generator for realization. Another issue, the generation of referring expressions in amultimedia presentation must take into account not only the preceding text but also the visual context.Finally,spatialandtemporalcoordinationissuesincludelayout,sequencingofspokenlanguagewiththevisual display, and the use of deictic gestures by embodied agents. First generation research publishedthrough the end of the 1990s is thoroughly surveyed in André (2000). Some of the application areasincluded the generation of written instructions and diagrams (Feiner and McKeown 1991; André et al.1993), the generation of text and information graphics (Mittal et al. 1998; Fasciano and Lapalme 2000;

EmergingApplicationsofNaturalLanguageGeneration 559
Greenetal.2004),andthegenerationoftextanddynamicmultimediaandanimation(Dalaletal.1996;Lesteretal.1999;RickelandJohnson1999).
Althoughdocumentstructuringinthecontextofmultimediapresentationsisstillanimportantareaof
research,morerecentresearchhasfocusedonthecontentselectionandtheintegrationoftextgenerationwithinformation visualization, whereas standardNLGtechniquestendtobeused insubsequent stagesofgeneration.Whereasmostoftheﬁrstgenerationsystemsperformedcontentselectiononoutputfromanothercomponentofthesameapplication(e.g.,aplanner),thesecondgenerationhasusedexternaldatasources. A range of knowledge sources is represented in this work: numerical time-series data, medicalrecords, images of bar charts published on the Web, and corpora of evaluative text. In fact, use of suchknowledgesourceshasbroadenedthescopeofcontentselectiontoincludenonlinguistictechniquessuchas numerical data analysis. The goal of this research is to provide text that summarizes the knowledgesourceasanalternativeorcomplementtovisualdisplays.Inthelattercase,thetextisgeneratedaspartofaninformationvisualizationarchitecture.Informationvisualization,fromtheﬁeldofhuman–computerinteraction, addresses the presentation of information graphically to exploit human perceptual abilitiesandtofacilitatedataexploration.Intherestofthissection,wesurveythissecondgenerationmultimediapresentationresearch.
The SumTime project has investigated the generation of textual summaries of numerical time-series
data. Although the numerical data used in these systems could be displayed graphically, the researchersargue that generating textual summaries is advantageous to the intended audience. In both SumTimesystemswewilldiscuss(SumTime-TurbineandBT-45),dataanalysistechniquesareemployedtoidentifypatternsinthedatathatarelikelytobeofinteresttotheuser.SumTime-Turbine(Yuetal.2007),generatesshorttextualsummariesoflarge(100KBormore)datasetsofturbinesensordata.Inthiscase,thesheervolumeofdatamakesagraphicaldisplayimpracticalfortheuser. Thus, thegoalofthatresearchwastosummarizeuptohundredsofKBofnumericaldatainafewsentences.
Figure 23.1 shows an example of a summary generated by SumTime-Turbine covering three hours
of sensor readings at one-second intervals for six sensors. SumTime-Turbine was evaluated with twodomainexpertsatboththecomponentlevelandthesystemlevel.Theauthorssummarizetheevaluationresultsasfollows(Yuetal.2007,p.47):
[Backgroundinformation]Gas turbine: aylesfordSubsystem: exhaust temperatureMonitoring channels: TTXD-1, TTXD-2, TTXD-3, TTXD-4, TTXD-5 and TTXD-6Turbine running state: part loadTime interval of these channels: from 12 to 15 on 27 Nov 99[Overviewinformation]There were large erratic spikes in all channels at 12:59, 13:01, 13:41 and 14:40.[Mostsigniﬁcantpatterns]At 12:59, there were large erratic spikes in TTXD-1, TTXD-2, TTXD-3, TTXD-4, TTXD-5 and TTXD-6. Thesepatterns violated the pairs and follows check. In more detail, there were dips with oscillatory recoveries in TTXD-3and TTXD-4, followed 1s later by dips with oscillatory recoveries in TTXD-1, TTXD-2, TTXD-5 and TTXD-6. Thisoccurred between 12:59:17 and 12:59:54.
FIGURE23.1 AsummarygeneratedbySumTime-Turbine.(ReproducedfromYu,J.etal., Nat.Lang.Eng. ,13,25,
2006.Withpermission.)

560 HandbookofNaturalLanguageProcessing
they[thetwodomainexperts]thinkSumTime-Turbineisdoingareasonablejob,buttheyalsothink
thereisroomforimprovement.
Another SumTime system, BT-45 (Portet et al. 2008), generates textual summaries of 45min of
physiological signals and discrete events describing a patient in a neonatal intensive care unit. One
motivation for developing BT-45 was a previous study that found that clinical decision-making was
improvedbytheuseofsummarieswrittenbyhumanexpertscomparedtographicaldisplaysofthedata
((Lawetal.2005),citedin(Portetetal.2008)).Inaddition,BT-45inferstemporalandcausalrelationships
betweenclinicaleventsandtheimportanceoftheeventstotheaudience.TheBT-45documentplanning
component uses parameterssuch asimportance thresholds and desired document length to perform an
additional ﬁltering of content. The bottom of Figure 23.2 shows a summary generated by BT-45 of the
datadisplayedgraphicallyatthetopofFigure23.2.
An evaluation of BT-45 involved 30 medical personnel (15 nurses and 15 doctors) having to take
actioninsimulatedscenarios,withthedatapresentedviahuman-writtensummaries,orjustthegraphics,
or the computer-written summaries. The subjects’ actions were then judged by experts as appropriate,
200.0
HR
TcPO2
TcPCO2
SaO2
T1
T250.0
20.0
0.0
15.0
0.0
100.0
0.0
40.0
30.0
1.0
–1.014:15:40
HEEL PRICK
14:10 15 janv. 01 14:15 14:20 14:25 14:30 14:35 14:40 14:45Discrete observations:
14:15:40 HEEL PRICK
14:21:36 HEEL PRICK
14:23:48 FIO2 SETTING
14:29:10 FIO2 SETTING
14:35:02 EXAMINE BABY
...
Mean BP
You saw the baby between 14:10 and 14:50. Heart Rate (HR) = 159. Core Temperature (T1) = 37.7.
Peripheral Temperature (T2) = 34.3. Transcutaneous Oxygen (TcPO2) = 5.8. Transcutaneous CO2
(TcPCO2) = 8.5. Oxygen Saturation (SaO2) = 89.
Over the next 30 minutes T1 graduallly increased to 37.3.
By 14:27 there had been 2 successive desaturations down to 56. As a result, Fraction of Inspired
Oxygen (FIO2) was set to 45%. Over the next 20 minutes T2 decreased to 32.9. A heel prick was taken.
Previously the spo2 sensor had been re-sited.
At 14:31 FIO2 was lowered to 25%. Previously TcPO2 had decreased to 8.4. Over the next 20 minutes
HR decreased to 153.
By 14:40 there had been 2 successive desaturations down to 68. Previously FIO2 had been raised to 32%.
TcPO2 decreased to 5.0. T2 had suddenly
increased to 33.9. Previously the spo2 sensor had been re-sited. The temperature sensor was re-sited.
FIGURE 23.2 Bottom: Summary generated by BT-45 for the graphical data at the top. (Reprinted from Portet, F.
etal.,Artif.Intell. ,173,791,2009,Elsevier.Withpermission.)

EmergingApplicationsofNaturalLanguageGeneration 561
inappropriate,orneutral.Subjectsperformedthebestwithhuman-writtensummaries,whileperformance
withsimplegraphicsorwithcomputer-writtensummarieswasnotasgood.
Bridging the ﬁrst and second generations of intelligent multimedia presentation systems, AutoBrief
generates presentations on transportation schedules in text and information graphics (Green et al.
2004). In addition to addressing ﬁrst-generation issues in multimedia presentation planning and media
allocation, AutoBrief exempliﬁes the second-generation theme of integrating text generation with an
informationvisualizationarchitecture.Forexample,afterAutoBriefhasgeneratedamultimediapresen-
tation,theusercandragelementsofthegeneratedinformationgraphics(suchasabarinabarchart)or
highlightedelementsinthegeneratedtextintoadatavisualizationtooltoexplorethedataunderlyingthe
selectedelement.
In the CLEF project, text generation is integrated with a visualization architecture used to enable
clinicianstonavigatecancerpatients’medicalhistories(HallettandScott2005;Hallett2008).Amedical
historyincludeslargeamountsofnumericdatafromtestresults,chronologicaldatasuchasthedatesthat
tests were performed, and textual data such as reports. Information from each patient’s medical history
is aggregated into a semantic network, the chronical. A visual navigator displays events in the chronical
alongthreeparalleltimelinesshowingdiagnoses,treatments,andinvestigations.Ausercanzoominand
outtomodifythegraphicaldisplay, orrequestareportaboutaselectedeventondisplay. Thegenerated
textsummarizesfeaturesoftheeventanditsrelationshiptoothereventsinthehistory.Akeytaskofthe
documentplanneristorecognizeimportanteventsinthechronical.AsinBT-45,theselectionofcontent
fromthechronicalisconstrainedbyparameters,inthiscase,thedesiredtypeandthelengthofthereport
tobegenerated.Asfarasweknow,therearenopublishedevaluationresultsforCLEF.
Anotherexampleofresearchintegratingtextgenerationwithvisualization,aninteractivesummarizer
generates interactive multimedia summaries of large corpora of evaluative text such as product reviews
(Carenini et al. 2006). As shown in Figure 23.3, the interface includes an interactive visualization of the
data on the right, and a generated textual summary on the left. Users are expected to spend most of
their time exploring the data via the visualization. The purpose of the textual summary is to orient the
userbeforeinteractingwiththevisualization.Contentselectiontasksincludedeterminingfeaturesofan
entityintheevaluativetext,andthenrecognizingthestrengthandthepolarityoftheevaluation.Content
selection creates a hierarchy of extracted features and aggregates the extracted information based upon
thehierarchy,polarityandstrength.Aftercontentselection,thesummaryisstructuredusingadiscourse
strategyforevaluativesummarization.Notethatthisworkdiﬀersfromotherresearchonmulti-document
summarization; in that work, summaries are constructed directly from text extracted from documents
ratherthanbyNLGtechniques.Aformativeevaluationstudyshowedthatusersfoundtheinterfaceboth
intuitiveandinformative.
Summary of customer
reviews for: Apex AD2600
progressive-scan DVD player
There was disagreement among the users about
the Apex AD2600. Although some purchasers
found the video output 1 to be very poor,
customers had mixed opinions about the range
of compatible disc formats 2,3. Furthermore, 
there was disagreement among the users about
extra features 6 were poor, because some users
found the supplied universal remote control 7 to 
be very poor.the user interface 4,5. However, users did agree
on some things. Some purchasers thought the
FIGURE23.3 Textualsummariestoorienttheuserininformationvisualization.

562 HandbookofNaturalLanguageProcessing
TheCaptionGenerationSystem,aﬁrst-generationresearchproject,addressedgenerationofcaptions
for information graphics automatically produced by an automated graphic design system (Mittal et al.1998). Content selection included the analysis of aspects of a generated graphics design that might bediﬃcultforaviewertointerpret.Greatlybroadeningthescopeofcontentselectionforcaptiongeneration,theSIGHTproject(Elzeretal.2006,2007)hasinvestigatedthegenerationoftextsummarizingthemaincommunicative goal of a bar chart appearing on the Web. The motivation for SIGHT is to provide analternative means of access for visually impaired users. For example, if a user encounters a bar chart ona web page, he can invoke SIGHT, which would generate a summary such as This bar chart titled ‘The
notebook spiral’ shows that the dollar value of the average laptop prices fell from 2000 to 2003 and thenfalls more slowly until 2007 (Elzer et al. 2007). To produce such a summary, ﬁrst, a visual extraction
module creates a representation of a bar chart’s visual elements (e.g., axes, bars, and labels). Given thisinput,SIGHT’scontentselectionmoduleusesBayesianplanrecognitiontoinferthemaincommunicativegoal of the bar chart. The evidence used for plan recognition includes the predicted relative eﬀort fordiﬀerent perceptual tasks supported by the graphic, the relative salience of elements of the graphic, andthe use of visual terminology in the graphic’s accompanying text. Note that using perceptual task eﬀortas evidence for the bar chart designer’s communicative goal is motivated by an approach used in themultimedia presentation system mentioned above, AutoBrief (Green et al. 2004); there communicativegoalsinthedocumentplanaremappedbythegraphicsgeneratortoperceptualtasksthatagraphicshouldfacilitate in order to convey those goals. After SIGHT has inferred the main communicative goal of abarchart, generationofthesummaryistemplate-based. However, corpus-derivedheuristicsareusedtoextractadditionalcontentfromtheaccompanyingtextinordertogenerateadequatedescriptionsofthedata displayed on the dependent axis of the bar chart (Demir et al. 2007). SIGHT was evaluated by twohumanevaluators,thatjudgedthequalityofsummariesgeneratedbySIGHTfor202barcharts,randomlyselectedfrom19diﬀerentnewspapersandmagazines.ThetextsgeneratedbySIGHTwerejudgedbetweengoodandverygood,andsigniﬁcantlybetterthanthetextsgeneratedbythreecompetitive,anddiﬀerent,baselines(Demiretal.2007).
23.3 Language Interfaces for Intelligent Tutoring Systems
Educational technology is an area of great signiﬁcance for researchers interested in issues of humancomputer interaction in general and of conversational agents in particular, well beyond the purview ofNLG. Educational applications that are supported by appropriate interactive user interfaces, are calledInteractive Learning Environments (ILEs). For CL/NLP/HLT research, the question arises, what rolelanguageandlanguageprocessingcanplaytosupportILEs,andultimately,toengenderlearningintheirusers.
Here we focus on one kind of ILEs, ITSs, software systems that provide individualized instruction,
like human tutors do in one-on-one tutoring sessions.
∗Whereas ITSs have been shown to be eﬀective
in engendering learning, they still are not equivalent to human tutors. Hence, many researchers areexploringNLasthekeytobridgingthegapbetweenhumantutorsandcurrentITSs.Thisareaofinquiryhas been ﬂourishing in the last few years (Aleven et al. 2003a; Moore et al. 2004; Di Eugenio et al. 2005,2008; Graesser et al. 2005; Zinn et al. 2005; Kumar et al. 2006; Litman and Forbes-Riley 2006; Litmanet al. 2006; Pon-Barry et al. 2006; Fossati et al. 2008), but it has older roots: ﬁrst, pioneering work fromthe1970sand1980s,suchas(Carbonell1970;BurtonandBrown1979);second,continuingresearchbyahandfulofresearcherssuchasMarthaEvensandcolleagues(Evensetal.1993;EvensandMichael2006),
∗Needless to say, the literature on ILEs is vast and we cannot do justice to it here. In particular, there are ILEs built as
pedagogical agents (Lester et al. 1999), or ILEs that support learning through collaboration (Soller 2001; Kersey et al.2009).Someofthemdoincludelanguageintheirinterfaces.PleaserefertotheHandbookWikiforfurtherdiscussionandreferences.

EmergingApplicationsofNaturalLanguageGeneration 563
who did not abandon the enterprise like many others did, probably because of the brittleness of the NLcomponentsofthetime.
Two crucial goals of this collective eﬀort are (a) to ascertain whether an ITS that models tutorial
dialogue,namely,one-on-oneconversationsbetweenahumantutorandastudent,doespositivelyimpact
learning;and(b)toinvestigatewhichspeciﬁcfeaturesoftutorialdialoguesengenderlearning. Thepursuitisboththeoreticalandpractical.Fromacognitivepointofview,researchersinpsychology,education,andcomputerscienceareinvestigatingwhichfeaturesofdialogueareconducivetolearning.Fromapracticalpointofview, full-ﬂedgedNLinteractionwithanITSisnotattainableyet. Ifonlysomespeciﬁcfeaturesofhumantutoringengenderlearning,thenanITSthatonlyincludesthosewouldbeeasiertobuild,andmore likely to be eﬀective than an ITS that tries to address the full complexity of human dialogue. Forexample, several researchers have studied prompts(Chi et al. 1994; Pilkington 1999; Evens and Michael
2006; Cade et al. 2008). While deﬁnitions vary, a core component of a promptis the tutor prodding the
student along, either with a pump (a content-free question such as And then? ), or a question proper
(How can TPR change?), or a trailing statement ( If you divide 10 by 1, you get ... ). If we discovered
that,say,pumpsbutnotcontentful questions engenderlearning,obviouslypumpswouldbemucheasier
to implement. We note that ﬁne-grained studies that compare the eﬀectiveness of diﬀerent features oftutoring dialogues have started to appear only in the very last few years (Litman and Forbes-Riley 2006;Luetal.2007;Ohlssonetal.2007).
It is not by accident that we focused on moves on the part of the tutor, rather than on the part of the
students, as examples of possible eﬀective features of tutoring dialogues. Whereas language interactionwith an ITS needs to address both components of a dialogue, the interpretation of the input from thestudentandprovidingfeedbackonthepartoftheITS,muchresearchhasfocusedonthelatter,perhapsbecause providing hints and feedback in the appropriate way is considered as a primary goal of ILEs(Aleven et al. 2003b); or perhaps because many studies of tutoring dialogues have shown that tutors domostofthetalking,producinganywherefrom63%(EvensandMichael2006),to77%(Cadeetal.2008),toanastounding93%ofthetotalwords(Fossatietal.2008).
Before turning to the description of some representative systems and their interfaces, a few words
on how these systems are evaluated. The most important thing to ascertain is whether they fosterlearning. Hence, they are often evaluated in terms of learning gains: did students who used the ITS
show more learning that students in a competitive condition? Learning gains are most often a function
of two scores obtained by the students on two tests: the pretest, a test taken before the treatment, andthe posttest, a test taken after the treatment. The pre- and posttest are most often identical. To trackpersistence of learning, sometimes the posttest is (re)administered after a delay of days or weeks. Thesimplest version of learning gain is the diﬀerence between these two scores, sometimes normalizedby the maximum possible gain. Finally, much research on educational technology talks about eﬀect
size: given a statistical diﬀerence between the various conditions, how much more eﬀective is onecondition with respect to the other? One common deﬁnition of eﬀect size is Cohen’s d, the diﬀerence
between the two means of post- and pretest scores, divided by the standard deviation of either (Cohen1988).
∗
Asthereaderwillnoteafterreadingtherestofthissection,evaluationsofITSsendowedwithlanguage
interfacesprovideamixedpicture.Speciﬁcally,itisstillnotclearwhetherITSsthatareabletoengageinfull-ﬂedgeddialogueinteractionsaremoreeﬀectivethanITSsendowedwithsimplerlanguageinterfaces,such as providing canned explanations to address students’ misconceptions. However, these results arenot necessarily disappointing from an NLG point of view. Even if it turns out that full-ﬂedged dialogueinteractionisnotnecessary,itisimportanttonotethataninterfacethatprovideslanguagefeedback,evenif not interactive, still appears to be the superior choice, as we hope to demonstrate by the end of thissection.
∗Cohen argued that the standard deviation of either group could be used when the variances of the two groups are
homogeneous.Otherwise,ameasureof pooledstandarddeviation canbeemployed.

564 HandbookofNaturalLanguageProcessing
23.3.1 CIRCSIM-Tutor
CIRCSIM-Tutor (http://www.cs.iit.edu/˜circsim/) can be considered as the pioneer among the ITSsendowed with NL interfaces developed in the last 15–20 years. The book by Evens and Michael (2006)retracesitshistoryanddevelopment.Sinceitsinception,itwasmeanttohelpstudentslearnaboutaspeciﬁckindofcardiovascularphenomenon,bysimulatingtheinteractionsthattwoexperttutorsinthisdomainhadwiththeirstudentsinthephysiologycomputerlaboratory.TheCIRCSIM-Tutorprojecthasresultedinawealthofdataandanalysesofthatdata,fromtutormovestostudents’answers.TheCIRCSIM-Tutorproject was also one of the ﬁrst to use machine learning, speciﬁcally, decision tree learning, to uncoverhowhumantutorsmakedecisions.Onepartoftheanalysisthathasbeenveryinﬂuentialonmanyotherresearchers engaged in modeling tutorial dialogues was the identiﬁcation of Directed Lines of Reasoning
(DRL). A DLR is a series of questions, prompts, and hints that tutors use to deliver information andto remedy misconceptions. Often it ends with the student uncovering a contradiction. The excerpt inFigure 23.4 shows this style of tutoring (it is taken from the data included on the CD accompanyingthe Evens and Michael (2006) book). These were keyboard–keyboard dialogues, and formatting andmistypingsarefromtheoriginal.Theacronymsstandfor:RAP,forRightAtrialPressure;HR,forHeartrate;MAP,forMeanArterialPressure;TPR,forTotalPheriperalResistance.Thetutor’sturnsarelabelledasK2-tu-16-1,andthestudent’s,asK2- st-17-1.
DLRs are representative of an interactive and reactive tutoring style: the tutor is pursuing certain
tutoring goals, decomposes them both according to tutoring strategies but also according to how thestudentreactsandtakespartinthedialogueitself.Thissortofinteractionthusposessomerequirementson the dialogue planner the ITS uses. The latest version of the CIRCSIM-TUTOR dialogue manageris built on top of APE (Freedman 1996). APE is a hierarchical task network planner, and as such it isparticularlyappropriateforhierarchicallyorganizeddialogues.APEsupportssingle-turnandmulti-turnteachingstrategies.Itusessimpletemplatedrivengenerationforrealizingelementaryplansteps.WewillﬁndAPEusedagainbelow,inATLAS-ANDESandWHY2-ATLAS.
Three versions of CIRCSIM-Tutor were evaluated, including the last Version 2.9. This version of
CIRCSIM-TUTORisabletounderstandthestudent’sinputviaaparserthatiscomposedbyacascadeofﬁnite state automata, which can also interpret “algebraic sentences” that mix English and mathematics.Subjects were medical students who were learning the material. The experiments show that CIRCSIM-Tutordidengenderlearning, andthelearningeﬀectswerelargerthansimplyreadingtext. However, nosigniﬁcantdiﬀerencesinlearningwereuncoveredinanexperimentthatpittedCIRCSIM-TUTORagainst
K2-tu-16-1: Is rap the first variable that would be affected by
a suddenincrease in HR?
K2-st-17-1: No, I believe that map would first be affectedK2-tu-18-1: Could you write an equation that showed how HR and
MAP wererelated?
K2-st-19-1: Map is not directly related to HR but is directly related
to Co tpr
K2-tu-20-1: So then when HR goes up suddenly, what will be the
next variableaffected and in what direction will itchange?
K2-st-21-1: Tpr will increaseK2-tu-22-1: TPR is a neurally controlled variable.K2-tu-22-2: We are in the DR period,before reflexes and neural
firing rates change.
K2-tu-22-3: How can TPRchange?K2-st-23-1: TPR can change by sympathetic action, therefore without
this neuralresponse, the next variable to be affectedwould be the CO
K2-tu-24-1: Absolutely.K2-tu-24-2: Now were on the right track.
FIGURE23.4 AnexampleofaDirectedLineofReasoningfromtheCIRCSIMdialogues.

EmergingApplicationsofNaturalLanguageGeneration 565
CIRCSIM,amuchsimplerversionofthesystemthatdoesnotincludetutorialdialogue,butthatprovidesfeedbackasauthoredmini-lessons(intheauthors’words, carefullyeditedrelevanttexts ).
23.3.2 AUTOTUTOR
AUTOTUTOR (http://www.autotutor.org/) is an ITS whose design is routed in a long tradition atthe University of Memphis of studying learning by means of tutorial interactions (inﬂuential olderpapers by Graesser and collaborators include (Person et al. 1994; Graesser et al. 1995)). In its fullerincarnation, AutoTutor is embodied as an animated agent that engages in a conversation with thestudent, and interacts via spoken language, facial expressions, and gestures. The input from studentsis most often typed, not spoken. The AUTOTUTOR architecture has been applied to three domains,computer literacy, scientiﬁc reasoning, and qualitative Newtonian physics (for the latter, see below onWHY2-AUTOTUTOR)(Graesseretal.2001,2004,2005).
AUTOTUTOR’s dialogue management relies on curriculum scripts. AUTOTUTOR asks the student
questions about certain topics, and conducts a dialogue until a good answer to that question has beenobtained. Each script includes a main focal question, an ideal complete answer, expected good answers,andmisconceptions. LatentSemanticAnalysis(LSA)(LandauerandDumais1997; Foltzetal. 1999), anapproachbasedonSingularValueDecomposition,isusedtocomparestudentcontributionstoexpectedanswers, good and bad. A Dialog Advancer Network (DAN) manages the conversation. The DANcomprisesasetofdialogpathslinkedtoparticularstudentspeechacttypes,sothatAutoTutorcanadapteachdialogmovetotheprecedingstudentturnandrespondappropriately.
The DAN embeds diﬀerent algorithms to choose the next move. One employs a set of 15 fuzzy
production rules to select the next dialogue move for the tutoring system. Although these productionrules have achieved good results for AUTOTUTOR, they are deﬁned manually and only cover limitedsituations.Manualdesignofproductionrules(oroftheplanoperatorsinAPE,forthatmatter)isresource-and time- consuming, hence, the ﬁeld is moving toward more empirical approaches—for example,see the newly established area of Educational Data Mining (http://www.educationaldatamining.org/).Additionally,AUTOTUTOR’sDANdoesnotallowfordialoguestrategiesthataremultiturnorresultinsubdialogues.
23.3.3 ATLAS-ANDES, WHY2-ATLAS, and WHY2-AUTOTUTOR
The ANDES physics tutor from the University of Pittsburgh is an ITS designed to support students inlearningNewtonianmechanics.ANDESpresentsstudentswithquantitativeproblemstobesolvedwithina graphical interface that tries to resemble a piece of paper as much as possible. Immediate feedbackis presented via red or green highlighting, and hints are provided upon request. It has been used inclassroomsatU.S.colleges(http://www.andestutor.org/).
In a ﬁrst development toward adding language to ANDES, the group at the University of Pittsburgh
developedATLAS-ANDES.ANDESwasendowedwithafulldialogueplanningapproach,viatheATLASdialogue manager, which in turn has the APE dialogue planner at its core, that we described above(Freedman2000;VanLehnetal.2000).
In a second more encompassing development, the ANDES research group moved to explore the
followinghypothesis:engagingstudentsin qualitative physicsproblemsolving,asopposedtoquantitative,
would engender more opportunities for tutoring them via natural dialogues, and as a consequence,would help them deepen their conceptual understanding. Two diﬀerent ITSs emerged from this eﬀort,WHY2-ATLAS and WHY2-AUTOTUTOR
∗(http://www.pitt.edu/˜vanlehn/why2000.html). These two
ITSs engage students in qualitative problems, such as Suppose you are running at constant speed in a
∗ThefollowingdescriptionofthetwoITSsismainlyadaptedfromVanLehnetal.(2007).

566 HandbookofNaturalLanguageProcessing
straight line. You throw a pumpkin straight up. Where will it land? . In response, students write an essay
thatisinterpretedbytheITS;theITSthenengagesthestudentinadialoguetoremedymisconceptions.
Thetwosystemsdiﬀerinthewaythestudentessaysareprocessed,andalsosomewhatinthepurpose
of the interaction: in WHY2-ATLAS, the ITS chooses one ﬂaw from the ones the essay exhibited andengages the student in a dialogue to lead the student to correct it in writing in a dedicated subwindow,whereasWHY2-AUTOTUTORdirectlyuseshintsandpromptstoleadthestudenttocorrectingtheﬂawinthedialogueitself.
InWHY2-ATLAS,thesystemanalyzestheﬂawusingacombinationofknowledge-basedandstatistical
techniques (Jordan et al. 2006). Interestingly, among those techniques is an abductive reasoner thatanalyzestherepresentationofthestudent’sexplanationforcorrectnessandcompleteness.IftheITSﬁndsthat an essay has ﬂaws, it picks one and discusses it with the student. The discussion is organized as aKnowledge Construction Dialogue(KCD),whosedesign, astheauthorssay, wasstronglyinﬂuenced bytheDirectedLineofReasoningstudiedbyEvensandcolleagues.Atthecoreofthedialoguemanagerwestill ﬁnd APE, described above; a compiler maps KCDs into plan operators, which are used by APE tocombine KCDs into larger recursive automata, in this way supporting tutoring goals that develop overmultipleturnsofdialogue.
InWHY2-AUTOTUTOR,thegeneralarchitectureisthatofAUTOTUTOR,asdescribedabove(hence
the name). Thus, the student essay is interpreted via LSA; and the ensuing dialogue is managed via theAUTOTUTOR dialogue manager. Additionally, the tutor is embodied as an animated conversationalagent,anditsturnsarespokenviaatext-to-speechsynthesizer.
VanLehnetal.(2007)discussesanimpressivebatteryofsevenexperimentswherehumantutoringand
the two computer tutors are pitted against a variety of less interactive conditions: from reading from atextbook to reading canned text based on a general model of students’ misconceptions, rather than onthe speciﬁc misconceptions students show in their essays. The experiments were originally conceivedas a way to verify the Interaction Hypothesis , i.e., that it is tutorial interaction that fosters learning in
the tutee (Chi et al. 1989, 2001; Fox 1993). The expectation was that human tutors would be superiorto computer tutors, which in turn would be superior to reading canned text and to reading a textbook.However,theresultsweremixed.Inparticular,interactivetutoring,whetherbyhumansorbycomputers,wasnottheclearwinner. Humanandcomputertutoringwasbetterthanreadingfromthetextbook. Asfar as beating reading canned text, the hypothesis was veriﬁed only for novice students working witha human tutor when they were taught materials appropriate for intermediate students. From an NLinterface point of view, it is interesting to note that no signiﬁcant diﬀerences between WHY2-ATLASand WHY2-AUTOTUTOR were found. It would be tempting to conclude that no matter what sortof interaction the system provides, students learn the same amount, and even more dramatically, thatinteraction is not crucial to learning. However, ﬁrst, as VanLehn et al. (2007) mention, there maybe alternative explanations, one of which—the lack of spoken interaction—is mentioned below, underITSPOKE. Second, even if the interaction hypothesis were ultimately disproven, it is important to notethatalanguageinterface,evenifnotinteractive,maystillbethesuperiorchoice.Infact,thebarposedbythe“cannedtext”conditionwasquitehigh:thetextsthestudentsreadwerecarefullycrafted,notjustliftedout of a textbook, as in the experiment pitting CIRCSIM-Tutor against CIRCSIM we described earlier.NLGtechniquescouldgenerateatleastsomeofthosetextsontheﬂy,insteadofhumanspreparingtheminadvance.23.3.3.1 ITSPOKEThe research stemming from the original ANDES system spawned two more strands of inquiry thatare worth mentioning. First, part of the reason why neither WHY2-ATLAS nor WHY2-AUTOTUTORengendered as much learning as expected may be that the interaction between the ITS and the studentis typed as opposed to spoken (in both, students type all their input, but in WHY2-AUTOTUTORthe output from the ITSs is spoken). There is evidence that using typed text may be detrimental. Forexample, Moreno (2006) shows that presenting text via speech in three diﬀerent multimedia learning

EmergingApplicationsofNaturalLanguageGeneration 567
scenarios is more eﬀective than presenting it in written form on the screen. Diane Litman and collabo-rators (http://www.cs.pitt.edu/˜litman/itspoke.html) are precisely exploring this question: what are theconsequences,ifany,ofaddingspokenoutputtoanITS?ITSPOKEisaversionofWHY2-ATLASwherethestudentstilltypestheinitialanswer,andessay;however,thewholetutoringdialogueisspoken,byboththestudentandtheITS.Litman’sresearchhasresultedinawealthofdataandanalysesofthediﬀerencesbetween typed and spoken tutoring dialogues, with both human and software tutors. However, the juryis still out on whether speech is more eﬀective than typed text in an ITS. Litman’s results (Litman et al.2006) are consistent with the initial hypothesis that tutored students learn more when the dialogue isspoken as opposed to typed. However, this holds only with human tutors. In fact, when ITSPOKE andWHY2-ATLAS were directly compared, there were no diﬀerences in learning. This could be due not somuchtothediﬀerentsetting, butrather, totechnologicallimitations. Students inITSPOKEtooksignif-icantly longer on average to complete their tasks, 97’ with ITSPOKE but 68’ with WHY2-ATLAS. Thereverse holds with human tutors. The average length of spoken human–human dialogues was 166’; thislength almost triples to 430’ in typed human–human dialogues. The considerably longer dialogues withITSPOKEareduetotwofactors. ExtrautterancesaregeneratedbyITSPOKEduetospeechrecognitionerrors, as when ITSPOKE asks the student to repeat an utterance it did not understand. Additionally,studentstooklongertoprocessITSPOKEprompts,sincetheyoftenﬁrstlistenedtothem,andthenreadthem: after the student and the tutor are ﬁnished speaking, the dialogue history window displays howITSPOKEinterpretedthestudent’sinput,andITSPOKE’sownturns.23.3.3.2 TUTALKAnother oﬀshoot of the ANDES research program is TuTalk (Jordan et al. 2001, 2007). In its authors’words,TuTalk provides a dialogue system server and authoring tool that supports the rapid development
of dialogue systems to be used in learning studies . Its development was prompted by the realization that
huge eﬀorts are required to develop a dialogue manager for learning applications, and that researchersnotversedinComputerSciencewouldnotbeabletodevelopsuchasystematall.AtthecoreofTuTalkare tools that support “Knowledge Construction Dialogues (KCDs),” inspired by the DLRs discussedunder CIRCSIM-Tutor. In a KCD, the tutor tries to elicit a main line of reasoning from the student bya series of questions. The most basic dialogue that one can create with TuTalk corresponds to a ﬁnitestate machine: each state contains a single tutor turn, and the arcs leaving the state correspond to allpossibleclassiﬁcationsofstudentturns.Morecomplexdialoguescanbecreatedbynestingsubdialogues;formally,TuTalkbecomesapush-downautomaton.TheTuTalkdialoguemanagerisimplementedusingthereactiveplannerAPE(Freedman2000)thatwasdiscussedearlier,anddecideswhattoexpressnextandhowtocontextualizestudentresponses.TuTalkalsoprovidesanauthoringenvironmenttoauthortutorialdialogues, meantfortutoringexpertsinthedomainwhoareunlikelytobeproﬁcientatprogrammingadialogue manager. So far, TuTalk has been evaluated from the authoring point of view, but we are notaware of evaluation results for ITSs whose NL interfaces are built on top of TuTalk, other than (Kumaret al. 2006). However, various groups including (Kersey et al. 2009) are planning to conduct this sort ofevaluationinthenearfuture.
23.3.4 Brieﬂy Noted
Toconclude,webrieﬂynotetheworkdonebythefollowinggroups.WereferthereadertotheHandbookWikiforfurtherinformationonalltopicsdiscussedinthissection,andonthelargerthemeofmarryingNLPandeducationaltechnology.
•JohannaMoore(UniversityofEdinburgh)wasoneoftheﬁrstinvestigatorstoexploretheroleoflanguage in interfaces to ITSs, with a focus on the analysis and annotation of tutoring dialogues(MoserandMoore1995,1996),andondiscourseplannersthatcandeliverthatfeedback(Youngetal.1994;Mooreetal.1996;Zinnetal.2002,2005).

568 HandbookofNaturalLanguageProcessing
•Barbara Di Eugenio’s group (University of Illinois at Chicago) has looked into how diﬀerentfeatures of feedback aﬀect learning: from showing that providing more succinct and abstractfeedback engenders more learning (Di Eugenio et al. 2005, 2008); to exploring the diﬀerencesbetween expert and novice tutors (Di Eugenio et al. 2006; Lu etal. 2008); to modeling therole ofpositiveandnegativefeedbacksinanITSthattutorsaboutlinkedlists,andthathasstartedbeingevaluatedinrealclassrooms(Ohlssonetal.2007;Fossatietal.2008).
•Much work on delivering explanations of mathematical proofs (Benzmüller et al. 2003; FiedlerandTsovaltzi2005)hasbeenconductedatSaarlandUniversityinSaarbrücken,Germany.
•AninterdisciplinaryresearchgroupledbyJohnAndersonandKenKoedingeratCarnegieMellonUniversity has been extremely successful in developing a number of Cognitive Tutors, some of
which have been adopted by hundreds if not thousands of schools (http://pact.cs.cmu.edu/).This group has explored many aspects of tutoring and learning, including the role of language(HeﬀernanandKoedinger2002;Alevenetal.2003a).
23.4 Argumentation for Health-Care Consumers
TherehasbeenaconsiderableamountofNLGresearchforhealth-careapplicationsingeneral,assurveyedinCawseyetal.(1997);Hüske-Kraus(2003);BickmoreandGiorgino(2006).Theﬁeldincludesresearchon the generation of argumentation addressed to the health-care consumer, which is the focus of thissection. Argumentation is a social and verbal activity whose goal is to support or refute a position (vanEemeren et al. 1996). The scope of argumentation theory goes beyond the criteria of formal validity toacceptabilityineverydaydiscourseandinspecializedﬁeldssuchaslawandscience.Someargumentationtheories consider contextual factors in the analysis of argumentative discourse, e.g., the analysis of anargument may include its implicit premises or assumptions. Some address the internal organization ofarguments,theargumentationschemethatdescribestherelationshipofaclaimtoitspremises.Researchonargumentgenerationforhealth-careconsumerscanbecharacterizedbyitsexplicitorimplicitbasisintheoriesofargumentation(surveyedin(vanEemerenetal.1996))and/ortheoriesfromthesocialsciences(e.g., Prochaska and Clemente 1992). In most but not all of the work covered in this section the goal istopersuadetheaddresseetoalterbehaviorinawaytopromotegoodhealth,e.g.,toadoptahealthydiet.Theargumentsmaybeexpressedinwrittentextordialogue;dialoguemaybedeliveredintextorspokenbyanEmbodiedConversationalAgent(ECA).Themainresearchfocusinallofthisworkisondocumentplanning(includingcontentselectionanddocumentstructuring)ofarguments.
TheSTOPsystem(Reiteretal.1999,2003)generatespersonalizedletterswiththegoalofencouraging
therecipienttostopsmoking.Usinginformationacquiredfromarecipient’sresponsestoaquestionnaire,STOPclassiﬁestherecipientintooneofsevencategoriesofsmoker.Therecipient’sclassiﬁcationisusedto select from genre-speciﬁc document-planning schemas. The classiﬁcation scheme is a reﬁnement,suggested by domain experts, of the Stages of Change model used in health counseling (Prochaska andClemente1992).Theschemasarealsobaseduponknowledgeacquiredfromdomainexperts.Forexample,a recipient who is classiﬁed as a Classic precontemplator, someone who is ambivalent about smokingbut not currently planning to quit, would be given a letter emphasizing the disadvantages of smoking;whereassomeoneclassiﬁedasLacksconﬁdence,i.e.,someonewhowouldliketostopsmokingbutdoubtsthat he could, would be given a letter to increase his conﬁdence. The eﬀectiveness of letters generatedby STOP was evaluated in a large-scale clinical trial to see if the recipients had quit smoking within sixmonths of receiving the letter. However, the study found that recipients of letters generated by STOPwerenomorelikelytoquitthanrecipientsofnon-tailoredletters.Reiteretal.(2003)speculatesatlengthonwhythismayhavebeenthecase.Potentialexplanationsrangethegamutfromthetypeofapplication(the important factor is to receive a letter from one’s doctor encouraging a patient to stop smoking, asopposed to receiving a tailoredletter); to tailoring being based on too little information, or being done

EmergingApplicationsofNaturalLanguageGeneration 569
incorrectly;totailoringhavinganeﬀectonheavysmokers,buttheclinicaltrialbeingtoosmalltoprovidestatisticallysigniﬁcantevidenceofthis.
Daphne(Grassoetal.2000)isdesignedtoengageinpersuasivedialoguewithausertopromotehealthy
nutrition.ThedesignofDaphne’susermodelisbasedupontwocomplementaryapproachesfromtheﬁeldof health promotion. A user is characterized by his progress through the stages of the Stages of Changemodel. In addition, the Health Belief model (Becker 1974) is used to characterize the kinds of beliefsthat impede behavior change. Daphne’s dialogue generator employs a hierarchical planning process.Thetop-level goals are planned using operators thatembody knowledge from theStages of Change andHealthBeliefmodels.ThenextlevelofplanningusesplanoperatorsthatembodyargumentationschemasfromtheNewRhetoric(PerelmanandOlbrechts-Tyteca1969),atheoryofinformalargumentationthatdescribes how people attempt to persuade an audience by use of premises that reﬂect the audience’spreferences and values. Although the schemas of the New Rhetoric are not domain-speciﬁc, a studyconﬁrmed that the argumentative style used by actual nutritionists can be analyzed in terms of NewRhetoric schemas. To illustrate, Argumentation by dissociation makes a distinction that the audiencemay not have considered, such as You said that people who are concerned about diet are self-centred but
Iprefertoconsiderthemjustresponsiblepersons (p.1082).AschemainthecategorynamedArgumentation
establishing the structure of reality uses an appeal to a model to promote an action, e.g., Healthy people
havefruitforbreakfast (p.1082).InanevaluationofDaphne,46participantsengagedine-mail”dialogue”
with Daphne. (Daphne’s responses were translated into English by an experimenter.) Over half of theparticipants said that the system made them more conscious of their diet and led them to contemplatechanging their diet (since there was only one experimental condition, it is not possible to ascertain thesigniﬁcanceoftheseresults).
AprototypeECAfornutritioncounselinghasbeendevelopedbydeRosisetal.(2006).AsinDaphne,
thesystemusestheStagesofChangemodelindialogueplanning.RepresentedwithadynamicBayesiannetwork (Nicholson and Brady 1994), the system’s user model is updated after each dialogue moveto infer the user’s probable current Stage of Change and attitude toward the ECA. A related group ofresearchers(Mazzottaetal.2007)developedPortia,thepersuasionmoduleforadialoguesystemthathasbeen implemented in the same domain. Again using Bayesian networks, Portia’s user model infers therecipient’sprobableattitudes,values,andgoalsfromknowledgeofhispersonalitytraitsandlivinghabits.ABayesiannetworkisalsousedtorepresentrationalandemotionalargumentationstrategiesbaseduponschemesinformallydescribedbyanargumentationtheorist(Walton1996),e.g.,AppealtoExpertOpinionandArgumentfromPositiveConsequences.Whenplanninganargument,theinferreduserattributesareusedtopredictthepersuasivenessofdiﬀerentargumentationstrategies,rationaloremotional,thatcouldbe used. Portia may combine subarguments to increase the predicted persuasiveness. The argumentsare translated into text or spoken dialogue by using canned text. For example, Portia can generate thefollowingargument: I’msurprisedatyou,John!Youplaysportsandlookafteryourselfwithregularmedical
checkups,thenyoueatalotofmeatandcarbohydrates,almostexcludingvegetablesfromyourdiet!Perhapsyou don’t know the beneﬁts that a diet rich in vegetables can have on your health. A dinner of fresh, tastysalads is easy to prepare and is an excellent way of having a good time with your friends (Mazzotta et al.
2007, p. 48). Portia’s design was partly based on the results of a formative experiment with 39 subjects;however,atthetimeofthiswriting,therearenopublishedresultsonevaluatingPortiaitselfwithusers.
The FitTrack system was developed to investigate the ability of an ECA exercise advisor to promote
physical activity (Bickmore and Picard 2005; Bickmore et al. 2005a, 2005b). In contrast to the aboveresearchincorporatingstrategiesfromargumentationtheories, thedesignofFitTrackwasmotivatedbycounseling theories and uses linguistic strategies for maintaining long-term social-emotional relation-ships with users, e.g., expressing empathy, use of social dialogue, self-disclosure, and talking about therelationship. In addition, FitTrack maintains a memory of the user’s past interactions with the systemtobereferencedinfutureinteractions.DialoguemanagementiscontrolledbyanAugmentedTransitionNetwork (ATN). Generation of the ECA’s utterances is template-based. In a later version of the system,to provide variability in dialogue, two simple approaches are followed. At each state of the dialogue,

570 HandbookofNaturalLanguageProcessing
multiple utterances are provided and one is randomly selected. In addition, information stored frompast dialogues with the user is used to select branches in the ATN and to ﬁll in utterance template slots.One study compared the eﬀectiveness of two versions of FitTrack. One version employed the linguisticstrategies for maintaining long-term social–emotional relationships with users, as discussed above; thesecondversiondidnot.Subjectsinteractedwiththesystemalmostdailyfor30days.Thegroupinteractingwiththerelationalversionshowedasigniﬁcantincreaseinadesiretocontinueusingthesystem.Anotherstudy(Bickmoreetal.2005a)compared,overa2monthperiod,subjectswhousedFitTracktoacontrolgroup who were given educational pamphlets. The intervention group performed signiﬁcantly morewalkingduringtheexperimentthanthecontrolgroup.
GenIEAssistantgeneratestheﬁrstdraftofgeneticcounselingletters,whichtypicallycontainarguments,
e.g.,justifyingthediagnosisofageneticcondition(Greenetal.2009).Ratherthangenerateargumentstopersuadearecipienttochangehisbehavior,thegoalofthisresearchistogeneratenormativeargumentstransparentlysothattherecipientcanevaluateorchallengeanargumentorreevaluateitinlightofnewevidence.Transparencyrequiresanargument’sstructureandcomponentstobeavailabletoitsaudience.Arguments in a corpus of genetic counseling letters were analyzed in terms of their argument-theoreticcomponents: data, claim, and warrant (Toulmin 1998). In addition, the domain content of the letterswasanalyzedintermsofasimpliﬁedquasi-causalconceptualmodelofgenetics(Green2005)thatcanbemodeledinaQualitativeProbabilisticNetwork(QPN)formalism(DruzdzelandHenrion1993).Fromthetwoanalysesofthecorpus,abstractnon-domain-speciﬁcargumentationschemes,suchasEﬀecttoCause,weredescribedintermsofvariablesandformalpropertiesofQPNs.Forgeneration,GenIEAssistantusestheschemestoextractcontentfromaQPNdescribingthegeneticconditionstobecoveredinaletter.Afteran argument has been added to the discourse plan representing other parts of the letter (generated by adiscoursegrammar),theplanundergoesaggregation,pruning,andadditionofdiscoursecuestopromoteargument transparency. The resulting plan is transformed to text by a linguistic realization component.The generated text is two to four paragraphs in length, depending upon the type of medical case. In anevaluation of letters generated by GenIE Assistant, domain experts found the writing quality of thoseletterstobeaboutasgoodasthatoflettersonthesametopicwrittenbyageneticcounselor,i.e.,boththehuman-writtenandcomputer-generatedlettersreceivedaboutthesameamountofeditingbythejudges.
Acknowledgments
TheauthorsaregratefultoNitinIndurkhyaforallmannersofencouragementandforhelpfulsuggestionsonthecontentandformatofthechapter;toGiuseppeCareniniforhisthoughtfulreview,andforprovidinguswithFigure23.3;andtoPamelaJordanforherhelponthesectiononNLGforITSs.BarbaraDiEugeniogratefullyacknowledgestheNationalScienceFoundation(awardALT-0536968)andtheOﬃceofNavalResearch (award N000140010640) for partial ﬁnancial support. Nancy Green gratefully acknowledgesthe support of the National Science Foundation (award CAREER 0132821) during the period that thismaterialwaswritten.
References
Aleven, V., K. R. Koedinger, and O. Popescu (2003a, June). A tutorial dialog system to support self-
explanation: Evaluation and open questions. In H. U. Hoppe, F. Verdejo, and J. Kay (Eds.), AIED
03,Proceedingsofthe11thInternationalConferenceonArtiﬁcialIntelligenceinEducation ,Biarritz,
France,pp.39–46.IOSPress.
Aleven, V., E. Stahl, S. Schworm, F. Fischer, and R. Wallace (2003b, Fall). Help seeking and help design
ininteractivelearningenvironments. ReviewofEducationalResearch73 (3),277–320.

EmergingApplicationsofNaturalLanguageGeneration 571
André,E.(2000).Thegenerationofmultimediapresentations.InR.Dale,H.Moisl,andH.Somers(Eds.),
Handbook of Natural Language Processing (1st ed.). Chapter 12, pp. 305–328. New York: Marcel
Dekker,Inc.
André, E., W. Finkler, W. Graf, T. Rist, A. Schauder, and W. Wahlster (1993). WIP: The automatic
synthesis of multimodal presentations. In M. T. Maybury (Ed.), Intelligent Multimedia Interfaces ,
pp.75–93.Cambridge,MA:TheMITPress.
Becker,H.(1974). TheHealthBeliefModelandPersonalHealthBehavior .Thorofare,NJ:C.B.Slack.
Benzmüller, C., A. Fiedler, M. Gabsdil, H. Horacek, I. Kruijﬀ-Korbayová, D. Tsovaltzi, B. Q. Vo, and
M.Wolska(2003).Discoursephenomenaintutorialdialogsonmathematicalproofs. InI.Kruijﬀ-KorbayováandC.Kosny(Eds.), ProceedingsofDiaBruck’03,theSeventhWorkshopontheSemantics
andPragmaticsofLanguage ,Wallerfangen,Germany,pp.165–166.
Bickmore, T. and T. Giorgino (2006). Health dialog systems for patients and consumers. Journal of
BiomedicalInformatics39 (5),556–571.
Bickmore, T. and R. Picard (2005). Establishing and maintaining long-term human–computer
relationships. ACMTransactionsonComputer-HumanInteraction12(2),293–327.
Bickmore, T., L. Caruso, K. Clough-Gorr, and T. Hereen (2005a). ‘It’s just like you talk to a friend’—
Relationalagentsforolderadults. InteractingwithComputers17 (6),711–735.
Bickmore, T., A. Gruber, and R. Picard (2005b). Establishing the computer-patient working alliance in
automatedhealthbehaviorchangeinterventions. PatientEducationandCounseling 59 (1),21–30.
Burton, R. R. and J. S. Brown (1979). Toward a natural language capability for computer-assisted
instruction. In H. O’Neill (Ed.), Procedures for Instructional Systems Development , pp. 272–313.
NewYork:AcademicPress.
Cade,W.L.,J.L.Copeland,N.K.Person,andS.K.D’Mello(2008).Dialoguemodesinexperttutoring.In
Intelligent Tutoring Systems, Lecture Notes in Computer Science 5091:470–479. Berlin/Heidelberg:
Springer.
Carbonell, J. (1970). AI in CAI: An artiﬁcial intelligence approach to computer-aided instruction. IEEE
TransactionsonMan-MachineSystems11,190–202.
Carenini, G., R. Ng, and A. Pauls (2006). Interactive multimedia summaries of evaluative text. In IUI
’06: Proceedings of the 10th International Conference on Intelligent User Interfaces,N e wY o r k ,pp.124–131.ACM.
Cawsey, A. J., B. L. Webber, and R. B. Jones (1997). Natural language generation in health care. Journal
oftheAmericanMedicalInformaticsAssociation4 (6),473–82.
Chi,M.T.H.,M.Bassok,M.W.Lewis,P.Reimann,andR.Glaser(1989).Self-explanations:Howstudents
studyanduseexamplesinlearningtosolveproblems. CognitiveScience13(2),145–182.
Chi, M.T.H., N.deLeeuw, M.-H.Chiu, andC.LaVancher(1994). Elicitingself-explanationsimproves
understanding. CognitiveScience18(3),439–477.
Chi, M. T. H., S. A. Siler, T. Yamauchi, and R. G. Hausmann (2001). Learning from human tutoring.
CognitiveScience25,471–533.
Cohen,J.(1988). StatisticalPowerAnalysisFortheBehavioralSciences (2nded.).Hillsdale,NJ:Lawrence
EarlbaumAssociates.
Dalal, M., S. Feiner, K. McKeown, S.Pan, M.Zhou, T. Höllerer, J. Shaw, Y.Feng, and J. Fromer (1996).
Negotiation for automated generation of temporal multimedia presentations. In MULTIMEDIA
’96:ProceedingsoftheFourthACMInternationalConferenceonMultimedia,NewYork,pp.55–64.ACM.
de Rosis, F., N. Novielli, V. Caroﬁglio, A. Cavalluzzi, and B. De Carolis (2006). User modeling and
adaptation in health promotion dialogs with an animated character. Journal of Biomedical Infor-
matics39 (5),514–531.
Demir, S., S. Carberry, and S. Elzer (2007). Eﬀectively realizing the inferred message of an information
graphic. In Proceedings of Recent Advances in Natural Language Processing (RANLP) , Borovets,
Bulgaria,pp.150–156.

572 HandbookofNaturalLanguageProcessing
Di Eugenio, B., D. Fossati, D. Yu, S. Haller, and M. Glass (2005, June). Aggregation improves learning:
Experimentsinnaturallanguagegenerationforintelligenttutoringsystems.In ACL05,Proceedings
ofthe42ndMeetingoftheAssociationforComputationalLinguistics ,AnnArbor,MI,pp.50–57.
Di Eugenio, B., T. C. Kershaw, X. Lu, A. Corrigan-Halpern, and S. Ohlsson (2006). Toward a compu-
tational model of expert tutoring: A ﬁrst report. In FLAIRS06, the 19th International Florida AI
ResearchSymposium ,MelbourneBeach,FL.
DiEugenio,B.,D.Fossati,S.Haller,D.Yu,andM.Glass(2008).Bebrief,andtheyshalllearn:Generating
concise language feedback for a computer tutor. International Journal of AI in Education 18 (4),
317–345.
Druzdzel, M. J. and M. Henrion (1993). Eﬃcient reasoning in qualitative probabilistic networks. In
Proceedingsofthe11thNationalConferenceonArtiﬁcialIntelligence(AAAI–93) ,Washington,DC,
pp.548–553.
Elzer, S., N. Green, S. Carberry, and J. Hoﬀman (2006). A model of perceptual task eﬀort for bar
charts and its role in recognizing intention. User Modeling and User-Adapted Interaction 16 (1),
1–30.
Elzer, S., E. Schwartz, S. Carberry, D. Chester, S. Demir, and P. Wu (2007). A browser extension for
providing visually impaired users access to the content of bar charts on the web. In Proceedings of
Third International Conference on Web Information Systems and Technology (WebIST) Barcelona,
Spain.
Evens, M. W. and J. A. Michael (2006). One-on-One Tutoring by Humans and Machines.M a h w a h ,N J :
LawrenceErlbaumAssociates.
Evens, M. W., J. Spitkovsky, P. Boyle, J. A. Michael, and A. A. Rovick (1993). Synthesizing tutorial
dialogues. In Proceedings of the 15th Annual Conference of the Cognitive Science Society, Hillsdale,
NJ,pp.137–140.LawrenceErlbaumAssociates.
Fasciano,M.andG.Lapalme(2000).Intentionsinthecoordinatedgenerationofgraphicsandtextfrom
tabulardata. KnowledgeandInformationSystem2 (3),310–339.
Feiner, S. K. and K. R. McKeown (1991). Automating the generation of coordinated multimedia
explanations. Computer 24(10),33–41.
Fiedler, A. and D. Tsovaltzi (2005). Domain-knowledge manipulation for dialogue-adaptive hinting. In
Proceedingsofthe12thInternationalConferenceonArtiﬁcialIntelligenceinEducation(AIED2005),Amsterdam,theNetherlands,pp.801–803.
Foltz,P.W.,D.Laham,andT.K.Landauer(1999).Theintelligentessayassessor:Applicationstoeduca-
tionaltechnology. InteractiveMultimediaElectronicJournalofComputer-EnhancedLearning 1 (2),
http://imej.wfu.edu/articles/
Fossati, D., B. Di Eugenio, C. Brown, and S. Ohlsson (2008). Learning Linked Lists: Experiments with
the iList System. In ITS 2008, the Ninth International Conference on Intelligent Tutoring Systems ,
Montreal,Canada.
Fox, B. A. (1993). The Human Tutorial Dialogue Project: Issues in the Design of Instructional Systems .
Hillsdale,NJ:LawrenceErlbaumAssociates.
Freedman,R.K.(1996).Interactionofdiscourseplanning,instructionalplanninganddialoguemanage-
ment in an interactivetutoring system. PhDthesis, Computer Science Department, NorthwesternUniversity,Evanston,IL.
Freedman, R.K.(2000, May). Plan-baseddialoguemanagementinaphysicstutor. In Proceedingsof the
SixthAppliedNaturalLanguageConference,Seattle,WA.
Graesser, A. C., N. K. Person, and J. P. Magliano (1995). Collaborative dialogue patterns in naturalistic
one-to-onetutoring. AppliedCognitivePsychology9,495–522.
Graesser,A.C.,N.K.Person,D.Harter,andTheTutoringResearchGroup(2001).Teachingtacticsand
dialoginAutoTutor. InternationalJournalofArtiﬁcialIntelligenceinEducation12 ,257–279.

EmergingApplicationsofNaturalLanguageGeneration 573
Graesser, A. C., S. Lu, G. Jackson, H. Mitchell, M. Ventura, A. Olney, and M. Louwerse (2004).
AutoTutor: A tutor with dialogue in natural language. Behavioral Research Methods, Instruments,
andComputers36,180–193.
Graesser,A.C.,N.Person,Z.Lu,M.Jeon,andB.McDaniel(2005).Learningwhileholdingaconversation
withacomputer. InBrianL.PytlikZillig, M.Bodvarsson, andR.Brunin(Eds.), Technology-Based
Education: Bringing Researchers and Practitioners Together . Greenwich, CN: Information Age
Publishing.
Grasso,F.,A.Cawsey,andR.Jones(2000).Dialecticalargumentationtosolveconﬂictsinadvicegiving:
A case study in the promotion of healthy nutrition. International Journal of Human - Computer
Studies53(6),1077–1115.
Green, N. (2005). A Bayesian network coding scheme for annotating biomedical information presented
togeneticcounselingclients. JournalofBiomedicalInformatics38(2),130–144.
Green, N. L., G. Carenini, S. Kerpedjiev, J. Mattis, J. D. Moore, and S. F. Roth (2004). AutoBrief: An
experimental system for the automatic generation of brieﬁngs in integrated text and informationgraphics. InternationalJournalofHuman-ComputerStudies61 (1),32–70.
Green,N.,R.Dwight,K.Navoraphan,andB.Stadler(2009).Naturallanguagegenerationofbiomedical
argumentsforlayaudiences.Inpreparation.
Hallett, C. (2008). Multi-modal presentation of medical histories. In IUI ’08: Proceedings of the 13th
InternationalConferenceonIntelligentUserInterfaces ,NewYork,pp.80–89.ACM.
Hallett, C. and D. Scott (2005). Structural variation in generated health reports. In Proceedings of the
ThirdInternationalWorkshoponParaphrasing(IWP2005),JejuIsland,Korea.
Heﬀernan, N. T. and K. R. Koedinger (2002). An intelligent tutoring system incorporating a model of
an experienced human tutor. In ITS02, International Conference on Intelligent Tutoring Systems ,
Biarritz,France.
Hüske-Kraus, D. (2003). Text generation in clinical medicine—A review. Methods of Information in
Medicine42(1),51–60.
Jordan,P.W.,C.P.Rosé,andK.VanLehn(2001,May).Toolsforauthoringtutorialdialogueknowledge.
In J. D. Moore, C. L. Redﬁeld, and W. L. Johnson (Eds.), Proceedings of the 10th International
ConferenceonArtiﬁcialIntelligenceinEducation(AIED2001) ,SanAntonio,TX,pp.222–233.IOS
Press.
Jordan,P.W.,M.Makatchev,U.Pappuswamy,K.VanLehn,andP.Albacete(2006).Anaturallanguage
tutorial dialogue system for physics. In FLAIRS06, the 19th International Florida AI Research
Symposium,MelbourneBeach,FL.
Jordan,P.W.,B.Hall,M.Ringenberg,Y.Cui,andC.P.Rosé(2007).Toolsforauthoringadialogueagent
that participates in learning studies. In Proceedings of the Thirteenth International Conference on
ArtiﬁcialIntelligenceinEducation(AIED2007) ,LosAngeles,CA,pp.43–50.
Kersey, C., B. Di Eugenio, P. W. Jordan, and S. Katz (2009, July). Knowledge co-construction and
initiativeinpeerlearninginteractions.In AIED2009,the14thInternationalConferenceonArtiﬁcial
IntelligenceinEducation,Brighton,U.K.
Kumar,R.,C.P.Rosé,V.Aleven,A.Iglesias,andA.Robinson(2006,June).Evaluatingtheeﬀectiveness
of tutorial dialogue instruction in an exploratory learning context. In Proceedings of the Seventh
InternationalConferenceonIntelligentTutoringSystems ,Jhongli,Taiwan.
Landauer, T. K. and S. Dumais (1997). A solution to Plato’s problem: The latent semantic analy-
sis theory of acquisition, induction, and representation of knowledge. Psychological Review 104 ,
211–240.
Law,A.S.,Y.Freer,J.Hunter,R.H.Logie,N.McIntosh,andJ.Quinn(2005).Acomparisonofgraphical
and textual presentations of time series data to support medical decision making in the neonatalintensivecareunit. JournalofClinicalMonitoringandComputing 19 (3),183–194.

574 HandbookofNaturalLanguageProcessing
Lester, J. C., J. L. Voerman, S. G. Towns, and C. B. Callaway (1999). Deictic believability: Coordinated
gesture,locomotion,andspeechinlifelikepedagogicalagents. AppliedArtiﬁcialIntelligence13 (4–5),
383–414.
Litman,D.andK.Forbes-Riley(2006).Correlationsbetweendialogueactsandlearninginspokentutoring
dialogues. NaturalLanguageEngineering 12(2),161–176.
Litman, D. J., C. P. Rosé, K. Forbes-Riley, K. VanLehn, D. Bhembe, and S. Silliman (2006). Spoken
versustypedhumanandcomputerdialoguetutoring. InternationalJournalofArtiﬁcialIntelligence
inEducation16,145–170.
Lu, X., B. Di Eugenio, T. Kershaw, S. Ohlsson, and A. Corrigan-Halpern (2007). Expert vs. non-
expert tutoring: Dialogue moves, interaction patterns and multi-utterance turns. In CICLING07,
ProceedingsoftheEighthInternationalConferenceonIntelligentTextProcessingandComputationalLinguistics ,MexicoCity,Mexico,pp.456–467.BestStudentPaperAward.
Lu, X., B. Di Eugenio, S. Ohlsson, and D. Fossati (2008). Simple but eﬀective feedback generation to
tutorabstractproblemsolving.In INLG08,ProceedingsoftheFifthInternationalNaturalLanguage
GenerationConference,SaltFork,OH,pp.104–112.
Mazzotta, I., F. de Rosis, and V. Caroﬁglio (2007). Portia: A user-adapted persuasion system in the
healthy-eatingdomain. IEEEIntelligentSystems22 (6),42–51.
Mittal,V.O.,G.Carenini,J.D.Moore,andS.Roth(1998).Describingcomplexchartsinnaturallanguage:
Acaptiongenerationsystem. ComputationalLinguistics24(3),431–467.
Moore,J.D.,B.Lemaire,andJ.A.Rosenbloom(1996).Discoursegenerationforinstructionalapplications:
Identifyingandexploitingrelevantpriorexplanations. JournaloftheLearningSciences5 (1),49–94.
Moore,J.D.,K.Porayska-Pomsta,S.Varges,andC.Zinn(2004).Generatingtutorialfeedbackwithaﬀect.
InFLAIRS04, Proceedings of the 17th International Florida Artiﬁcial Intelligence Research Society
Conference,MiamiBeach,FL.
Moreno, R. (2006). Does the modality principle hold for diﬀerent media? A test of the method-aﬀects-
learninghypothesis. JournalofComputerAssistedLearning 22(3),149–158.
Moser, M. and J. D. Moore (1995). Investigating cue selection and placement in tutorial discourse. In
ACL95,Proceedingsofthe33rdMeetingoftheAssociationforComputationalLinguistics ,Cambridge,
MA,pp.130–135.
Moser, M. and J. D. Moore (1996). Towards a synthesis of two accounts of discourse structure.
ComputationalLinguistics22(3),409–419.
Nicholson, A.andJ.Brady(1994). Dynamicbeliefnetworksfordiscretemonitoring. IEEETransactions
onSystems,ManandCybernetics24(11),1593–1610.
Ohlsson, S., B. Di Eugenio, B. Chow, D. Fossati, X. Lu, and T. Kershaw (2007). Beyond the code-and-
count analysisof tutoring dialogues. In AIED 2007, the 13th International Conference on Artiﬁcial
IntelligenceinEducation,MarinadelRey,CA.
Oviatt,S.L.(1999,November).Tenmythsofmultimodalinteraction. CommunicationsoftheACM42 (11),
74–81.
Perelman, C. and L. Olbrechts-Tyteca (1969). The New Rhetoric: A Treatise on Argumentation . Notre
Dame,IN:UniversityofNotreDamePress.
Person, N. K., A. C. Graesser, J. P. Magliano, and R. J. Kreuz (1994). Inferring what the student
knowsinone-to-onetutoring:Theroleofstudentquestionsandanswers. LearningandIndividual
Diﬀerences6 (2),205–229.
Pilkington,R.M.(1999).Analyzingeducationaldialogue:TheDISCOUNTscheme(version3).Technical
Report99/2,ComputerBasedLearningUnit,TheUniversityofLeeds,Leeds,U.K.
Pon-Barry, H., K. Schultz, E. O. Bratt, and S. Peters (2006). Responding to student uncertainty in
spoken tutorial dialogue systems. International Journal of Artiﬁcial Intelligence in Education 16 ,
171–194.
Portet,F.,E.Reiter,J.Hunter,S.Sripada,Y.Freer,andC.Sykes(2008).Automaticgenerationoftextual
summariesfromneonatalintensivecaredata. ArtiﬁcialIntelligence173 ,789–816.

EmergingApplicationsofNaturalLanguageGeneration 575
Prochaska, J. and D. D. Clemente (1992). Stages of change in the modiﬁcation of problem behaviors.
ProgressinBehaviorModiﬁcation28 ,183–218.
Reiter,E.andR.Dale(2000). BuildingNaturalLanguageGenerationSystems .StudiesinNaturalLanguage
Processing .Cambridge,U.K.:CambridgeUniversityPress.
Reiter,E.,R.Robertson,andL.Osman(1999).Typesofknowledgerequiredtopersonalisesmokingces-
sationletters.In AIMDM’99:ProceedingsoftheJointEuropeanConferenceonArtiﬁcialIntelligence
inMedicineandMedicalDecisionMaking ,London,U.K.,pp.389–399.Springer-Verlag.
Reiter, E., R. Robertson, and L. Osman (2003). Lessons from a failure: Generating tailored smoking
cessationletters. ArtiﬁcialIntelligence144 (1–2),41–58.
Rickel,J.andW.L.Johnson(1999).Virtualhumansforteamtraininginvirtualreality.In Proceedingsof
theNinthInternationalConferenceonAIinEducation ,LeMans,France,pp.578–585.IOSPress.
Shneiderman, B. and C. Plaisant (2004). Designing the User Interface: Strategies for Eﬀective Human-
ComputerInteraction (4thed.).Reading,MA:AddisonWesley.
Soller, A. (2001). Supporting social interaction in an intelligent collaborative learning system.
InternationalJournalofArtiﬁcialIntelligenceinEducation12 ,40–42.
Toulmin,S.(1998). TheUsesofArgument (9thed.).Cambridge,U.K.:CambridgeUniversityPress.
van Eemeren, F. H., R. Grootendorst, and F. S. Henkemans (1996). Fundamentals of Argumentation
Theory: A Handbook of Historical Backgrounds and Contemporary Developments .M a h w a h ,N J :
LawrenceErlbaumAssociates.
VanLehn, K., R. Freedman, P. W. Jordan, C. Murray, C. Oran, M. Ringenberg, C. P. Rosé, K. Schultze,
R. Shelby, D. Treacy, A. Weinstein, and M. Wintersgill (2000). Fading and deepening: The nextstepsforANDESandothermodel-tracingtutors.In ProceedingsoftheIntelligentTutoringSystems
Conference,Montreal,Canada.
VanLehn, K., A. C. Graesser, G. T. Jackson, P. W. Jordan, A. Olney, and C. P. Rosé (2007). When are
tutorialdialoguesmoreeﬀectivethanreading? CognitiveScience31(1),3–62.
Walton,D.(1996). ArgumentationSchemesforPresumptiveReasoning.Mahwah,NJ:LawrenceErlbaum
Associates.
Young,R.M.,M.E.Pollack,andJ.D.Moore(1994).Decompositionandcausalityinpartialorderplan-
ning.InSecondInternationalConferenceonArtiﬁcialIntelligenceandPlanningSystems ,University
of Chicago, Chicago, IL. Also Technical Report 94-1, Intelligent Systems Program, University ofPittsburgh,Pittsburgh,PA.
Yu, J., E. Reiter, J. Hunter, and C. Mellish (2007). Choosing the content of textual summaries of large
time-seriesdatasets. NaturalLanguageEngineering 13 (1),25–49.
Zinn, C., J. D. Moore, and M. G. Core (2002). A 3-tier planning architecture for managing tutorial
dialogue. In ITS 2002, Sixth International Conference on Intelligent Tutoring Systems , Biarritz,
France,pp.574–584.
Zinn,C.,J.D.Moore,andM.G.Core(2005).Intelligentinformationpresentationfortutoringsystems.
InM.ZancanaroandO.Stock(Eds.), MultimodalIntelligentInformationPresentation .pp.227–254.
Dordrecht,theNetherlands:KluwerAcademicPublishers.



