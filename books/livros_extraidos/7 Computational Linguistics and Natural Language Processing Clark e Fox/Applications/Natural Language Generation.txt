“9781405155816_4_020” — 2010/5/8 — 12:15 — page 574 — #1
20 Natural Language
Generation
EHUD REITER
Natural language generation (NLG) systems generate texts in English and otherhuman languages. Although they are based on many of the same linguistic andalgorithmic insights that underlie other kinds of natural language processingsystems, they are not simply natural language understanding systems run ‘inreverse.’
In this chapter, I will brieﬂy review NLG. In Sections 1–4, I summarize the basic
concepts of NLG, and try to highlight issues which are important to building NLGsystems and also potentially interesting to linguists and psycholinguists. Then, inSection 5, I discuss some contemporary research in NLG, in areas which are of per-sonal interest to me and which I believe should be of interest to other researchersin the language community. The research topics discussed are by no meansexhaustive – they are just a sample of what the NLG research community isworking on. I conclude (Section 6) with a brief summary of resources (software,corpora, information) for researchers who wish to work in NLG.
1 High-Level Perspective: Making Choices
about Language
From a high-level perspective, perhaps the biggest difference between NLG andother types of NLP is the central role of choice making. NLG systems have to makenumerous choices about their output texts, ranging from high-level choices aboutappropriate content to low-level choices about the use of pronouns. Althoughchoice making of course also occurs in other NLP tasks (for example machinetranslation systems have to decide which target-language word to use when trans-lating a source-language word), choice making is arguably more central to NLGthan to most other areas of NLP .
Sometimes NLG choices can be made on the basis of linguistic correctness, as in
the following example of a pronominalization choice:

“9781405155816_4_020” — 2010/5/8 — 12:15 — page 575 — #2
Natural Language Generation 575
(1) a) * ‘Mary read about Mary.’
b)‘Mary read about herself.’
In this case the NLG system can use binding theory (Büring 2005) to determine thata reﬂexive pronoun must be used in this context, and hence decide to generate (1b).
However, in other cases, such as the example below, both choices lead to
linguistically correct texts:
(2) a) ‘I bought an apple. I ate it.’
b)‘I bought an apple. I ate the apple.’
Since both choices lead to valid texts, the NLG system must decide between themusing other criteria. Often such decisions are made based on readability factors,which in turn are based on psycholinguistic models of language comprehension;in the above example such models might suggest that (2a) will be read faster, andhence should be generated. Decisions may also be inﬂuenced by genre constraints;for example, pronoun usage may be discouraged in safety-critical texts such asoperation manuals for nuclear power plants, so in such genres (2b) should begenerated. Genre models are typically based on corpus analysis or explicit genrewriting guides. In some cases decisions are also inﬂuenced by the linguistic abil-ities and preferences of the reader of the text; for example an NLG system maychoose (2b) if its reader is not ﬂuent in English.
NLG is thus largely the study of choice making, including analyses of individ-
ual choices; architectures and systems that can be used to make sets of choices; andmethodologies for creating and evaluating new choice making rules and systems.Analyses of individual choices are often based on linguistic and/or psycholinguis-tic research; analyses of choice making architectures and systems often build onartiﬁcial intelligence techniques; and methodologies for creating and evaluatingrules draw on both AI and (psycho)linguistics.
2 Two NLG Systems: SumTime and SkillSum
In order to illustrate choice making and other aspects of NLG, it is useful to exam-ine some real NLG systems. In this section we look at SumTime, which generatesweather forecasts, and SkillSum, which generates feedback reports on educationalassessments.
2.1 SumTime: Weather Forecasts
One popular application of NLG is generating textual weather forecasts fromnumerical weather prediction data. NLG systems such as FOG (Goldberg et al.,1994), MultiMeteo (Coch 1998), SumTime (Reiter et al., 2005), and RoadSafe(Turner et al., 2008) take as their input a large set of numbers which predict tem-perature, precipitation, wind speed, and so forth at various points and times.

“9781405155816_4_020” — 2010/5/8 — 12:15 — page 576 — #3
576 Ehud Reiter
Table 20.1 Numerical wind forecast
for September 19, 2000
Time Wind Dir. Wind Speed
06:00 SE 11
09:00 SSE 13
12:00 SSE 14
15:00 SSE 15
18:00 SE 18
21:00 SE 23
00:00 SE 28
Corpus (human) text:
SSE 10–15 INCREASING 15–20 BY EVENING AND 25–30
LATER.
SumTime text:
SE 9–14 veering SSE 13–18 by mid-afternoon, then increasing
SE 26–31 by midnight.
Figure 20.1 Human and corpus wind descriptions for September 19, 2000.
These numbers are produced by a supercomputer running a numerical weathersimulation, and modiﬁed by human forecasters based on their knowledge of localmeteorological conditions. From this input data, the systems produce weatherforecast texts (sometimes in multiple languages) which are sent to forecast users(usually after being checked and post-edited by the human forecasters) (Sripadaet al., 2004). Table 20.1 shows a simple extract from one of SumTime’s data sets,showing 24 hours of predicted wind speed and direction for an offshore oil rig inthe North Sea. Figure 20.1 shows the text produced by SumTime from this data,and also the corpus text for this data (that is, a text written by a human forecaster,which was actually sent to users on the oil rig).
In order to generate the output text shown in Figure 20.1 from the input data
shown in Table 20.1, SumTime needs to make many kinds of choices.•Choices about document content and structure : SumTime must decide what
information to communicate in the text, and also how the document is struc-tured around this information. This is called document planning. In this exam-
ple, SumTime has decided to communicate information about the wind at thebeginning and end of the period, and also at one point in the middle, 15:00(‘by mid-afternoon’). The human forecaster has similarly chosen to describe thewind at the beginning and end, and at one intermediate point but has chosena different intermediate point – 18:00 instead of 15:00.

“9781405155816_4_020” — 2010/5/8 — 12:15 — page 577 — #4
Natural Language Generation 577
One of these sentences has a word which is wrong.
Click on it.•He was walking to the canteen when he slipped on a wet ﬂoor.
•I was walking to the canteen when I slipped on a wet ﬂoor.
•They was walking to the canteen when they slipped on a wet ﬂoor.
Figure 20.2 An example literacy screener question (SkillSum input).
Thank you for doing this.
You got 19 questions right. Click here for more information .
Your skills seem to be OK for your Health and Social Care course.You got all except 3 of the reading questions right. But you made 5
mistakes on the questions about writing.
Perhaps you would like to take a course to help you with your English.A course might help you to practise your reading skills, because you
said you do not read much.
Click here for Key Skills at XXX College
.
Figure 20.3 Example text produced by SkillSum.
•Choices about linguistic structures: SumTime must decide which linguis-tic structures (words, syntax, sentences) should be used to communicate thedesired information. This is called microplanning . An example of word choice
is communicating the time 00:00; in the above example the human forecasterhas referred to this time using the phrase ‘later,’ while SumTime has used the
phrase ‘by midnight.’
•Choices about word order and forms : SumTime must decide which forms of
words to use, and which order words will appear in, based on the above deci-sions. This is called realization. An example of word-form choice is that both
the human forecaster and SumTime use the present participle (‘+ing’ )f o r mo f
verbs; this is based on the genre conventions of this type of weather forecast.
2.2 Example NLG system: SkillSum
SumTime generates short summaries of numerical data for specialist users (work-ers in the offshore oil industry). Our second example system, SkillSum (Williams& Reiter 2008), generates summaries of performance on an educational assessment(of basic numeracy and literacy skills). Its users are students at further education(community) colleges who are enrolled in a course which requires certain levels ofbasic skills. The input to SkillSum is some background information about the user,plus his or her responses to a set of multiple-choice questions which test basic lit-eracy or numeracy; an example is shown in Figure 20.2. The output of SkillSum isa short text summarizing the user’s performance on the test; an example is shownin Figure 20.3.

“9781405155816_4_020” — 2010/5/8 — 12:15 — page 578 — #5
578 Ehud Reiter
Although SkillSum’s input data and output text are very different from
SumTime’s, it must make the same kind of choices. SkillSum’s document plannermust decide what information to give; for example, how much detail to go intoabout the user’s mistakes. SkillSum’s microplanner must decide how to linguisti-cally express this information; for example, whether to say ‘You got 19 questions
right’ or‘You got 19 questions correct.’ SkillSum’s realizer must make low-level
word-form and ordering choices, such as using ‘questions’ instead of ‘question’ in
the above sentence.
2.3 Other NLG applications
Many other applications of NLG have been explored, including:•Summarizing other kinds of data, including medical data (Portet et al., 2007),engineering data (Yu et al., 2007), ﬁnancial data (Kukich 1983), and sports data(Robin & McKeown 1996). The input to these systems, like SumTime, is usuallya combination of numeric data and event records (Reiter 2007).
•Generating initial drafts of documents, such as instruction manuals (Paris et al.,1995), legal documents (Sheremetyeva et al., 1996), clinical documents (Hüske-Kraus 2003), and business letters (Coch 1996). The input to these systems isusually a knowledge base which describes the content of the document; some-times the NLG system is integrated with the knowledge-base authoring tool(Power et al., 1998).
•Generating explanations of reasoning in AI systems, including expert systems(Lacave & Diez 2004), Bayesian reasoners (Lacave & Diez 2002), and theoremprovers (Fiedler 2005). The input to these systems is usually a trace of thereasoning used by the AI reasoning system.
•Generating texts that are intended to persuade or motivate users (Reiter et al.,2003a), make users less anxious (Cawsey et al., 2000), or entertain users(Binstead & Ritchie 1997). The input to these systems is quite varied, butusually includes a user model of the reader.
•Supporting users with disabilities; for example letting blind users examinegraphs (Ferres et al., 2006), and helping non-speaking users create stories aboutwhat they have done (Reiter et al., 2009).
Despite these efforts, NLG has not been widely used in real-world applications.
A number of NLG systems have been used in a limited way; for example Sum-Time was used for a few years by the Aberdeen ofﬁce of a weather forecastingcompany to generate draft forecasts which human forecasters post-edited (Sripadaet al., 2004), and indeed an evaluation showed that forecast users preferred someof SumTime’s (unedited) forecasts to forecasts written by human meteorologists(Reiter et al., 2005). However, to the best of my knowledge, no NLG system hasentered long-term widespread use, in the sense of being used by many organiza-tions for many years. In this regard NLG has been less successful than other areasof NLP such as speech recognition, dialogue systems, machine translation, and

“9781405155816_4_020” — 2010/5/8 — 12:15 — page 579 — #6
Natural Language Generation 579
(no message)Structure : paragraph
Temporal sequence
Wind changeSpeed : 15
Direction : SSE
Time : 15:00Wind initialSpeed : 11
Direction : SE
Time : 06:00Wind changeSpeed : 28
Direction : SE
Time : 00:00
Figure 20.4 Example SumTime document plan.
grammar checking; and also less successful than simple text-generation systemsbased on ﬁll-in-the-blank templates or mail-merge. My personal belief is that oneof the keys to making NLG technology more practically useful on real applicationsis a better understanding of the research issues which I discuss at the end of thischapter; for example SumTime would probably have been used much more if ithad been embedded into an interactive multi-modal meteorological informationsystem (Section 5.3).
3 NLG Choices and Tasks
NLG is often divided into the three stages of document planning, microplanning,and realization. In this section we discuss each of these stages, and brieﬂy sum-marize the types of choices each stage must make. For more information about thestages, including algorithms and representations, see Reiter and Dale (2000).
3.1 Document planner
The document planner decides what information to communicate in the text(content determination ), and how this information should be organized (document
structuring).
From a software perspective, the input to the document planner is the input
to the entire NLG system; for example numerical weather prediction data inSumTime, and responses to the test questions in SkillSum. The output of the doc-ument planner is typically a tree of messages. Messages are chunks of information
(extracted from the input data), which can be linguistically expressed as a clauseor phrase; they are sometimes represented as instances in an AI knowledge-basesystem such as Protégé.
1The edges of the tree are often used to represent rhetorical
relations between messages. Nodes of the tree can also be annotated to representdocument structures (Power et al., 2003) such as paragraphs.
An example of a simple SumTime document plan is shown in Figure 20.4; this is
for the SumTime text shown in Figure 20.1. The tree consists of a root node which

“9781405155816_4_020” — 2010/5/8 — 12:15 — page 580 — #7
580 Ehud Reiter
does not contain a message, but does establish that this text is a ‘paragraph’ doc-ument structure. This node has three children, which are in a temporal sequencerelation. Each child communicates a single message about the wind. The ﬁrst childis awind initial message, which communicates the initial state of the wind; the
remaining children are wind change messages, which communicate a change in
the wind. Each of these messages has the parameters speed ,direction,a n d time.
Although SumTime does not use Protégé, these messages could easily be repre-sented in a Protégé ontology (and we would use this representation if we werereimplementing SumTime today).
As this example suggests, the heart of document planning in SumTime is select-
ing a small number of wind changes to mention, from the input data (Table 20.1).In this case SumTime has chosen to mention the wind changes at 15:00 and 00:00,it assumes the user can interpolate between these points if necessary. This pro-cess is guided by a limit to interpolation error, which is based on expert advicefrom meteorologists as to how much interpolation error is acceptable to end users,considering the tasks that they typically perform using the weather forecasts. Doc-ument structure is very simple in SumTime: the messages are always linked by atemporal sequence relation as in the example of Figure 20.4.
As can be seen in this example, document planning typically involves reasoning
about the data and how it will be used. Explicit linguistic reasoning may play arole in deciding on document structure (how messages are organized into a tree),but often has a fairly minor role in deciding on document content (which messagesare in the tree).
The reasoning performed by document planning can be more complex than
SumTime’s use of maximum allowable interpolation error. For example, the STOPsystem (Reiter et al., 2003a), which generated smoking-cessation letters basedon the responses to a smoking questionnaire, largely based its document plan-ning on a psychological model of what information should be given to smokers,based on their attitudes towards and beliefs about smoking cessation (Prochaska& diClemente 1992).
Unfortunately, it is difﬁcult to generalize about document planning; for exam-
ple, the algorithms used by SumTime to decide what information is most appro-priate for a weather forecast reader on an offshore oil rig are completely differentfrom the algorithms used by STOP to decide what smoking-cessation informa-tion would be most effective for a particular user. In very general terms, the goalof document planning is to identify the information that is useful to the user, andstructure it into a coherent document, and it has proven difﬁcult to create a generalmodel of how this should be done.
In the early 1990s Hovy (1993) and other researchers tried to formalize docu-
ment planning as an AI planning problem based on formal models of rhetoricalrelations, such as rhetorical structure theory (RST) (Mann & Thompson 1988).However, this approach did not work well in practice. One major problem wasthat RST-like models of the semantics of relations are too vague to be used indocument planners, and also (because they attempt to be general) do not cap-ture important genre-speciﬁc aspects of document structure. For example, weather

“9781405155816_4_020” — 2010/5/8 — 12:15 — page 581 — #8
Natural Language Generation 581
forecasts for offshore oil rigs describe each aspect of the weather (wind, temper-ature, precipitation, etc.) separately, and describe events about the same aspect(e.g., wind) in strict temporal order. This structure cannot be derived from theo-ries of optimal rhetorical presentation; it is a convention which has arisen in thisgenre and (for better or for worse) must be adhered to.
An alternative approach to document planning is to try to imitate what human
writers do, without explicitly modeling or reasoning about what content would bebest for the user. This is typically done by analyzing corpora of human-authoredtexts and/or explicitly conducting knowledge acquisition sessions with humanwriters (Reiter et al., 2003b); this approach was used in developing the Skill-Sum document planner (Williams & Reiter 2005), for example. Recently there hasbeen interest in trying to automate this process using machine learning techniques(Barzilay & Lapata 2005a).
Perhaps the biggest problem with this approach is data sparsity and incomplete-
ness. This kind of analysis usually requires a data-text corpus, which contains theinput data (e.g., the data shown in Table 20.1) as well as the human-written texts(e.g., the texts shown in Figure 20.1). Unfortunately, most existing data-text cor-pora are either too small to provide good coverage of the different cases, and/or donot include all of the data used by the human writers. For example, the SkillSumcorpus contained just 16 texts, and Barzilay and Lapata only had correspondinginput data for one third of the sentences in their corpus.
Because of these problems, document planners cannot (at the time of writing)
be based purely on corpus analysis. Human developers must extrapolate rules tocover gaps in the corpus, based on their domain knowledge and feedback fromdomain experts and pilot experiments (Williams & Reiter 2005). There is undoubt-edly considerable scope for improving the process of creating document plannersin this fashion, by improving corpus-analysis and gap-ﬁlling methodologies.
3.2 Microplanning
The microplanner decides how information is linguistically expressed in thegenerated text. This process requires many choices to be made, including thefollowing:•lexical choice: choosing which content words should be used to expressdomain concepts and data;
•reference: choosing referring expressions to identify domain entities;
•syntactic choice : choosing syntactic structures in generated sentences;
•aggregation: choosing how many messages should be expressed in eachsentence.
The input to the microplanner is the document plan, which is created by the
document planner. The output of the microplanner is a text speciﬁcation ; essen-
tially this is a tree whose internal nodes specify document structure (for example,paragraphs), and whose leaf nodes specify deep syntactic structures of sentences.

“9781405155816_4_020” — 2010/5/8 — 12:15 — page 582 — #9
582 Ehud Reiter
Coordinated sentencecoordinator: < none >
first
subject
WindNPDirection: SESpeed: 9–14Time: < elided >WindNPDirection: SSESpeed: 13–18Time: by mid-afternoonWindNPDirection: SESpeed: 26–31Time: by midnightobject
subject
elidedobject
SentenceVerb: veerForm: gerundSentenceVerb: increaseForm: gerundCue Phrase: thensecond
Figure 20.5 Example SumTime deep syntactic structure.
The latter specify content words, coreference, syntactic relationships, and sentenceboundaries. The exact form of the deep syntactic structure varies considerablydepending on the system’s realizer and the grammatical theory (if any) that therealizer is based on.
An example of a deep syntactic structure is shown in Figure 20.5; this is for the
document plan shown in Figure 20.4. We do not show the text speciﬁcation forthis example, it would simply contain a root node indicating document structure(very similar to the root node of the document plan shown in Figure 20.4), and aleaf node containing the abstract syntactic structure shown in Figure 20.5.
The deep syntactic structure shown in Figure 20.5 is based on intuitive ideas
such as subject and noun phrase, but is customized for the speciﬁc genre usedin weather forecasts. Thus for example the SumTime realizer accepts a ‘syntactic’structure called WindNP which communicates wind speed, direction, and time;this seemed more sensible than trying to force the realizer to use standard nounphrase structures which do not really ﬁt the sublanguage (genre) used in weatherforecasts.
In any case, Figure 20.5 illustrates many of the choices that the SumTime
microplanner must make. An example of lexical choice is choosing the verb ‘veer’
to communicate the change between the wind at 06:00 and the wind at 15:00;this involves deciding which aspect of the change to focus on (in this case thefocus is on the change in wind direction), and then choosing the verb based onwhat occurred in this aspect (in this case ‘veer’ as the wind direction changed
clockwise). Other lexical choice examples include choosing ‘by mid-afternoon’ to
communicate the time 15:00, and ‘13–18’ to communicate the speed 15. The lat-
ter choice could be regarded as a content (document planner) choice instead ofa lexical (microplanner) choice, the distinction between the two is not alwaysclear cut.

“9781405155816_4_020” — 2010/5/8 — 12:15 — page 583 — #10
Natural Language Generation 583
No referring decisions are needed to generate SumTime texts, including the
one shown in Figure 20.5. An example of a referential choice in the SkillSumtext shown in Figure 20.3 is ‘your Health and Social Care course.’ Other potential
ways of referring to this entity include ‘your course’ and ‘your Health and Social
Care course at Aberdeen College’; the referential choice is choosing which of thesereferring expressions to use in the generated text.
An example of a syntactic choice in the Figure 20.5 SumTime text is using
the gerund form of the verbs (for example, ‘veering’ instead of ‘veers’). Another
example is the decision to elide (omit) the time phrase from the ﬁrst WindNP .
An example of an aggregation choice is the decision to express the content in a
single sentence. An alternative would have been to use two sentences, for example‘SE 9–14 veering SSE 13–18 by mid-afternoon. Increasing SE 26–31 by midnight.’
Microplanning choices in SumTime, as in many NLG systems, are made with
different levels of sophistication. Some choices are forced by the sublanguage(Grishman & Kittredge 1986); for example SumTime always uses the gerund formsof verbs in wind descriptions, because this is how such texts are convention-ally written. Some choices require little computation but are based on substantiallinguistic analyses and/or psycholinguistic data. For example lexical choice inSumTime is done using ﬁxed concept-to-word mappings (a trivial computationalmechanism), but these mappings are based on an extensive linguistic analysis ofword usage in corpus texts and also feedback from users about their word choicepreferences. And some choices require non-trivial algorithms (whose design isinformed by (psycho)linguistic data); this is the case for aggregation and ellipsisdecisions in SumTime.
Perhaps the best studied microplanning choices are referential ones; see Reiter
and Dale (2000) for more details on these and other microplanning decisions. Inparticular a considerable amount of work has been done on the generation of def-inite noun phrases to identify visible or otherwise salient physical objects (suchas ‘the red book ’); indeed there has even been a shared task evaluation in this area
(Belz & Gatt 2007).
One interesting observation from the work on reference, which has since been
observed in other areas of NLG, is that the language produced by human speakersand writers is not necessarily ideal for human listeners and readers (Oberlander1998). This means that algorithms that generate high-quality referring expressionscannot just be based on corpus analysis and other studies of human languageproduction – they must also be based on studies (often psycholinguistic ones) ofhuman language comprehension.
This raises the more general question of what the goals of microplanning choices
are. Is the goal to produce texts that are similar to those produced by human writ-ers (under what metric?); texts that are appropriate for human readers (under whatcriteria?); or texts that satisfy some other criteria (for example, minimizing legalliability)? Of course, such questions could be asked about all aspects of NLG, butthey seem especially prominent in microplanning.
Lexical choice (choosing content words which communicate the information
in messages) is extremely important for producing high-quality texts, but is less

“9781405155816_4_020” — 2010/5/8 — 12:15 — page 584 — #11
584 Ehud Reiter
well understood than referential choices. In principle, it would be nice to baselexical choice algorithms on linguistic theories of lexical semantics (Cruse 1986),but in fact such theories have not proven very useful in NLG. This is becausethey focus on the relationship between semantic primitives (usually in ﬁrst-orderlogic) and words, but very few NLG systems have semantic primitives as theirinput. The NLG community needs a better understanding of how to map theinput data that NLG systems actually get (sensor readings, databases, etc.) on towords (Roy & Reiter 2005), and how this mapping is affected by contextual factors.Such contextual factors include alignment (Brennan & Clark 1996) and other dia-logue issues, individual differences between readers’ language (idiolect) (Reiter& Sripada 2002), and the desirability or otherwise of varying word choice. Theseissues are further discussed in Section 5.2. In some cases we also need to consideraffective issues (Section 5.4) such as the emotional impact on users of particularword choices; for example, SkillSum needs to use words which not only are under-standable and convey the correct meaning, but also are not perceived by the readeras patronizing or disheartening.
A similar situation applies to aggregation choices, that is deciding when and
how to combine multiple messages into one sentence. Again aggregation is veryimportant for achieving high-quality texts, but it is not well understood. Whilemany papers have been published on aggregation, there is still considerable uncer-tainty about when and how to aggregate messages in speciﬁc contexts. This ispartially because the amount and type of aggregation performed is very depen-dent on the domain and genre. There are also major differences in the amount ofaggregation preferred by different readers, and in the aggregation choices madeby different writers.
The ﬁnal microplanning task we discuss here is high-level syntactic choices,
such as whether a sentence should be active or passive, and which tense shouldbe used. In principle many such choices could be based on linguistic theories. Forexample, centering theory could be used to guide information structure choicessuch as passivization, and a Reichenbach model could be used to make choicesabout tenses. In practice such theories often need considerable further elaborationbefore they are precise enough to be useful in NLG systems (Poesio et al., 2004).
In summary, microplanning requires an NLG system to make decisions about
the best way to linguistically express information. With the partial exception ofreferring expressions, there is little in the way of general theories for guiding NLGmicroplanners today, instead systems tend to rely on empirical analysis of howlanguage is used in a particular domain and genre. If linguists can help developa better theoretical underpinning for microplanning tasks, this would be veryhelpful to the NLG community.
3.3 Realization
The realizer generates an actual text (surface form), based on the informationselected by the document planning module and the linguistic choices made by

“9781405155816_4_020” — 2010/5/8 — 12:15 — page 585 — #12
Natural Language Generation 585
the microplanner. For example, the SumTime realizer generates the text shown inFigure 20.1 from a syntactic structure such as the one shown in Figure 20.5.
Realization is perhaps the best understood aspect of NLG, and indeed many
software packages have been developed to carry out this task (which is not true ofdocument planning or microplanning). Most of these packages combine an enginebased on a particular grammatical formalism, and one or more grammars based onthis engine. These systems include KPML, which is based on systemic functionalgrammar (Bateman 1997); FUF/SURGE, which is based on functional uniﬁcationgrammar (Elhadad & Robin 1997); RealPro, which is based on meaning-text theory(Lavoie & Rambow 1997); and OpenCCG, which is based on categorial grammar(White et al., 2007). There are also some atheoretical packages which provide lesslinguistic functionality but allow linguistic constructs to be integrated with tem-plates, such as TG2 (Busemann & Horacek 1998) and Simplenlg (Reiter 2007); vanDeemter et al. (2005) discuss in general terms how templates of different levels ofsophistication can be used by an NLG system. Morphological generators have alsobeen created, such as Morphg (Minnen et al., 2001).
Some realizers support overgeneration and selection. In this mode, the realizer
generates several possible surface forms, and uses a separate mechanism to selectone of these. The most common selection mechanism is n-gram language models
which are derived from corpora (these are described in Chapter 3,
STATISTICAL
LANGUAGE MODELING ). OpenCCG, for example, supports this architecture. In
principle, an overgenerate-and-select architecture should allow the grammar writ-ing task to be simpliﬁed, because subtle constraints such as adjective ordering canbe implicit in the language model – they do not need to be explicitly programmed.Also this architecture should make it easier to adapt systems to different genres,because genre linguistic preferences can be implicit in the language model, and donot need to be explicitly coded.
On the other hand, from a practical engineering perspective, it is not clear how
to perform testing, quality assurance, and maintenance on systems which arebased on language models which are automatically built from corpus texts. Forexample, if we look at adjective ordering, explicitly encoding adjective orderingrules is a lot of work, but once this is done the rules can be tested and checked,and also modiﬁed if users want a different ordering. Implicitly deriving adjectiveordering rules from a language model is much less work, but it is harder to testsuch systems to ensure that they do not produce inappropriate texts in some cases,and more difﬁcult to modify such systems if users request a different ordering.
One pragmatic solution to this problem, which in fact is supported by systems
such as OpenCCG, is to combine a symbolic grammar which handles importantlinguistic decisions which must be correct and which users may wish changed,with a language model which takes care of less important decisions. If it subse-quently turns out that a decision made by the language model is more importantthan initially expected and/or is the subject of user change requests, the symbolicgrammar can be expanded to incorporate this decision.
As can be seen from the above discussion, the state of the art in realization is
sufﬁciently advanced (compared to other aspects of NLG) that we can seriously

“9781405155816_4_020” — 2010/5/8 — 12:15 — page 586 — #13
586 Ehud Reiter
consider software engineering issues such as quality assurance, maintenance, easeof software integration, and documentation quality. Indeed these factors oftenplay a larger role than theoretical factors (such as underlying linguistic theories)when system builders are deciding which realizer to use in their software.
3.4 Other comments
As many people have pointed out (for instance, Mellish et al., 2006), the boundariesbetween the above stages are not precise. For example, in the above architectureI have said that paragraph boundaries are decided upon in document planning,while sentence boundaries are decided upon in microplanning; but one couldalso argue that these decisions should be made together, not in different modules.Similarly I have said that the microplanner makes linguistic choices and the realizerimplements them; but of course the realizer probably needs to make some choices(especially low-level ones) as well. So the above architecture should be thoughtof as a starting point; real systems could and should modify it to suit their needs.
The above discussion should also make clear that there are considerable dif-
ferences in how well different NLG tasks are understood. Our understanding ofrealization is relatively good, and indeed a number of software packages are avail-able for this task. Our understanding of microplanning is patchy: reasonable insome places (for example, generating deﬁnite noun phrases to refer to objects),limited in some places (such as aggregation), and poor in others (such as affec-tive issues in lexical choice). Our understanding of document planning is perhapsweakest of all; current document planners are mostly based on empirical work ina domain with very limited contribution from theoretical models.
4 NLG Evaluation
An important issue in NLG, as in other aspects of NLP , is how to evaluate sys-tems. See Chapter 11,
EVALUATION OF NLP SYSTEMS , for a general introduction
to the evaluation of natural language processing systems, including terminology,underlying concepts, and common techniques.
In very general terms, one can evaluate how well individual choices are made
in NLG; how well NLG modules work; and/or how well complete NLG sys-tems work. Evaluations can also try to determine how effective generated textsare for human readers (reader-based evaluation), or how successfully generatedtexts match texts produced by human writers (writer-based evaluation). The typeof evaluation depends of course on its purpose. For example, if the purpose isto enable a user to decide whether to use an NLG system, then a reader-basedsystem evaluation is most appropriate. On the hand, if the purpose of the evalua-tion is to test the cognitive plausibility of a model of reference generation, then awriter-based module evaluation would be most appropriate.
Probably the most prominent kinds of evaluation in NLG are reader-based
system evaluations, so I will focus on these in the rest of this section. In very

“9781405155816_4_020” — 2010/5/8 — 12:15 — page 587 — #14
Natural Language Generation 587
general terms, there are three ways of trying to determine how effective an NLGsystem is at achieving its communicative goal. The most direct approach is anextrinsic evaluation which directly measures whether the system achieves its goal.
Such evaluations almost always involve human subjects, and generally tend tobe relatively expensive and time-consuming. A cheaper alternative is a non-task-
based human evaluation, where human subjects are asked to read generated texts,and rate, post-edit, or comment on them. A ﬁnal (and more controversial) alter-native is a metric-based corpus evaluation ; this involves using metrics such as B
LEU
and R OUGE (these are discussed in Chapter 11, EVALUATION OF NLP SYSTEMS )t o
measure how similar generated texts are to corpus texts (in other words, we per-form a writer-based evaluation in the hope that its results are good predictors ofreader-based evaluation).
4.1 Extrinsic evaluations
The most trusted system evaluations are extrinsic ones that directly measure thesystem’s effectiveness at achieving its communicative goal; this is especially trueof evaluations which are intended to convince people outside the NLP community,such as doctors, teachers, and mariners. For example, the STOP system was eval-uated in a clinical trial with 2,000 smokers (Reiter et al., 2003a). All of the smokersﬁlled out our smoking questionnaire. One third of them received STOP letters, onethird received a control non-tailored letter, and one third just received a thank youletter. We contacted them six months after the letters had been sent, and found outhow many in each group had managed to stop smoking.
SkillSum was also evaluated extrinsically (Williams & Reiter 2008). We recruited
230 people who were about to start a course at a UK further education college,and asked them to complete the SkillSum literacy and numeracy assessment. Thestudents were again divided into three groups of roughly equal size; two of thegroups received variants of SkillSum texts, while the third received a controltext (essentially the text produced by the existing software). We asked studentsto judge whether their skills were sufﬁcient for the course they were signed upfor, both before and after they took the assessment and read the texts, and com-puted how many students in each of the groups increased the accuracy of theirself-assessment of their skills.
Both of these evaluations were expensive and time-consuming. The STOP eval-
uation took 20 months (including planning and data analysis) and cost UK£75,000.The SkillSum evaluation was not separately costed, but required roughly 8 monthsto carry out (including planning and data analysis) and cost on the order ofUK£25,000.
4.2 Non-task-based human evaluations
Extrinsic evaluations may be appropriate as ﬁnal evaluations of systems with siz-able development budgets and timescales, but they may not be realistic for smallerprojects and indeed for pilot studies (intended to detect problems and improve

“9781405155816_4_020” — 2010/5/8 — 12:15 — page 588 — #15
588 Ehud Reiter
systems) in large projects. In such contexts we need evaluation techniques whichare quicker and cheaper.
In NLG, such evaluations are usually done using experiments with human
subjects, most commonly asking subjects to rate texts on ordinal scales (oftenLikert scales) or to compare texts; subjects are also usually asked to comment onproblems in texts and how to improve them.
For example, the SumTime system was evaluated (Reiter et al., 2005) by gen-
erating three alternative texts from data sources: one produced by S
UMTIME,
one written by humans (professional meteorologists), and one produced by amodiﬁed version of SumTime which essentially extracted document plans fromthe human texts but microplanned and realized these using SumTime. Subjectswere shown the texts (without knowing their origin), and asked comprehensionquestions about the texts; they were also shown different variants of the textsand asked which variant they thought was most accurate, which was easiest toread, and which was overall the best. In another exercise, several systems withSumTime-like functionality were evaluated by having the systems generate alter-native forecasts from the same data set, and then asking human subjects to ratethe generated texts (Reiter & Belz 2009).
There are a number of other activities we can ask subjects to perform, in addition
to rating texts. One is to ask them to edit generated texts and see what changes theymake; such an exercise was in fact carried out with SumTime texts (Sripada et al.,2005). Post-editing seems less useful for quantitative comparisons, because thereare very large differences in the amount of post-editing which different peopleperform, and hence a lot of noise in the quantitative data. But it is very useful forqualitative analyses of problems and potential improvements, because the post-edit data tells developers what speciﬁc parts of the texts subjects did not like, andhow they thought the texts should be improved.
We can also time subjects and see how long it takes them to read texts; this was
done in SkillSum, for example, since one of the goals of the project was to gen-erate texts which low-skilled readers could easily read. Simply asking people tosilently read a text and press a button when ﬁnished is problematic, because somesubjects may read in depth while others just skim. It is better to ask subjects to reada text for a concrete purpose, such as answering comprehension questions; anotherpossibility (for low-skill readers in particular) is to ask subjects to read textsaloud. Experiments of both of these types were done in SkillSum (Williams &Reiter 2008).
Last but not least, we can ask subjects to simply read texts and qualitatively
comment on them. This can be useful especially in the initial stages of a project;this probably works best with subjects who are articulate and have some idea ofthe project’s goals.
4.3 Metric-based corpus evaluations
As discussed in Chapter 11, EVALUATION OF NLP SYSTEMS , some ﬁelds of NLP
routinely use automatic metrics such as B LEU and R OUGE to evaluate output

“9781405155816_4_020” — 2010/5/8 — 12:15 — page 589 — #16
Natural Language Generation 589
texts; these metrics work by comparing the output of the system to human-writtenreference texts. Such metrics are occasionally used in NLG as well, but in a muchmore limited way than in machine translation and document summarization. Thisis largely because of doubts as to how well such metrics correlate with (predict)the results of human evaluations.
Reiter and Belz (2009), who worked in the SumTime domain, empirically
evaluated how well
BLEU and ROUGE scores correlated with human ratings of
weather-forecast texts generated by a number of systems. They found that, while
BLEU and R OUGE ratings did not correlate with human evaluations of the content
quality of generated texts, some variants of B LEU did correlate with human rat-
ings of the linguistic quality of generated texts, provided that the generated textswere produced by systems built with similar technology (B
LEU ratings do not cor-
relate well with human ratings of texts produced by systems built with differenttechnologies; Belz & Kow 2009). They conclude that B
LEU could be used, with cau-
tion, in formative evaluations, but should not be used in summative evaluations(this terminology is explained in Chapter 11,
EVALUATION OF NLP SYSTEMS ).
Other studies have been more negative. For example, Gatt et al. (2009) evaluated
systems that generated referring expressions using extrinsic task-based measures(whether human subjects were able to successfully identify the reference target,and how long it took subjects to do this); non-task-based human ratings, and sev-eral automatic metrics (B
LEU,ROUGE , and string edit distance). They found that
none of the automatic metrics they looked at had a signiﬁcant correlation withthe extrinsic task-performance measures; the human ratings, in contrast, werereasonably well correlated with the results of the extrinsic evaluation.
All of the above studies looked at existing automatic metrics, which were devel-
oped for other areas of NLP such as machine translation. Perhaps metrics can bedeveloped speciﬁcally for NLG, which do a better job of evaluating NLG systems;this is one of the research challenges for the NLG community.
5 Some NLG Research Topics
In this section I discuss some (by no means all!) current research themes in NLG.
5.1 Statistical approaches to NLG
Statistical corpus-based techniques are very common in other areas of NLP (asis clear from the other chapters in this handbook), and many researchers areinvestigating how to use such techniques in NLG.
Perhaps the earliest use of statistical corpus-based techniques in NLG was real-
izers which overgenerated and then used a language model to select between theoptions (Langkilde & Knight 1998). As mentioned in Section 3.3, this approachis attractive because it reduces the amount of knowledge that must be explicitly

“9781405155816_4_020” — 2010/5/8 — 12:15 — page 590 — #17
590 Ehud Reiter
encoded in a grammar, although it can raise quality assurance and maintenanceconcerns.
The overgeneration approach can be used with other selection mechanisms
in addition to n-gram models. For example, Walker et al. (2007) have created
a microplanner based on the overgenerate-and-select approach. The selection isbased on ranking rules which are learned from a corpus of example texts whichhave been ranked by humans. As Walker et al. point out, one advantage ofthis approach is that it enables the microplanner to adapt to speciﬁc genres andeven individual differences, if appropriate training data is available; this is veryimportant since dealing with such differences is one of the main challenges inmicroplanning.
Another statistical approach to NLG is to build statistical models of speciﬁc
choices that NLG systems must make. Rambow and colleagues have writtena number of papers about individual choices, including VP ellipsis (Hardt &Rambow 2001) and lexical choice between near-synonyms (Bangalore & Rambow2000).
Belz has tried to create a statistical model of the entire microplanning and real-
ization process. Her pCRU framework (Belz 2008) models the generation processas a series of context-free rules. Corpus data is used to create a probabilistic modelof the likelihood of each of these rules being used. Given an input data set, thepCRU system then repeatedly invokes the most likely rule, until an output datatext is produced; the system also has a Viterbi mode which maximizes the likeli-hood of all decisions needed to generate a text (the Viterbi algorithm is discussedin Chapter 12,
SPEECH RECOGNITION ).
The above researchers have tried to create statistical models which can be incor-
porated into current NLG systems; such models need to be reliable and havegood coverage in the target domain. Perhaps for this reason, these researchershave tended to focus on either relatively well-understood choices (such as real-ization) and/or on domains with relatively simple language (such as weatherforecasts). Barzilay and Lapata have taken the different approach of trying tobuild stand-alone statistical models (i.e., models that are not part of an NLG sys-tem) of poorly understood choices such as content selection (Barzilay & Lapata2005a) and aggregation (Barzilay & Lapata 2006), in linguistically complex texts(sports stories in newspapers). It is not clear if Barzilay and Lapata’s models arecomprehensive and reliable enough to be used in real systems, but they showhow statistical techniques might be used to solve some of the hardest problemsin NLG.
Relatively little evaluation has been conducted on how well statistical NLG
approaches work when incorporated into complete NLG applications of the kinddiscussed in this chapter; this is perhaps one reason why the uptake of statisticaltechniques in the NLG community has been slower than in other NLP commu-nities. One exception is Belz (2008), who created pCRU systems in the SumTimedomain, and showed that human evaluators regarded pCRU texts to be similar inquality to human-written weather forecasts.

“9781405155816_4_020” — 2010/5/8 — 12:15 — page 591 — #18
Natural Language Generation 591
5.2 NLG inputs: connecting language to the world
Of course statistical techniques are an important research focus in almost all areasof NLP . Two research questions which are more speciﬁc to NLG concern the inputsand outputs of an NLG system. In this section we will look at some research issuesinvolving inputs; in the next section we will look at some research issues involvingoutputs.
As mentioned previously, it is rare for the input to an NLG system to be the
sort of formal semantic representation which is described in Chapter 15,
COMPU -
TATIONAL SEMANTICS . Usually the input to the system is some combination of
databases, knowledge bases, sensor data, event logs, outputs of other systems,and human-authored texts – in other words, the kind of data that computer sys-tems typically store and manipulate. Hence the NLG system must be able to eitherwork with such input data itself, or interface with an external data analysis system.This raises a number of interesting technological, scientiﬁc, and even philosoph-ical questions. In this section I will brieﬂy discuss three of the research issuesinvolved in generating texts which are based on non-linguistic input data; seeRoy and Reiter (2005) for a description of some of the numerous other challengesinvolved in connecting an NLP system to real-world input data.5.2.1 Language and the world: what do words mean? There is a tradition
in linguistics, including computational linguistics, of treating language as a‘stand-alone’ symbolic system and de-emphasizing how language relates to thenon-linguistic world. But of course language evolved to enable humans to com-municate about their world (social, intellectual, and physical), not as an isolatedsymbolic system. In particular, linguistic symbols (that is, words) should haverelationship to the non-linguistic world shared by the computer system and itshuman users.
The problem of mapping data to words is a difﬁcult one, which has received
surprisingly little attention in the linguistic community. Lexical semanticists haveexamined how logical forms are mapped into words, but this is only part of theproblem. Using an example from Roy and Reiter (2005), if an NLG system is try-ing to describe the visual appearance of an object based on camera data, it is notparticularly helpful to know that the predicate Red(X) maps to the adjective ‘red .’
What the system really needs to know is what pixel values from the camera can bedescribed as ‘red ,’ and how this is inﬂuenced by context (lighting conditions, other
objects in the scene, user’s background, and object being described). The systemalso may need to know when an object which incorporates many colors can still bedescribed as ‘red ’ (for example, an apple whose skin is mostly red but has a brown
stalk and some greenish areas on its skin). Last but not least, the NLG system maywant to know if ‘red ’ means more than just color; for example, if an apple is visu-
ally on the borderline between being ‘ red’a n d‘ green ,’ perhaps the decision as to
which term to use should depend on how ripe it is, since ‘ green apple’ suggests an
apple which is not ripe as well as an apple which is visually green.

“9781405155816_4_020” — 2010/5/8 — 12:15 — page 592 — #19
592 Ehud Reiter
Some of these issues were empirically investigated in the SumTime project,
especially for choosing phrases to describe time, and choosing verbs to communi-cate increases and decreases (Reiter et al., 2005). The analysis was performed byaligning the input data (numerical weather predictions) with the corpus texts, andthen trying to learn how corpus authors choose words, using both machine learn-ing techniques and manual analysis. The main ﬁnding of this investigation wasthat there were large individual differences in how different forecasters mappeddata to words. For example, some forecasters used ‘ by evening ’ to mean roughly
6pm, while others used ‘by evening ’ to mean midnight. An example involving a
verb is that one forecaster said he used the verb ‘ easing’( i n s t e a do f‘ decreasing ’) to
communicate a decrease in wind speed when the absolute wind speed was low;another said he used ‘easing’ when the absolute wind speed was high.
There were also differences between the forecast authors and the forecast read-
ers. For example, the forecast authors all used ‘ later’ to mean near the end of a
forecast period, but some forecast users interpreted ‘later’ to mean after a periodof at least 12 hours. A few of the forecast readers (but none of the authors) alsothought that time terms should depend on season (because they were linkedto sunrise and sunset) and/or on country (because they were linked to culturalexpectations about when people woke up, ate, and went to sleep).
Thus, SumTime showed that there were large differences in how different indi-
viduals mapped data to words in the weather domain (and in fact psychologistsand linguists have observed such differences in many other domains; Reiter andSripada 2002). In other words, this aspect of language is not standardized acrossa linguistic community in the same way that syntax and spelling are. Such prob-lems may be overcome in human language use by lexical alignment mechanisms(Brennan & Clark 1996); these help human participants in a dialogue agree onword usage. However, we do not understand alignment well enough to let acomputer NLP system align with a human, and in any case most NLG systemsdo not participate in dialogues with their users.5.2.2 Data analysis for linguistic communication A data-to-text system
typically must include data analysis and reasoning modules as well as linguis-tic modules (Reiter 2007). Another interesting research issue is how these modulesare affected by the need to generate textual summaries. In other words, how dolinguistic constraints and requirements affect the non-linguistic parts of a data-to-text system?
Sripada et al. (2003) addressed this issue, and in particular hypothesized that
such data analysis modules are affected by the Gricean maxims (Grice 1975). Forexample, the Gricean maxim of quality says that utterances should be truthful.One popular data analysis technique is linear segmentation, which involves ﬁttinga straight line to a set of datapoints. For data analysis purposes, this is often doneby ﬁnding the line which best ﬁts the data points, even if the end points of such aline are not real datapoints. Sripada et al. argue (largely on the basis of linguisticwork such as corpus analysis) that if such line segments are explicitly mentioned

“9781405155816_4_020” — 2010/5/8 — 12:15 — page 593 — #20
Natural Language Generation 593
in generated texts, it is better to use line segments anchored on real datapoints, asthis is more truthful.
Sripada et al.’s hypothesis is an interesting one, and more research is needed
to investigate to what degree Gricean maxims do indeed affect data analysis andinterpretation in systems that produce textual output. If this turns out to be thecase, it would be a very interesting example of how a linguistic theory (Griceanmaxims) affects what seems to be a non-linguistic task (data interpretation).5.2.3 Integrating linguistic and non-linguistic knowledge Another important
research topic is representations and models that include both linguistic andnon-linguistic information. This is not straightforward because a vision system,a knowledge-based reasoner, and an NLP system (for example) may representvery different kinds of information. For example, an NLP system may needto know that rain can be communicated using a verb which takes a dummy
subject; a knowledge-based meteorological reasoner may need to know that rain
is a type of precipitation; and a vision system may need to know that rain
consists of many small semi-spherical objects falling from the sky. It is unclearto what degree it makes sense to try to integrate these types of knowledge intoa single representation, and to what degree it is better to keep them distinct.Intuitively it seems that there should be some information which is shared bythe different reasoners; for example, rain is similar to snow from a linguistic
perspective (both can appear as verbs with dummy subjects, or as nouns), aknowledge perspective (both are kinds of precipitation), and a visual perspective(both consist of many small objects falling from the sky). But we do not knowhow to design knowledge representations which capture such commonalitieswhile still effectively representing the information needed by the different kindsof reasoners.
Even without integrated representation in the above sense, systems can still use
models and algorithms which utilize both linguistic and non-linguistic data. Forexample, Kelleher et al. (2005) used both linguistic and visual data in a referring-expression generation task. They computed the visual salience of objects in avisual scene, and used this information, together with a conventional linguisticdiscourse model, to generate referring expressions to objects in the scene.
5.3 NLG outputs, the role of language in
human–computer interaction
From a system perspective, an NLG module is usually part of a larger systemwhose goal is to inform, assist, motivate, persuade, and/or entertain a user. Thelarger system may be interactive, include graphical as well as textual outputs, andbe sensitive to the user’s disabilities, background, and tasks. This raises a numberof interesting research questions, ranging from basic questions about the effective-ness of language vs. graphics as a communication tool, to more applied questionssuch as what sort of language is most appropriate for blind people using a screen

“9781405155816_4_020” — 2010/5/8 — 12:15 — page 594 — #21
594 Ehud Reiter
reader. Collectively these can be considered as questions about the appropriaterole of generated language in human–computer interaction (HCI). As with thelanguage-and-world issues mentioned in the previous section, these issues havenot received much attention in the linguistic community.5.3.1 Text and graphics Perhaps the most studied of these issues is text and
graphics. In the 1990s there were many publications about ‘media choice,’ that isthe problem of deciding whether a particular bit of information should be pre-sented linguistically or graphically. For example, Feiner and McKeown (1990)suggested, in the context of generating instruction manuals, that physical loca-tion should be communicated graphically, and conditional information should becommunicated linguistically. Bernsen (1995) proposed an abstract theory whichguided the choice of text vs. graphics. Other researchers pointed out that therewere many similarities between text and graphics, and in particular many lin-guistic phenomena, such as conversational implicature (Marks & Reiter 1990),rhetorical structure theory (André & Rist 1994), and sublanguages (Reiter 1995),applied to graphics as well as text.
Of course, what most users really want is not text-only or graphics-only doc-
uments, but rather integrated documents that combine text and graphics. Morerecent research has focused on integrating text and graphics, primarily in the con-text of embodied conversational agents (ECA), that is animated characters whichmove, gesture, and talk. I will not discuss ECAs here as they typically communi-cate using speech instead of written language, but the interested reader can ﬁndout more about recent NLG-related ECA research by looking at proceedings ofthe Multimodal Output Generation (MOG) workshop (for example, Theune et al.,2007 and van der Sluis et al., 2008). Bateman and his colleagues (Bateman et al.,2001) have looked at integrating text and graphics in written documents, takinginto consideration layout issues.
One of the difﬁculties in this research area is evaluation. Users like graphics,
even if they are not actually useful and effective (Law et al., 2005). Hence eval-uations of multi-modal systems which are based on user ratings or preferencesmay not be good predictors of task effectiveness. In this area even more than otherareas of NLG, we need careful task-effectiveness studies to evaluate systems, andindeed to provide the basis for good theories of media choice and integration.
One common observation about text and graphics is that the choice depends
on user characteristics. Most obviously, graphics are probably not appropriate fora visually impaired user, and speech is not appropriate for a hearing-impaireduser. Less obviously but perhaps more importantly, the choice may depend onthe expertise of the user. In particular, as many visualization experts have pointedout (Tufte 1983), it is easy to mislead people with graphics, intentionally or unin-tentionally; viewers need some experience using graphs in order to be able tointerpret them correctly. Of course language can also mislead people, but almostall users have decades of experience in using language, whereas relatively fewpeople have this much experience using visualizations.

“9781405155816_4_020” — 2010/5/8 — 12:15 — page 595 — #22
Natural Language Generation 595
5.3.2 Interaction Another aspect of the ‘HCI of NLG’ is interaction. One of
the most impressive aspects of current visualization systems is their interactivity;users do not just see a static graph, they can interact with the system and requestclose-ups, choose to have different information presented, etc. In contrast, mostcurrent NLG systems generate static texts which cannot be interacted with; indeedbetter interactivity is one of the most common requests I receive from potentialusers of NLG systems. Of course dialogue systems (see Chapter 16,
COMPUTA -
TIONAL MODELS OF DIALOGUE ) allow interaction, but the current state of the art
in dialogue technology makes it difﬁcult to build systems with which the user canreliably interact.
An alternative is to allow the user to interact with an NLG system via mouse
clicks and/or keyboard commands, as indeed users interact with visualizationsystems. One way of structuring this interactivity is via ‘dynamic hypertext.’Such NLG systems generate texts which include hyperlinks, and some of thesehyperlinks invoke the NLG system to generate different texts. The
ILEX system
(O’Donnell et al., 2001), for example, generated descriptions of museum items,which had hyperlinks to related items. Clicking on one of these links would invoke
ILEX to generate a description of the related item; this description could include
references and comparisons to the original description.
Other interaction models are also possible. For example, IGRAPH (Ferres et al.,
2006), which helps blind users browse statistical data sets, uses a keyboard inter-face with keys which allow users to browse forward and backward in the data set,and to get higher-level summaries or lower-level details. This interface is similarto a screen reader, which of course is what most blind users are used to.
Most work on NLG interaction attempts to adapt existing types of interfaces,
such as hypertext and screen readers. But perhaps what NLG really needs is newtypes of interfaces. One interesting idea is
WYSIWYM (Power et al., 1998), which
uses NLG to help users construct knowledge bases and queries; the user con-structs these entities by manipulating a feedback text, which is generated fromthe actual knowledge base entity or query being authored. Another innovativeauthoring interface is used in
STANDUP (Ritchie et al., 2006), which allows chil-
dren with learning difﬁculties to create jokes. STANDUP uses an interface which
presents the process of creating a joke as a bus journey, with stops such as ‘WordShop.’ Hopefully we will see more experimentation with novel interfaces to NLGsystems in the future.5.3.3 User modeling As should be clear by now, there are major differences
between individual users of NLG systems, in terms of the type of language theyprefer, (dis)abilities, expertise, and task. In principle it would be nice to representthese differences in a user model, and take the user model into account during thegeneration process.
Zukerman and Litman (2001) summarize research on user modeling in NLG
(and other aspects of NLP). In very broad terms, most research on user model-ing for NLG has either explicitly asked users to classify themselves into one of asmall number of categories (such as ‘novice’ and ‘expert’), or tried to implicitly

“9781405155816_4_020” — 2010/5/8 — 12:15 — page 596 — #23
596 Ehud Reiter
acquire user models based on how a user interacts with the NLG system. Neitherof these approaches allows very detailed models of users to be created; and henceneither approach allows sophisticated in-depth tailoring of generated texts to theparticulars of individual users.
However, the beneﬁt of tailoring texts to shallow user models does not seem
to be very high, at least in my experience. Detailed user models probably wouldallow much better texts to be generated, but we do not know how to acquire suchmodels. Researchers have proposed ideas for acquisition of detailed models; forexample perhaps it would be possible to create detailed models (at least of a user’slinguistic expertise) via corpus analysis of texts that a user has written, or by ask-ing users to rate a large number of texts and analyzing their ratings (Walker et al.,2007). However, to the best of my knowledge no one has yet tried to use these tech-niques to obtain a good empirical understanding of how language varies betweenindividuals in a linguistic community. This is a pity, because such research couldshed light on fundamental questions about language, as well as improve NLGtechnology.
5.4 Affective NLG: going beyond informing and
helping users
Most research on NLG has assumed that the purpose of generated texts is toinform users and help them achieve a task. But of course language is used formany other purposes, including motivation, persuasion, stress reduction, socialengagement, and entertainment. NLG systems which have such goals are calledaffective NLG systems (de Rosis & Grasso 2000).
5.4.1 Motivation and persuasion Perhaps the best-studied affective NLG goals
are motivation and persuasion. There is of course an extensive literature in psy-chology and marketing on the best way to motivate and persuade people; andalso a rich literature in philosophy and logic in formal models of argumentation.Several NLG systems have attempted to use theories from these communities topersuade and/or motivate people.
For example, the STOP system (Reiter et al., 2003a), which produced tailored
smoking-cessation letters, was based on a popular psychological model of howpeople can change addictive behaviors (Prochaska & diClemente 1992). Unfortu-nately, an evaluation of STOP showed that the system was not effective; recipientsof STOP letters were no more likely to stop smoking than recipients of controlnon-personalized letters. This may be because STOP used fairly shallow usermodels, and effective tailoring requires detailed user models (as discussed inSection 5.3.3).
Another approach was taken by Carenini and Moore (2006), who based their
system on argumentation and decision theory. Their GEA system generated real-estate descriptions of houses, and tried to make these descriptions more effective(in terms of persuading potential buyers to seriously consider a house) by tailor-ing the description based on a quantitative model of the buyer’s preferences.

“9781405155816_4_020” — 2010/5/8 — 12:15 — page 597 — #24
Natural Language Generation 597
GEA was tested in an artiﬁcial context (with subjects who were pretending to behouse buyers, not real house buyers), with mixed but overall encouraging results.
More recently, Guerini et al. (2007) developed a sophisticated system which
attempted to persuade people to visit a museum. Guerini’s system was basedon an embodied conversational agent, so his system could display facial expres-sions and use appropriate tones of voice. His system also had rich user models,which included information about cognitive state (beliefs, desires, and intentions),emotional state, and social relationships. Unfortunately Guerini’s system has onlybeen evaluated in small pilot evaluations (which did not see a signiﬁcant effect),so its effectiveness is unclear.
All of the above-mentioned systems relied heavily on user models; it may be
that the quality of the user model is one of the main limiting factors in the perfor-mance of persuasive NLG systems. As mentioned in Section 5.3.3, acquiring goodinformation about users is a major challenge in itself.5.4.2 Improving emotional state Another communicative goal is to make
people feel better; a particular goal of interest is to reduce stress. We know thatstress is often inversely correlated with sense of control; someone who feels theyhave no control over a situation is likely to feel more stressed than someone whofeels that they are at least partially in control. Furthermore we know that, inmedical contexts in particular, people are likely to feel more in control if theyknow more; patients of course are entitled to make decisions about their ownhealth care, but they can only effectively make decisions if they understand theirsituation. Also, understanding one’s medical situation can reduce uncertainty, andreduced uncertainty can reduce stress.
For these reasons, it seems plausible that a system which informs patients about
their medical condition could reduce their stress about their medical condition;such a system would be very useful in many medical contexts. This hypothe-sis was investigated by Cawsey et al. (2000), who built several systems whichtried to increase patients’ understanding of their medical record, using a browsingdynamic hypertext interface. An evaluation showed that patients liked the system,but unfortunately there was no signiﬁcant reduction in stress among patients whoused the system.
A new area of research is using NLG to promote social interaction, for example
by helping friends and relatives provide support to parents of sick babies (Moncur& Reiter 2007), and by helping people with communication disabilities engage insocial conversations (Reiter et al., 2009).5.4.3 Entertainment Last but not least, some NLG systems generate texts that
are intended to entertain readers. For example Binstead and Ritchie (1997) devel-oped a computer system which generated puns, and Ritchie et al. (2006) adaptedthis technology to help humans (children with learning difﬁculties) create puns.These systems combined theories of what makes a good pun with databases whichhold the necessary information about word pronunciation, meaning, etc.
There has also been considerable research on computer systems which
generate stories. This includes both research on the content and structure of

“9781405155816_4_020” — 2010/5/8 — 12:15 — page 598 — #25
598 Ehud Reiter
computer-generated stories (Perez y Perez & Sharples 2004) (much of this is car-ried out in the computational creativity community), and research on appropriatelanguage for stories (Callaway & Lester 2002). Much of this research is presented atconferences which involve the computer-gaming community, such as InteractiveDigital Storytelling (Spierling & Szilas 2008).
6 NLG Resources
I conclude this chapter with a short survey of practical resources which might beof interest to people who want to get involved in NLG research. One good generalsource of NLG resources is the NLG portal of the Association for ComputationalLinguistics wiki.
2
Probably the most commonly requested resource is NLG software. There are
a number of realizers (Section 3.3) which are freely available on the web. Theserealizers vary greatly in linguistic sophistication and ease of use, with the simplestrealizers (in linguistic terms) generally being the easiest to use. They also vary inpractical aspects such as documentation and programming language.
Unfortunately there are currently no software resources for microplanning and
document planning which have been successfully used outside the groups whichcreated them. Hopefully this situation will improve in the near future.
Data resources can also be very useful. Quite a few researchers have made
resources available on the web, but few of these have actually been used by otherpeople at the time of writing. Exceptions include the SumTime corpus,
3which
contains numerical weather predictions and human-written forecasts based onthese predictions; and the TUNA corpus,
4which contains scene descriptions and
referring expressions produced by human subjects from these scene descriptions.
Turning to information resources, such as textbooks and web sites, contempo-
rary NLP textbooks unfortunately say little about NLG. There is one specialistNLG textbook, Reiter and Dale (2000), but it does not present developments since2000. Bateman and Zock maintain a useful web page which lists NLG systems,including links to homepages and key references.
5Other than that, the main
source of information is conference proceedings, especially the International NLGConference and the European NLG workshop; proceedings of many of these areavailable from the ACL Anthology.
6
NOTES
1 http://protege.stanford.edu2 http://aclweb.org/aclwiki3 www.csd.abdn.ac.uk/research/sumtime/4 www.csd.abdn.ac.uk/research/tuna/corpus/5 http://www.nlg-wiki.org/systems/6 www.aclweb.org/anthology/

