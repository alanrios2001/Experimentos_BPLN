“9781405155816_4_017” — 2010/5/8 — 12:10 — page 482 — #1
17 Computational
Psycholinguistics
MATTHEW W. CROCKER
1 Introduction
Computational psycholinguistics is concerned with the development ofcomputational models of the cognitive mechanisms and representations thatunderlie language processing in the mind/brain. As a consequence, computa-tional psycholinguistics shares many of the goals of natural language processingresearch, including the development of algorithms that can recover the intendedmeaning of a sentence or utterance on the basis of its spoken or textual realiza-tion. Additionally, however, computational psycholinguistics seeks to do this in amanner that reﬂects how people process language.
Natural language is fundamentally a product of those cognitive processes that
are co-ordinated to support human linguistic communication and interaction. Thestudy of language therefore involves a range of disciplines, including linguis-tics, philosophy, cognitive psychology, anthropology, and artiﬁcial intelligence.Computational psycholinguistics, perhaps more than any other area, epitomizesinterdisciplinary linguistic inquiry: the ultimate goal of the enterprise is to imple-ment models which reﬂect the means by which linguistic information is stored in,and utilized by, the mind and brain. But beyond modeling of the representations,architectures, and mechanisms that underlie linguistic communication, compu-tational psycholinguistics is increasingly concerned with developing explanatory
accounts, which shed light on why the human language faculty is the way it is.As such, models of human language processing must ultimately seek to beconnected with accounts of language evolution and language acquisition.
This chapter presents some of the historically enduring ﬁndings from research in
computational psycholinguistics, as well as a state-of-the-art overview of currentmodels and their underlying differences and similarities. While computationalmodels of human language processing have been developed to account for var-ious levels of language processing – from spoken word recognition and lexicalaccess through to sentence production and interpretation – this chapter will placeprimary emphasis on models of syntactic processing. It will not be surprising that

“9781405155816_4_017” — 2010/5/8 — 12:10 — page 483 — #2
Computational Psycholinguistics 483
many accounts of human syntactic processing are heavily informed by compu-tational linguistics, speciﬁcally natural language parsing. A traditional approachhas been to try to identify parsing algorithms which exhibit the range of observedhuman language processing behaviors, including incremental processing, localand global ambiguity resolution, and parsing complexity (both time and space;see Chapter 2,
COMPUTATIONAL COMPLEXITY IN NATURAL LANGUAGE ,a n d
Chapter 4, THEORY OF PARSING ). Such symbolic approaches have the advantage of
being well understood computationally, transparent with respect to their linguis-tic basis, and scalable. An alternative approach has been to develop models usingneurally inspired connectionist networks (see Chapter 9,
ARTIFICIAL NEURAL NET -
WORKS ), which are able to learn from sufﬁcient exposure to language, are robust,
and degrade gracefully (Elman 1990; Plunkett & Marchman 1996). Purely connec-tionist approaches often use distributed, rather than symbolic, representations,making it difﬁcult to understand precisely what kinds of representations suchnetworks develop. Furthermore, they are typically relatively small-scale mod-els, and it has proven difﬁcult to scale their coverage. Some cognitive modelsof language are in fact best viewed as hybrids, exploiting a mixture of symbolicrepresentations, and connectionist-like computational mechanisms. Most recently,probabilistic approaches have dominated, providing a transparent linguistic basison the one hand, with an experience-based mechanism on the other.
Before considering the range of approaches, it is important to understand pre-
cisely the goals of computational psycholinguistics, and the kinds of data thatinform the development of models. Furthermore, while many ideas and algo-rithms have their roots in computational linguistics, we begin by identifyingwhere these two endeavors diverge, and why.
2 Computational Models of Human Language
Processing
While psycholinguistic theories have traditionally been stated only informally,the development of computational models is increasingly recognized as essen-tial. Speciﬁcally, computational models entail the explicit formalization of theories,and also enable prediction of behavior. Implemented models are especially impor-tant, not only because human language processing is highly complex, involvinginteraction of diverse linguistic and non-linguistic constraints, but also because itis inherently a dynamic process: people are known to understand, and produce,language incrementally as they read or hear a sentence unfold. This entails that therecovery of meaning happens in real time, with the interpretation being inﬂuencedby a range of linguistic, non-linguistic, and contextual sources of information, onthe one hand, and also shaping our expectations of what will come next, on theother.
How is computational psycholinguistics different from computational lin-
guistics? In fact, early conceptions of natural language processing explicitly

“9781405155816_4_017” — 2010/5/8 — 12:10 — page 484 — #3
484 Matthew W. Crocker
approached language as a cognitive process (Winograd 1983). Ultimately, how-ever, research is shaped by the speciﬁc goals of a particular research community.To understand this more clearly, it can be helpful to distinguish accounts of linguis-ticcompetence and performance. Broadly speaking, a theory of linguistic competence
is concerned with characterizing what it means to ‘know’ language, including thekinds of syntactic and semantic rules and representations provided by a linguistictheory. A theory of performance, in contrast, characterizes the means by whichsuch knowledge is used on-line to recover the meaning for a given sentence, as
exempliﬁed by a psychologically plausible parsing algorithm.
Consider, for example, one of the classic examples from psycholinguistics,
known as the main verb/reduced-relative clause ambiguity (Bever 1970):
(1) The horse raced past the barn fell.
For many readers, this sentence seems ungrammatical. The confusion arises
because the verb raced is initially interpreted as the main verb, leading the parser
‘up the garden path’ (Frazier 1979). Only when the true main verb fellis reached
can the reader potentially determine that raced past the barn should actually have
been interpreted as a reduced-relative clause (as in The horse which was raced past
the barn fell). In this relatively extreme example of a garden-path sentence, many
readers are unable to recover the correct meaning at all, despite the sentencebeing perfectly grammatical (cf. The patient sent the ﬂowers was pleased which is
rather easier, but has the same structure). Thus our linguistic competence offersno explanation for this phenomena, rather it seems necessary to appeal to how
people recover the meaning, resolving ambiguity as they encounter the sentenceincrementally.
Computational linguistics and psycholinguistics have traditionally shared
assumptions regarding linguistic competence; both are concerned with develop-ing algorithms which recover a linguistically adequate representation of a sentenceas deﬁned by current syntactic and semantic theories. At the level of perfor-mance, however, computational linguistics is rarely concerned with issues suchas incremental sentence processing and the resolution of local ambiguities which
are resolved by the end of the sentence. There is rather a greater interest in opti-mizing the computational properties of parsing algorithms, such as their time andspace complexity. Computational psycholinguistics, in contrast, places particularemphasis on the incremental processing behavior of the parser.
As computational linguistics has increasingly shifted its focus towards appli-
cation domains, the demands of these applications has further divided thecomputational linguistics and computational psycholinguistics communities. Theacknowledged difﬁculty of computationally solving the natural language under-
standing problem , which in turn relies on a solution to the artiﬁcial intelligence
problem,
1has led to an increased focus in computational linguistics on devel-
oping less linguistically ambitious technologies which are scalable and able toprovide useful technologies for particular subproblems. Robust methods for part-of-speech tagging, named entity recognition, and shallow parsing (see Chapter 5,

“9781405155816_4_017” — 2010/5/8 — 12:10 — page 485 — #4
Computational Psycholinguistics 485
MAXIMUM ENTROPY MODELS ), for example, can contribute to applications rang-
ing from spam-ﬁltering and document classiﬁcation to information extraction,question answering, and machine translation (see Chapter 18,
INFORMATION
EXTRACTION , Chapter 22, QUESTION ANSWERING , and Chapter 19, MACHINE
TRANSLATION ). For the most part, however, the methods used to perform these
tasks have no cognitive basis.
While the research goals of computational linguistics and computational psy-
cholinguistics have diverged since the 1970s, there continues to exist a signiﬁcantoverlap in some of the methods that are exploited. An interesting result of the shifttowards wide coverage and robust language processing has been a tremendousemphasis on statistical language processing, and machine learning. As we willsee, many of the same underlying methods play a central role in cognitive mod-els as well, with particular overlap coming from research on statistical languagemodeling (see Chapter 3,
STATISTICAL LANGUAGE MODELING ).
2.1 Theories and models
In developing accounts of human language processing, as with any other cog-nitive process, it is valuable to distinguish the expression of the theory from agiven model which implements the theory. Theories typically relate to a particularaspect of language processing – such as lexical access, parsing, or production –and as such provide incomplete characterizations of language processing in gen-eral. Furthermore, theories often provide a relatively high-level characterizationof a process, leaving open details about what speciﬁc algorithms might be usedto realize the theory. Marr (1982), in fact, identiﬁes three levels at which cognitiveprocesses may be described: (1) the computational level, which deﬁnes what is com-
puted, (2) the algorithmic level, which speciﬁes how computation takes place, and
(3) the implementation level, which states how the algorithms are actually realized
in the neural assemblies and substrates of the brain. In the case of language pro-cessing, which is a relatively high-level cognitive function, there have been veryfew accounts at the third level: we simply have insufﬁcient understanding abouthow language is processed and represented at the neural level.
There are several reasons for why a distinction of these levels is important. One
reason for wishing to state theories at a relatively high level is to emphasize thegeneral properties of the system being described, and ideally some justiﬁcation ofwhy it is the way it is. Additionally, it is often the case that the relevant empiricaldata available may not permit a more detailed characterization. That is to say, inbuilding a speciﬁc model (at the algorithmic level) of a given theory (stated atthe computational level), we are often required to specify details of processingwhich are underdetermined by the empirical data. While resolving those detailsis essential to building computational models that function, we may not wish toascribe any psychological reality to all aspects of the model. In the event that thereis some new piece of empirical evidence which the model incorrectly accounts for,such a distinction is critical: it may be a consequence of the original theory, eitherfalsifying it or entailing some revision to it, or it may simply be a result of some

“9781405155816_4_017” — 2010/5/8 — 12:10 — page 486 — #5
486 Matthew W. Crocker
(possibly purely pragmatically based) decision made in implementing the model,such that only a change at the algorithmic or implementation level, and not thecomputational level, is needed.
Theories of human language processing can be broadly characterized by the
extent to which they assume that the mechanisms underlying language pro-cessing are restricted orunrestricted (Pickering et al., 2000a). Restricted accounts
begin with the assumption that cognitive processes are resource bound, and thatobserved processing difﬁculties in human language processing are a consequenceof utilizing or exceeding these resource bounds. In order to explain a number ofexperimentally observed behaviors, a range of restrictions have been identiﬁedwhich may play a role in characterizing the architecture and mechanisms of thehuman language processor.
Working Memory: the language processor has limited capacity for storing lin-
guistic representations, and these may be exceeded during the processing ofcertain grammatical structures, such as center-embeddings: ‘ The mouse [that
the cat [that the dog chased] bit] died ,’ in which three noun phrases must be
maintained in memory before they can be integrated with their respectiveverbs (Miller & Isard 1964; Bever 1970; Gibson 1991).
Serial Processing: while there may be many structures that can be associated
with a sentence during incremental processing, the human parser only pur-sues one structure, rather than several or all of them, so as to minimize spacecomplexity. This predicts that, if the sentence is disambiguated as havingan alternative structure, some form of reanalysis will be necessary and cause
processing difﬁculty (Frazier 1979).
Modularity: Cognitive processes underlying sentence processing are simpli-
ﬁed by restricting their representational and informational domains. Thisenables on-line syntactic processes to operate independently of more general,complex, and time-consuming cognitive processes such as pragmatics, worldknowledge and inference (Fodor 1983).
Unrestricted accounts, in contrast, typically assume that the processing is not
fundamentally constrained, and that people are able to bring diverse informa-tional constraints (i.e., interactive rather than modular) to bear on deciding amongpossible structures and interpretations (i.e., parallel rather than serial). Suchaccounts do not deny that cognitive resources are ultimately limited, but do tac-itly assume that the architectures and mechanisms for language processing arenot fundamentally shaped by the goal of conserving such resources. Most currentmodels are best viewed as lying somewhere between the two extremes.
2.2 Experimental data
As noted above, models of human language processing seek to model not only lin-guistic competence – the ability to relate a sentence or utterance with its intended

“9781405155816_4_017” — 2010/5/8 — 12:10 — page 487 — #6
Computational Psycholinguistics 487
meaning – but also human linguistic performance. Language processing is bestviewed as a dynamic process, in which both the linguistic input and associatedprocessing mechanisms unfold over time. Evidence concerning how people pro-
cess language can be obtained using a variety of methods. An important aspectof all controlled psycholinguistic experiments, however, is a clear experimentaldesign. Experiments are designed to test a speciﬁc hypothesis about language pro-cessing, usually as predicted by a particular theoretical proposal or model. As anexample, let’s consider the matter of serial, incremental processing: the claim thateach word is attached into a single connected partial syntactic representation asthe sentence is read. This claim makes the prediction that any local ambiguity willbe resolved immediately and if that decision later turns out to be wrong, thensome processing difﬁculty will ensue. Consider the following sentences:
(2) a. The athlete [
VPrealized [NPher potential]]
b. The athlete [VPrealized [S[NPher potential][ VPmight make her famous ]]]
c. The athlete [VPrealized [S[NPher exercises][ VPmight make her famous ]]]
In sentences (2a) and (2b), a local ambiguity occurs when we encounter the
word ‘her,’ following the verb ‘realized .’ While the word ‘her’ certainly begins a
noun phrase (NP), that NP can be either the direct object of the verb, as in thesentence (2a), or the subject of an embedded sentence, as in (2b). To investigatewhether or not people immediately consider the direct object reading, Pickeringet al. (2000b) compared processing of this ambiguity, manipulating only whetherthe NP following the verb was a plausible direct object. They argued that if peoplefavor building the direct object reading, this will inﬂuence processing complex-ity in two ways. First, in (2b), they will attach the NP ‘ her potential ’a st h ed i r e c t
object, and then be surprised when they encounter the following VP , which forcesthem to reanalyze the object NP as the subject of the embedded clause. For (2c),they should also attempt the direct object attachment, but be surprised because itis implausible, and then assume it begins an embedded clause. In an eye-trackingstudy, they found evidence supporting exactly this prediction. Namely, in (2c)people spent longer reading the NP (‘her exercises’) following the verb, than theydid reading the NP (‘her potential ’) in (2b), suggesting they built a direct object
structure only to realize it is implausible. In (2b), however, people spent longerreading the disambiguating region (the embedded VP) than in (2c), suggesting they
had committed to the (plausible) direct object reading, and then needed to revisethat analysis.
Since many different factors are known to inﬂuence reading times, most psy-
cholinguistic experiments use a design like the one just described above, in whichthe difference in reading times for similar sentences (or regions of the sentence)
are compared, and where only the factor which is of interest is varied betweenthe sentences. One simple method which has been used effectively to investigateincremental reading processes is the self-paced reading (SPR) paradigm. Using this
method, the sentence is presented one word at a time, and the participant mustpress a key to see the next word. The latency between key presses can then be

“9781405155816_4_017” — 2010/5/8 — 12:10 — page 488 — #7
488 Matthew W. Crocker
averaged across both participants and a range of linguistic stimuli to obtain aver-age reading times, which can then be analyzed to determine if there are statisticallysigniﬁcant differences in reading times resulting from the experimental manipu-lation. Another more sophisticated method, eye tracking, provides an especiallyrich, real-time window into language processing, with the added advantage ofnot requiring any additional (possibly unnatural) task. Current eye-tracking tech-nology enables the precise spatial and temporal recording of eye movements(saccades) and ﬁxations as people read a sentence which is displayed in its entiretyon a display. Since people often look back to earlier points in the sentence whilereading, several reading-time measures can be computed, such as ﬁrst pass (the
amount of time spent in a region before the eye moves out of the region), or total
time (all the time spent reading a region, including looking back at it, etc.) (Rayner
1998).
When relating a theory or model of language processing to empirical data, it
is important to be clear about the exact nature of the relationship that is beingassumed, via a linking hypothesis . In the example described above, we implicitly
assumed that it was the surprise – of either an implausible interpretation, or a
subsequent cue that reparsing would be required – that would lead to increasedreading time. But there are many characteristics of a computational model that onemight argue would be reﬂected in empirically observable processing complexity.As we will see below, everything from the frequency of the word which is beingprocessed, to the memory load associated with processing completely unambigu-ous sentences, can be observed in reading times. This is one reason why carefullycontrolled experiments are so essential, as are clear linking hypotheses that can beused to relate a processing model to some empirical measure.
Reading times offer a robust and well-understood behavioral method for
establishing processing difﬁculty during sentence comprehension. More recently,however, neuroscientiﬁc methods have become increasingly important for inform-ing the development of psycholinguistic theories. This is particularly true ofevent-related potentials (ERPs), which can be observed using electroencephalog-
raphy (EEG) methods. ERPs reﬂect brain activity, as measured by electrodespositioned on the scalp, in response to a speciﬁc stimulus. Numerous ERPstudies have demonstrated the incrementality of language comprehension asrevealed by the on-line detection of semantic (e.g., Kutas & Hillyard 1980; 1983;van Petten & Kutas 1990) and syntactic (e.g., Osterhout & Holcomb 1992; 1993;Matzke et al., 2002) violations, indexed broadly by so-called N400 and P600 deﬂec-tions in scalp activation respectively. However, while there are several theoreticalprocessing accounts which are derived from such data (Friederici 2002; Bornkessel& Schlesewsky 2006), relatively few have led to the development of computationalmodels (but see Crocker et al., 2010). For this reason, we will focus here primarilyon models based on behavioral ﬁndings.
Finally, the visual world paradigm , in which participants’ eye movements to
visually displayed objects are monitored as participants listen to an unfoldingutterance, has revealed that people automatically map the unfolding linguisticinput onto the objects in their visual environment in real time (Tanenhaus et al.,

“9781405155816_4_017” — 2010/5/8 — 12:10 — page 489 — #8
Computational Psycholinguistics 489
1995). Using this method, Allopenna et al. (1998) demonstrated not only thatincreased inspections of visually present objects often occur within 200 ms of theirmention, but also that such utterance-mediated ﬁxations even reveal sublexicalprocessing of the unfolding speech stream. Perhaps of even greater theoreticalinterest are the ﬁndings of Tanenhaus et al. (1995), revealing on-line interaction ofvisual and linguistic information for sentences such as ‘ Put the apple on the towel
in the box.’ Not only did listeners rapidly ﬁxate the mentioned objects, but theirgaze also suggested the inﬂuence of the visual referential context in resolving thestructural ambiguity in this sentence (namely, whether towel is a modiﬁer of, or
the destination for, the apple). In fact, this paradigm has also shown that compre-
hension is not just incremental, but often highly predictive : Altmann and Kamide
(1999) demonstrated that listeners exploit the selectional restrictions of verbs likeeat, as revealed by anticipatory looks to edible objects in the scene (before thoseobjects have been referred to) (see also Federmeier (2007) for related ﬁndings fromevent-related potential studies).
3 Symbolic Models
Evidence that people understand language incrementally is perhaps one of themost ubiquitous ﬁndings in experimental research on human sentence process-ing. The importance of this ﬁnding for computational models is that it places astrong constraint on candidate parsing mechanisms. Not all early computationalaccounts adhered to the incrementality constraint, however. The Parsifal model
(Marcus 1980), for example, proposed a deterministic model of human parsing toaccount for the observation that people are generally able to understand languagein real time. Parsifal was essentially a bottom-up LR parser, which exploited upto three look-ahead symbols (which could be complex phrases, not just words) todecide upon the next parsing action with certainty. This look-ahead mechanismenabled the parser to avoid making incorrect decisions for most sentences, andMarcus argued that those sentences where the parser failed were precisely thosecases where people also had substantial difﬁculty.
There are, however, several criticisms that can be leveled at Parsifal. Not only is
the parser highly non-incremental, with the capacity to leave large amounts of theinput on the stack, it also offers only a binary account of processing difﬁculty: easyversus impossible. Experimental research has shown, however, that some kinds oferroneous parsing decisions are much easier to recover from than others (for adirect comparison of two such cases, see Sturt et al., 1999). The licensing-structure
parser (Abney 1989) responded to these criticisms by adapting a shift-reduceparsing architecture of Pereira (1985) to operate more incrementally. Since look-ahead must be excluded in order to maintain incrementality, the parser often facesnon-determinism during processing. For these cases, Abney proposes several pref-erence strategies which are intended to reﬂect parsing principles motivated byhuman behavior such as right association (Kimball 1973) (attach incoming material

“9781405155816_4_017” — 2010/5/8 — 12:10 — page 490 — #9
490 Matthew W. Crocker
low on the right frontier of the current parse) and theta attachment (Pritchett 1992)
(attach constituents so as to maximize thematic role assignment, see Section 3.1).Abney additionally addressed the issue of backtracking, in case parsing fails and
an alternative parse needs to be found. The licensing-structure parser, however,is still not strictly incremental, with some parse operations delaying the attach-ment of words and constituents. A further criticism, which applies to the accountsproposed by Marcus, Abney, and Pritchett, is their strong reliance on verb infor-mation to determine the parser’s actions. While this approach works reasonablyfor languages like English, it is problematic for explaining parsing of verb-ﬁnallanguages like Japanese, Turkish, and many others.
Resnik (1992a) reconsiders the role of space, or memory, utilization as a crite-
ria for selecting psychologically plausible parsing algorithms. As noted above,embedding structures reveal an interesting property of human sentence pro-cessing, illustrated by Resnik’s following examples (brackets indicate emdeddedconstituents):
(3) a. [[[John’s ]brother’s] cat] despises rats EASY
b. This is [the dog that chased [the cat that bit [the rat that ate the cheese ]]]
EASY
c.[The rat [that the cat [that the dog chased] bit] ate the cheese] HARD
While people typically ﬁnd left-embeddings (3a) and right-embeddings (3b) rel-
atively unproblematic, center-embeddings (3c) are often judged as difﬁcult, if notcompletely ungrammatical (though one can quite clearly demonstrate that theyviolate no rules of grammar). Building on previous work by Abney and John-son (1991) and Johnson-Laird (1983), Resnik (1992a) demonstrates that neitherstrictly top-down (LL) nor bottom-up (LR) parsers can explain this observation.Top-down parsing predicts only right-embeddings to be easy, while bottom-uppredicts only left-embeddings to be easy. Further, Resnik demonstrates that thestandard version of a left-corner (LC) parser, which combines top-down andbottom-up parsing, is no different than the bottom-up parser with regard tostack complexity. However, an arc-eager variant of the LC parser – in which
nodes that are predicted bottom-up can be immediately composed with nodes that
are predicted top-down – models the human performance correctly: left- andright-embeddings have constant complexity, while center-embedding complexityincreases linearly with the number of embeddings. A further advantage of the arc-eager LC parser is that it is incremental for all but a few sentence structures (formore detailed discussion of parsing mechanisms, see Crocker 1999).
3.1 Ambiguity resolution
A central element of any model of sentence processing concerns how it dealswith lexical and syntactic ambiguity: how do we decide which representationto assign to the current input? The assumption of incremental processing fur-ther entails that decisions regarding which structure to pursue must be made as

“9781405155816_4_017” — 2010/5/8 — 12:10 — page 491 — #10
Computational Psycholinguistics 491
each word is processed. One simple solution to this issue is to propose a parallelmodel of processing, in which all possible syntactic analyses are pursued simulta-neously during processing. Such a solution has traditionally been discarded fortwo reasons. First, for a large-scale grammar and lexicon, hundreds of analy-ses may be possible at any point during parsing – indeed, for grammars withleft-recursion, there may in fact be an unbounded number of parses possible –and would arguably exceed cognitively plausible memory limitations. One solu-tion to this is to assume bounded parallelism, in which only a limited subset of
parses is considered. Second, even if one assumes parsing is (possibly bounded)parallel, there is strong evidence that only one interpretation is consciously con-sidered, otherwise we would never expect to observe the kind of garden-pathsentence discussed in Section 2. Thus, regardless of whether incremental process-ing is serial or parallel, any model requires an account of which parse is to bepreferred.
There have been many proposals to explain such ambiguity preferences in the
psycholinguistic literature. Frazier (1979), building on previous work by Kimball(1973), proposed the following two general principles:
Minimal attachment (MA): Attach incoming material into the phrase marker
being constructed using the fewest nodes consistent with the well-formedness rules of the language.
Late closure (LC) : When possible, attach incoming material into the clause or
phrase currently being parsed.
Recall example (2) above. When the noun phrase ‘ her potential ’ is encountered, it
can be attached directly either as the object of ‘ realized ’ (2a), or as the subject of the
embedded clause (2b). The latter structure, however, requires an additional nodein the parse-tree, namely an S node intervening between the verb and the nounphrase. Thus MA correctly predicts the human preference to interpret the nounphrase as a direct object, until syntactic or semantic information disambiguates tothe contrary.
While these parsing principles dominated sentence processing for some time,
they have been criticized on several grounds. First, as noted by Abney (1989) andPritchett (1992), MA is highly sensitive to the precise syntactic analysis assignedby the grammar. The adoption of binary branching structures in many modernsyntactic theories means that MA fails to differentiate between a number of ambi-guities (including the one in Figure 17.2, discussed below). In response to this,several theories proposed a shift away from MA towards what Pritchett (1992)dubbed theta attachment (see also Abney 1989; Crocker 1996 for related proposals).
Theta attachment states that the parser should attempt to maximally satisfy verbargument relations whenever possible, and thus prioritize the parsing of phrasesinto such argument positions, where they will receive a semantic, or thematic,
role from the verb (Fillmore 1968). Returning to sentence (2a), theta attachmentasserts that attaching the noun phrase ‘ her potential ...’ as a direct object is pre-
ferred because not only is the verb able to assign a thematic role (THEME) to the

“9781405155816_4_017” — 2010/5/8 — 12:10 — page 492 — #11
492 Matthew W. Crocker
noun phrase, but the noun phrase also receives a thematic role at that point inprocessing. If the noun phrase were attached as the embedded subject, as in (2b),it would temporarily have no role assigned to it (until the embedded predicate‘might make ...’ is processed). Thus the latter option is dispreferred.
The above approaches are typically associated with modular processing
accounts (Fodor 1983), since they emphasize the role of purely syntactic decisionstrategies for parsing and disambiguation. Serial parsing is also assumed, namelythat the human language processor only constructs one parse – backtracking orreanalyzing the sentence if that parse turns out to be incorrect. For these reasons,such models of processing are typically viewed as restricted accounts, since they
fundamentally assume a processing architecture which is limited by the kinds ofinformation it has access to (i.e., syntactic), and the memory resources availablefor parsing.
While there is a considerable body of experimental evidence supporting the
importance of such syntactic strategies, there is also evidence suggesting that peo-ple are nonetheless able to draw upon a large repertoire of relevant constraintsin resolving ambiguity, such as speciﬁc lexical biases, and semantic plausibility(Gibson & Pearlmutter 1998). The general claim of such interactive constraint-based
approaches is that parsing is not a serial process inﬂuenced solely by syntac-tic strategies, but rather that ‘ multiple alternatives are at least partially available,
and that ambiguity resolution is accomplished by the use of correlated constraints fromother domains’ (Trueswell & Tanenhaus 1994). While one might envisage sucha model in symbolic terms, they typically rely on the use of probabilistic con-straints, and are better viewed as hybrid models, which we will we discuss in
Section 6.
3.2 Working memory
The above discussion of the left-corner parser might lead one to believe thatcenter-embeddings are the only unambiguous syntactic structures which causeprocessing difﬁculty. Gibson (1991), however, argues that processing complex-ity arising from working memory demands can also explain ambiguity resolu-tion preferences. Building on Pritchett’s theta attachment strategy (1992), Gibson
attributes a cost to the parser’s need to maintain thematic role assignments and
role ﬁllers in memory. He argues that such a working-memory metric can beused not only to explain increased processing complexity for structures withlocally high memory demands, but also to rank candidate parsers in the face oflocal ambiguity. That is, the parser will generally prefer interpretations whichhave lower cost with respect to unfulﬁlled role relations, thus predicting dis-ambiguation behavior in a manner similar to Pritchett (1992). Gibson’s depen-
dency locality theory (1998) reﬁnes this approach further, by taking into account
the distance between role assigners and role recipients (see also Gibson 2003for an overview). Lewis et al. (2006) propose an account of parsing whichdraws on a number of general observations concerning the dynamics of memoryretrieval that have been established across cognitive domains. These principles

“9781405155816_4_017” — 2010/5/8 — 12:10 — page 493 — #12
Computational Psycholinguistics 493
have also been implemented within the general cognitive architecture ACT-R(Anderson et al., 2004), enabling Lewis and colleagues to provide an indepen-dently motivated proposal regarding the role of working memory in sentenceprocessing.
4 Probabilistic Models
The symbolic accounts outlined above offer insight into both how hierarchical sen-tence structure and meaning are recovered incrementally, and when processing ofsuch sentences may be difﬁcult as a consequence of either working memory lim-itations or the need to reanalyze the sentence if the parser has followed a gardenpath. A variety of empirical results, however, suggest that such symbolic, mod-ular, and serial processing mechanisms may not scale sufﬁciently to account forhuman linguistic performance in general (Crocker 2005). First, serial backtrack-ing parsers are known to be extremely inefﬁcient as grammars are scaled up toprovide realistic linguistic coverage. In addition, such models accord no role tolinguistic experience despite a wealth of experimental ﬁndings indicating thatfrequency information plays a central role in determining the preferred part ofspeech, meaning, and subcategorization frame for a given word. Finally, whilecognitive resources like working memory undoubtedly constrain language pro-cessing, and provide an index of certain kinds of processing complexity, it hasbeen argued that people are in general able to understand most language effec-tively and without conscious effort. Indeed, one of the most challenging tasksfacing computational psycholinguistics is to explain how people are able to dealwith the complexity and pervasive ambiguity of natural language so accuratelyand in real time: what Crocker (2005) dubs the performance paradox.
Probabilistic approaches offer a natural means to address the above issues. Not
only do they provide a means to develop experience-based models, which can
exploit the kinds of frequency information that people have been shown to use,but probabilistic methods have also proven extremely successful for developingwide-coverage models of language processing (see Chapter 3,
STATISTICAL LAN -
GUAGE MODELING , Chapter 4, THEORY OF PARSING , and Chapter 13, STATISTICAL
PARSING ). Perhaps more fundamentally, probabilistic methods invite us to view
language processing less in terms of the difﬁculties people exhibit on some kindsof constructions, and instead emphasize the remarkable performance that peo-ple exhibit in understanding language in general. Chater et al. (1998) explicitlyargue that human language processing may be fruitfully viewed as a rational pro-
cess, in Anderson’s sense of the term (1990). If one views language understandingas a rational cognitive process one can begin by ﬁrst identifying the goal of that
process – e.g., to ﬁnd the correct interpretation of a sentence – and then reasonabout the function that best achieves that goal and accounts for observed behav-ior. One obvious rational analysis of parsing is to assume that the parser choosesoperations so as to maximize the likelihood of ﬁnding the intended global inter-pretation of the sentence, taking into account known cognitive and environmental

“9781405155816_4_017” — 2010/5/8 — 12:10 — page 494 — #13
494 Matthew W. Crocker
limitations. Given the overwhelming evidence that people process language incre-mentally, we can plausibly deﬁne the function that is implemented by the humanlanguage processor as follows:(4)ˆt
i=argmax
tiPi(ti|w1...i,K),∀ti∈Ti
This states that, as each word wiis processed, the preferred analysis of the
sentence-initial substring w1...wi,ˆti, corresponds to the analysis ti–i nt h es e t
of possible analyses Tithat span the sentence up to and including wi–t h a th a st h e
highest likelihood given the words of the sentence, and our general knowledge K.2
Crucially, this equation provides only a high-level characterization of how peopleprocess language, namely at Marr’s computational level , which we will refer to as
thelikelihood hypothesis . It leaves aside many crucial issues concerning howthe anal-
yses are constructed and their probabilities estimated. In principle, the likelihoodof a particular analysis of a sentence might reﬂect not only our accumulated lin-guistic experience as it relates to the current input, but also the current context andour general knowledge K. But just as statistical language processing techniques
have vastly simpliﬁed the kind of information used to condition the probabilities,it may be reasonable to assume that people similarly approximate probabilities,at least during initial processing of the input. In the following sections we reviewseveral proposals that can be viewed as instances of the likelihood hypothesis.
4.1 Lexical processing
Much of the ambiguity that occurs in syntactic processing in fact derives fromambiguity at the lexical level (MacDonald et al., 1994). Furthermore, it is pre-cisely at the lexical level that frequency effects have been most robustly observed:high-frequency words are processed more quickly than low-frequency ones(Grosjean 1980); words are preferentially understood as having their most likelypart of speech (Trueswell 1996; Crocker & Corley 2002); verb subcategorizationpreferences rapidly inﬂuence parsing decisions (Ford et al., 1982; Garnsey et al.,1997; Trueswell et al., 1993); and semantically ambiguous words are preferablyassociated with their more frequent sense (Duffy et al., 1988). These ﬁndings allsuggest that a likelihood-based resolution of lexical ambiguity will substantiallyreduce parsing ambiguity, and assist in guiding the parser towards the most likelyparse in a manner that reﬂects human behavior.
Based on this rationale, Corley and Crocker (2000) propose a broad-coverage
model of lexical category disambiguation as a means for substantially constrainingthe preferred syntactic analysis. Their approach uses a bigram model to incremen-tally determine the most probable assignment of part-of-speech tags, ˆt
0...ˆti,f o r
the (sub)string of input words w0...wi, as follows:
(5)ˆt0...ˆti=argmax
t0...tiP(t0...ti,w0...wi)≈i∏
j=1P(w j|tj)P(t j|tj−1)

“9781405155816_4_017” — 2010/5/8 — 12:10 — page 495 — #14
Computational Psycholinguistics 495
The bigram model results in the use of both the unigram likelihood of word wj
given a possible part of speech tj,P(w j|tj), as well as the context as captured by the
immediately preceding part-of-speech tag P(t j|tj−1). The likelihood for a particular
sequence of parts of speech, ranging from w0towi, is the product of this value as
computed for each word in the string. In order to efﬁciently determine the mostlikely part-of-speech sequence as the sentence is processed, the Viterbi algorithmis used (Viterbi 1967).
(6) a. The warehouse prices are cheaper than the rest .
b. The warehouse makes are cheaper than the rest.
This model capitalizes on the insight that many syntactic ambiguities have a
lexical basis, as in (6). These sentences are ambiguous between a reading in which‘prices’ (6a) or ‘makes ’ (6b) serves as either the main verb or part of a compound
noun. Once trained on a large corpus, the model predicts the most likely partof speech for ‘prices,’ correctly accounting for the fact that people preferentiallyinterpret ‘ prices’ as a noun, but ‘makes ’ as verb (Frazier & Rayner 1987; MacDonald
1993). In the latter case, a difﬁcultly in processing is observed once the sentencedisambiguates ‘makes’ as a noun (Crocker & Corley 2002). The model similarlyaccounts for the ﬁnding that categorially ambiguous words like ‘ that’ are resolved
by their preceding context: in sentence-initial position, ‘ that’ is more likely to be a
determiner, while post-verbally, it is more likely to be a complementizer (Juliano& Tanenhaus 1993).
Interestingly, the use of the Viterbi algorithm to determine the most likely
sequence incrementally predicts that reanalysis may occur when the most prob-able part-of-speech sequence at a given point requires revising a preceding partof speech assigment. This behavior in the model ﬁnds support from a study byMacDonald (1994) showing that reduced-relative clause constructions, like thoseillustrated in (7) were rendered easier to process when the word following theambiguous verb (simple past vs. participle) made the participle reading morelikely.
(7) a. The sleek greyhound admired at the track won four trophies.
b. The sleek greyhound raced at the track won four trophies .
Since ‘admired’ (7a) is transitive, the fact that is it not followed by a noun phrase
is a clear cue that its part of speech should be past participle, and parse inside therelative clause. For ‘ raced ’ (7b), however, which is preferentially intransitive, the
preposition ‘at ’ provides no such cue for rapid reanalysis, resulting in a garden
path when the main verb ‘ won’ is reached.
Importantly, however, the model not only accounts for a range of disambigua-
tion preferences rooted in lexical category ambiguity, it also offers an explanationfor why, in general, people are highly accurate in resolving such ambiguities. It isalso worthwhile to distinguish between various aspects of this account in terms ofMarr’s three levels. Equation (5) provides the computational theory, the likelihood

“9781405155816_4_017” — 2010/5/8 — 12:10 — page 496 — #15
496 Matthew W. Crocker
S
NP
VVP
NP
det N
PP
prepSomeone shot
the servant
NP
det N
the actressofRC
relp S
who ...EnglishSpanish
Figure 17.1 Relative clause attachment ambiguity.
function deﬁning the goal of the process, and its algorithmic instantiation in terms
of the bigram model and the Viterbi algorithm. This highlights the point that onemight change the algorithmic level – e.g., by using a trigram model, should therebe empirical evidence to support this – without in any way changing the compu-tational theory. The implementation level is not provided, since this would entail
a characterization of how the bigram model is processed in the brain and howprobabilities are estimated over the course of our linguistic experience (which wesimply approximate using corpus frequencies).
4.2 Syntactic processing
While lexical disambiguation is an important part of sentence processing, and goesa considerable way towards resolving many structural ambiguities, Corley andCrocker’s model (2000) is clearly not a full model of syntactic processing. Indeed,Mitchell et al. (1995) have taken the stronger view that the human parser not onlymakes use of lexical frequencies, but also keeps track of structural frequencies. Evi-
dence from relative clause attachment ambiguity (see Figure 17.1) has been takento support an experience-based treatment of structural disambiguation. Such con-structions are interesting because they do not hinge on lexical preferences. Whenreading sentences containing the ambiguity in Figure 17.1, English comprehen-ders appear to follow Frazier’s late closure strategy, demonstrating a preferencefor low attachment (where ‘ the actress’ is modiﬁed by the RC ‘who... ’). Spanish
readers, in contrast, when presented with equivalent Spanish sentences, preferhigh attachment (where the RC concerns ‘ the servant ’) (Cuetos & Mitchell 1988).

“9781405155816_4_017” — 2010/5/8 — 12:10 — page 497 — #16
Computational Psycholinguistics 497
This ﬁnding provided evidence against the universality of Frazier’s late closurestrategy (Section 3.1), leading Mitchell et al. (1995) to propose the tuning hypothe-
sis, which asserts that the human parser deals with ambiguity by initially selectingthe syntactic analysis that has worked most frequently in the past (Brysbaert &Mitchell 1996). Later experiments further tested the hypothesis, examining schoolchildren’s preferences before and after a period of two weeks in which exposure tohigh or low examples was increased. The ﬁndings conﬁrmed that even this briefperiod of variation in experience inﬂuenced the attachment preferences as predicted
(Cuetos et al., 1996).
Models of human syntactic processing have increasingly exploited probabilis-
tic grammar formalisms, such as probabilistic context-free grammars (PCFGs) toprovide a uniform probabilistic treatment of lexical and syntactic processing anddisambiguation (for PCFGs, see Manning & Schütze 1999, as well as Chapter 4,
THEORY OF PARSING , and Chapter 13, STATISTICAL PARSING ). PCFGs augment
standard context-free grammars by annotating grammar rules with rule probabil-ities. A rule probability expresses the likelihood of the left-hand side of the ruleexpanding to its right-hand side. As an example, consider the rule VP →VN Pi n
Figure 17.2(a). This rule says that a verb phrase expands to a verb followed by anoun phrase with a probability of 0.7. In a PCFG, the probabilities of all rules withthe same left-hand side must sum to one:(8)∀i∑
jP(Ni→ζj)=1
where P(Ni→ζj)is the probability of a rule with the left-hand side Niand the
right-hand side ζj. For example, in Figure 17.2(a) the two rules VP →VN Pa n d
VP→VP PP share the same left-hand side (VP), so their probabilities sum to one.
The probability of a parse-tree generated by a PCFG is computed as the productof the rule probabilities:(9) P(t)=∏
(N→ζ)∈RP(N→ζ)
where Ris the set of all rules applied in generating the parse-tree t. While rule
probabilities are in theory derived during the course of a person’s linguistic expe-rience, most models rely on standard techniques for estimating probabilities suchasmaximum likelihood estimation –asupervised learning algorithm which calculates
the probability of a rule based on the number of times it occurs in a parsed train-ing corpus. An alternate, unsupervised method is the expectation-maximization
(EM) algorithm (Baum 1972; see also Chapter 12,
SPEECH RECOGNITION ), which
uses an unparsed training corpus to estimate a set of rule probabilities that makesthe sentences in the corpus maximally likely (see also Chapter 8,
UNSUPERVISED
LEARNING AND GRAMMAR INDUCTION ).
Just as lexical frequency may determine the ease with which words are retrieved
from the lexicon, and the preferred morphological, syntactic, and semantic inter-pretations we associate with them, Jurafsky (1996) argues that the probability of a

“9781405155816_4_017” — 2010/5/8 — 12:10 — page 498 — #17
498 Matthew W. Crocker
(a) S →NP VP 1.0
PP→PN P 1 . 0
VP→VN P 0 . 7
VP→VP PP 0.3NP→Det NP 0.6
NP→NP PP 0.2
NP→John 0.2
P→with 1.0V→hit 1.0
N→man 0.5
N→book 0.5
Det→the 1.0
(b) t1;( c)t2;
S 1.0
VP 0.7
PP 1.0
theNP 0.6Det 1.0
theP 1.0V 1.0
Det 1.0NP 0.6
man
with
bookhitNP 0.2
NP 0.2
N 0.5
 N 0.5JohnVP 0.3S 1.0
P 1.0PP 1.0 VP 0.7
V 1.0
the theNP 0.6
Det 1.0 Det 1.0NP 0.2
manwith
bookN 0.5 N 0.5 hitJohn
NP 0.6
P(t1)=1.0×0.2×0.7×1.0×0.2
×0.6×1.0×1.0×0.5×1.0
×0.6×1.0×0.5=0.00252P(t2)=1.0×0.2×0.3×0.7×1.0
×1.0×0.6×1.0×0.6×1.0
×0.5×1.0×0.5=0.00378
Figure 17.2 An example for the parse-trees generated by a probabilistic-context free
grammar (PCFG) (adapted from Crocker & Keller 2006). (a) The rules of a simple PCFGwith associated rule application probabilities. The two parse-trees, (b) and (c), generatedby the PCFG in (a) for the sentence ‘John hit the man with the book ,’ with the respective parse
probabilities, P(t
1)and P(t2), calculated below.
grammar rule corresponds to how easily that rule can be accessed by the humansentence processor during parsing. The consequence of this claim is that struc-tures with greater overall probability should be easier to construct, and thereforepreferred in cases of ambiguity. The PCFG in Figure 17.2(a) generates two parsesfor the the sentence ‘John hit the man with the book .’ The ﬁrst parse t
1attaches the
prepositional phrase ‘with the book ’ to the noun phrase (low attachment) with a
total probability of 0.00252 (see Figure 17.2(b)). The alternative parse t2,w i t ht h e
prepositional phrase attached to the verb phrase (high attachment) is assigned aprobability of 0.00378 (see Figure 17.2(c)). Under the assumption that the proba-bility of a parse determines processing ease, the grammar will predict that t
2(high
attachment) will be generally preferred to t1, as it has a higher probability.
In applying PCFGs to the problem of human sentence processing, Jurafsky
(1996) makes two important observations. First he assumes that parsing, and thecomputation of parse probabilities, takes place incrementally. The consequence is

“9781405155816_4_017” — 2010/5/8 — 12:10 — page 499 — #18
Computational Psycholinguistics 499
Table 17.1 Conditional probability of a
verb frame given a particular verb, asestimated using the Penn Treebank
Verb Frame P(Frame|Verb)
discuss <NP PP> 0.24
<NP> 0.76
keep <NP PP> 0.81
<NP> 0.19
that the parse faces a local ambiguity as soon as it hears the fragment ‘ John hit
the man with ...’ and must decide which of the two possible structures is to be
preferred. This entails that the parser is able to compute preﬁx probabilities forsentence-initial substrings, as the basis for comparing alternative (partial) parses(Stolcke 1995). For the example in Figure 17.2, it should be clear that the prefer-ence for t
2would be predicted even before the ﬁnal NP is processed, since the
probability of that NP is the same for both structures.
The second major contribution of Jurafsky’s approach (1996) is the proposal to
combine structural probabilities generated by a probabilistic context-free gram-mar with probabilistic preferences of individual lexical items, using Bayes’s rule.The model therefore integrates lexical and syntactic probabilities within a singlemathematically founded probabilistic framework. As an example consider thesentences in (10), which have a similar syntactic ambiguity to that outlined inFigure 17.2.
(10) a. ‘The women discuss the dogs on the beach .’
b. ‘The women keep the dogs on the beach .’
The intuition when one reads these sentences is that low attachment of the PP
‘on the beach’t ot h eN P‘ the dogs’ is preferred for (10a), while high attachment to the
verb is preferred for (10b). A standard PCFG model, however, will always preferone of these (in our example PCFG, high attachment). Following Ford et al. (1982),Jurafsky argues that we must also take into account the speciﬁc subcategorizationpreferences of the verb (Table 17.1), in addition to the structural probabilities ofthe PCFG.
Jurafsky’s model computes the probabilities of these two readings based
on two sources of information: the overall structural probability of the high-attachment reading and the low-attachment reading, and the lexical probability ofthe verb occurring with a <NP PP> or a<NP> frame. The structural probability
of a reading is independent of the particular verb involved; the frame probability,however, varies with the verb. This predicts that in some cases lexical probabili-ties can override the general structural probabilities derived from the PCFG. If we

“9781405155816_4_017” — 2010/5/8 — 12:10 — page 500 — #19
500 Matthew W. Crocker
combine the frame probabilities from Table 17.1 with the parse probabilities deter-mined with the PCFG in Figure 17.2, we can see that high-attachment preferenceis maintained for ‘ keep,’ but low attachment becomes more likely for ‘ discuss.’
Strictly speaking, Jurafsky’s model does not aim to recover the single most
likely parse during processing, as suggested in equation (4). Rather he argues fora bounded parallel model, which pursues the most probable parses and prunesthose parses whose probability is less than
1
5the probability of the most likely
parse. Strong garden paths are predicted if the ultimately correct syntactic analysisis one which has been pruned during parsing.
4.3 Wide-coverage models
Jurafsky (1996) outlines how his framework can be used to explain a variety ofambiguity phenomena, including cases like (6) and (7) discussed above. How-ever, it might be criticized for its limited coverage, i.e., for the fact that it usesonly a small lexicon and grammar, manually designed to account for a handful ofexample sentences. Given that broad-coverage parsers are available that computea syntactic structure for arbitrary corpus sentences, it is important that we demandmore substantial coverage from our psycholinguistic models to ensure they are notoverﬁtting to a small number of garden-path phenomena.
Crocker and Brants (2000) present the ﬁrst attempt at developing a truly wide-
coverage model, based on the incremental probabilistic parsing proposals ofJurafsky (1996). Their approach combines the wide-coverage psycholinguisticbigram model of Corley and Crocker (2000) with the efﬁcient statistical parsingmethods of Brants (1999). The resulting incremental cascaded Markov model has
broad coverage, relatively good parse accuracy in general, while also account-ing for a range of experimental ﬁndings concerning lexical category and syntacticambiguities. For practical reasons, Crocker and Brants (2000) do not includedetailed subcategorization preferences for verbs, but rather limit this to transi-tivity, which is encoded as part of a each verb’s part of speech. Adopting a parallelparsing approach not unlike that of Jurafsky, Crocker and Brants (2000) also arguethat re-ranking of parses, not just pruning of the correct parse, is a predictor of
human parsing complexity.
This research demonstrates that, when such models are trained on large cor-
pora, they are indeed able to account for human disambiguation behavior suchas that discussed by Jurafsky (1996). In related work, Brants and Crocker (2000)also demonstrate that broad-coverage probabilistic models maintain high overallaccuracy even under strict memory and incremental processing restrictions. This isimportant to support the claim that rational models maintain their near optimality
even when subject to such cognitively motivated constraints.
4.4 Information-theoretic models
The probabilistic parsing proposals of Jurafsky (1996) and Crocker and Brants(2000) provide relatively coarse-grained predictions concerning human process-ing difﬁculty, based on whether or not the ultimately correct parse was assigned a

“9781405155816_4_017” — 2010/5/8 — 12:10 — page 501 — #20
Computational Psycholinguistics 501
relatively low probability (or pruned entirely), and must be re-ranked (or evenreparsed). Drawing on concepts developed in the statistical language model-ing literature (see Chapter 3,
STATISTICAL LANGUAGE MODELING ), Hale (2001)
proposes a more general linking hypothesis between incremental probabilisticprocessing and processing complexity. Speciﬁcally, Hale suggests that the cog-nitive effort associated with processing the next word, w
i, of a sentence will be
proportional to its surprisal. Surprisal is measured as the negative log-probability
of a word, such that surprising (unlikely) words contribute greater informa-tion than words that are likely, or expected, given the preﬁx of the sentence,w
1...wi−1.
(11) Effort ∝− logP(w i|w1...wi−1, Context )≈− logP(T i)
P(T i−1)
The notion of information, here, derives from information theory (Shannon 1948),
where highly likely or predictable words are viewed as providing little infor-mation, while unexpected words provide more. While, in principle, all ourknowledge about the words w
1...wi−1, linguistics constraints, and non-linguistic
context will determine the probability of wi, Hale assumes the probability can be
reasonably approximated by a PCFG. Speciﬁcally, he proposes that the probabilityof a given (sub)string w
1...wiisTi, which is the sum of all possible parses tifor
the preﬁx string (equation 11). Thought of in this way, surprisal at word wiwill be
proportional to the summed probability of all parses which are disconﬁrmed by the
transition from word wi−1to word wi.
Hale’s theory (2001) thus assumes full parallelism, and can be thought of as
associating cognitive processing effort with the sum of alldisambiguation that is
done during parsing. This contrasts with standard accounts in which it is onlydisconﬁrmation of the preferred interpretation which is assumed to cause pro-
cessing difﬁculty. While the assumption of full parallelism raises some concernsregarding cognitive plausibility, Hale’s model is able to account for a range ofgarden-path phenomena as well as processing complexity in unambiguous con-structions, such as the dispreferred status of object versus subject relative clauses.In recent work, Levy (2008) reﬁnes and extends Hale’s approach (2001) in sev-eral respects, improving the mathematical properties of the surprisal theory while
also extending the empirical coverage of the general approach. Hale (2003) pro-poses another variant on this approach, the entropy reduction hypothesis , in which
cognitive effort is linked to a slightly different measure, namely the reduction inuncertainty about the rest of the sentence.
4.5 Probabilistic semantics
One major limitation of cognitive models of sentence processing is their empha-sis on syntactic aspects of processing. This was arguably justiﬁed to some extentduring the 1980s, when modular theories of language, and cognition in gen-eral, prevailed. Since then, however, a wealth of empirical results have shownthat semantics and plausibility do not only inﬂuence our ﬁnal interpretation of

“9781405155816_4_017” — 2010/5/8 — 12:10 — page 502 — #21
502 Matthew W. Crocker
a sentence, but that such information rapidly informs on-line incremental com-prehension. In the case of the probabilistic parsing models discussed above,probabilities are conditioned purely on syntactic and limited lexical frequencies.For primarily practical reasons, a range of independence assumptions are made.Our PCFG above, for example, will assign exactly the same probability to the sen-tences ‘John hit the man with the book ’a n d‘ John hit the book with the man,’ since
exactly the same rules of grammar are used in deriving the possible parse-trees.Yet clearly the latter is semantically implausible, regardless of how it is parsed,and therefore should be assigned a lower probability.
In experimental psycholinguistics, the on-line inﬂuence of semantic plausibility
has been investigated by varying the argument of a particular verb–argument–relation triple, often called thematic ﬁt. McRae et al. (1998) investigated the
inﬂuence of thematic ﬁt information on the processing of the main clause/reduced-relative clause(MC/RR) ambiguity as illustrated in the sentences below.
(12) a. ‘ The pirate terrorized by his captors was freed quickly .’
b. ‘The victim terrorized by his captors was freed quickly.’
During incremental processing of sentences like (12a), the preﬁx ‘The pirate ter-
rorized ...’ is ambiguous between the more frequent main clause continuation (e.g.,
as in ‘The pirate terrorized the Seven Seas ’) and a less frequent reduced-relative con-
tinuation as shown in (12a), where ‘ terrorized ’ heads a relative clause that modiﬁes
‘pirate.’ The subsequent by-phrase provides strong evidence for the reduced-
relative reading, signaling the absence of a direct object which would otherwisebe required if ‘terrorized ’ were in simple past tense, and suggests it is more likely a
past participle. Finally the main verb region ‘was freed’ completely disambiguatesthe sentence.
Evidence from reading-time experiments has shown that readers initially have
a strong preference for the main clause interpretation over the reduced relative,but that this preference can be modulated by other factors (e.g., Rayner et al.,1983; Crain & Steedman 1985; Trueswell 1996). McRae et al. (1998), in particu-lar, showed that good thematic ﬁt of the ﬁrst NP as an object of the verb in the caseofvictim in (12b) allowed readers to partially overcome the main clause prefer-
ence and more easily adopt the dispreferred reduced-relative interpretation, whichmakes the ﬁrst NP the object of the verb (as opposed to the main clause reading,where it is a subject). Reading-time effects, both on the ambiguous verb and inthe disambiguating region, suggest that the thematic ﬁt of the ﬁrst NP and theverb rapidly inﬂuences the human sentence processor’s preference for the twocandidate structures.
Narayanan and Jurafsky (1998) outline how Bayesian belief networks can be
used to combine a variety of lexical, syntactic, and semantic constraints. Thecentral idea is that we can construct a belief network which integrates multipleprobabilistic sources of evidence, including: structural probabilities determinedby the PCFG; subcategorization preferences as motivated by Jurafsky (1996); verbtense probabilities; thematic ﬁt preferences; and so on. The central problem with

“9781405155816_4_017” — 2010/5/8 — 12:10 — page 503 — #22
Computational Psycholinguistics 503
this framework is that, while extremely powerful and ﬂexible, there is at presentno general method for parsing and constructing such Bayesian belief networksautomatically. Rather, the networks must be constructed by hand for each pos-sible structure to be modeled. We therefore leave aside a detailed discussion ofthis approach, while emphasizing that it may provide a valuable framework formodeling speciﬁc kinds of probabilistic constraints (for a detailed discussion, seeJurafsky 2003).
In recent work, Pado et al. (2009) extend standard probabilistic grammar-based
accounts of syntactic processing with a model of human thematic plausibility. Themodel is able to account for syntactic and semantic effects in human sentence
processing, while retaining the main advantages of probabilistic grammar-basedmodels, namely their ability naturally to account for frequency effects and theirwide coverage of syntactic phenomena and unseen input.
The probabilistic formulation of the semantic model equates the plausibility of a
verb–argument–role triple with the probability of that thematic role co-occurringwith the verb–argument pair – e.g., terrorized -victim-A
GENT . The semantic model
(equation 13) estimates the plausibility of a verb–role–argument triple as the jointprobability of ﬁve variables. These are, apart from the identity of the verb v, argu-
ment aand thematic role r, the verb’s sense s, and the grammatical function gfof
the argument. The verb’s sense is relevant because it determines the set of appli-cable thematic roles, while the grammatical function linking verb and argument(e.g., syntactic subject orsyntactic object) carries information about the thematic role
intended by the speaker.(13) Plausibility
v,r,a=P(v, s,gf,r,a)
This type of generative model can predict the most likely instantiation for missing
input or output values, allowing it to naturally solve its dual task of identifyingthe correct role that links a given verb and argument, and making a plausibilityprediction for the triple. It predicts the preferred thematic role for a verb–argumentpair,ˆr
v,a, by generating the most probable instantiation for the role, as shown in
equation (14).(14) ˆr
v,a=argmax
rP(v, s,gf,r,a)
The semantic model is to a large extent derived automatically from training data:clusters of semantically similar noun and verbs are used to reduce the numberofunseen triples in the semantically annotated FrameNet corpus (Fillmore et al.,
2003). The advantage of this approach is that it eliminates the need to obtainplausibility estimates experimentally (McRae et al., 1998).
In addition to demonstrating that the semantic model reliably predicts a range
of plausibility judgment data, Pado et al. (2009) integrate the model into a broad-coverage sentence processing architecture. The so-called SynSem-Integrationmodel, shown in Figure 17.3, combines a probabilistic parser, in the tradition ofJurafsky (1996) and Crocker and Brants (2000), with the semantic model described

“9781405155816_4_017” — 2010/5/8 — 12:10 — page 504 — #23
504 Matthew W. Crocker
1. . . . 1. . . .
Analyses1. . . .Cost
prediction
Semantic
rankingSyntactic
rankingGlobal
ranking
Semantics
modelSyntax
model
Figure 17.3 The architecture of the SynSem-Integration model, from Pado et al. (2009).
above. The syntax model, based on Roark’s top-down probabilistic parser (2001b),incrementally computes all possible analyses of the input and their probabilities.The semantic model evaluates the resulting structures with respect to the plausi-bility of the verb–argument pairs they contain. Both models simultaneously rankthe candidate structures: the syntax model ranks them by parse probability, andthe semantic model by the plausibility of the verb–argument relations containedin the structures. The two rankings are interpolated into a global ranking to predict
the structure preferred by people. Difﬁculty is predicted with respect to the globalranking and the two local rankings, via two cost functions: conﬂict cost quantiﬁes
the processing difﬁculty incurred in situations where the input yields conﬂictingevidence for which analysis to prefer, while revision cost accounts for the process-
ing difﬁculty caused by abandoning a preferred interpretation of the input andreplacing it with another.
The integration of plausibility into a probabilistic sentence processing archi-
tecture enables Pado et al. (2009) to model the ﬁndings of eight reading-timestudies, covering four ambiguity phenomena, including the NP/S ambiguity(2), PP attachment (10), and reduced-relative clauses (12), discussed earlier.Crucially, each of the modeled studies revealed the on-line inﬂuence of plausi-bility on disambiguation during human parsing. While previous models haveaccounted for some of these ﬁndings with hand crafted models for speciﬁc

“9781405155816_4_017” — 2010/5/8 — 12:10 — page 505 — #24
Computational Psycholinguistics 505
ambiguities (McRae et al., 1998; Narayanan & Jurafsky 1998; Tanenhaus et al.,2000), the SynSem-Integration model offers a wide-coverage model, trained onsyntactically and semantically annotated corpora, avoiding the need to spec-ify the set of relevant constraints and their probabilities by hand for each newphenomenon to be modeled.
5 Connectionist Models of Sentence Processing
Connectionist networks, also called artiﬁcial neural networks (see Chapter 9, ARTI -
FICIAL NEURAL NETWORKS ), offer an alternative computational paradigm with
which to model cognitive development and processing. While there is a tremen-dous variety of network architectures, most derive their inspiration from anabstraction of how the brain works: massively interconnected simple process-ing units (often called neurons) that operate in parallel. These units are usuallygrouped into layers, that themselves are an abstraction of the functional orga-
nization of the brain. Connectionist models of human sentence processing areattractive in that they inherit the experience-based behavior of probabilistic mod-els, as a direct consequence of their ability to learn. Connectionist systems aretypically trained through the adjustment of connection strengths in responseto repeated exposure to relevant examples, thereby providing an integratedaccount of how both acquisition and subsequent processing are determined bythe linguistic environment.
Connectionist models have been successfully applied to various aspects of
human lexical processing, and crucially emphasize the importance of experi-ence, speciﬁcally word frequency, for both learning and subsequent processing(Plunkett & Marchman 1996; Christiansen & Chater 1999a; 2001). Recent research,however, has also seen the emergence of sentence-level connectionist modelswhich place similar emphasis on distributional information.
5.1 Simple recurrent networks
Simple recurrent networks (SRNs) provide an elegant architecture for learning dis-tributional regularities that occur in sequential inputs (Elman 1990). SRNs processpatterns (vectors) rather than symbolic representations. SRNs process sentencesone word at a time, with each new input word represented in the input layer and
interpreted in the context of the sentence processed so far – represented by thecontext layer , which is simply a copy of the hidden layer from the previous time-step
(see Figure 17.4). The input layer and context layer are integrated and compressedinto the hidden layer, enabling the network to incrementally develop a distributedrepresentation of an unfolding sentence. Layers, in turn, may be partitioned intoassemblies that are dedicated to speciﬁc functional tasks. The output layer contains
patterns that the SRN has been trained to compute by providing targets for eachoutput assembly. The target output may be some desired syntactic or semantic

“9781405155816_4_017” — 2010/5/8 — 12:10 — page 506 — #25
506 Matthew W. Crocker
Hidden layerContext layer Input
OutputCopyWordi
Figure 17.4 A simple recurrent network.
representation, but often SRNs are simply trained to predict the next word of theinput, much like a probabilistic language model (see Chapter 3,
STATISTICAL LAN -
GUAGE MODELING ). Each unit in the network receives a weighted sum of the input
units feeding into it, and outputs a value according to an activation function thatgenerally is non-linear in order to bound the output value in an interval such as[0,1], such as the logistic function, σ(x)=(1+e
−x)−1.
SRNs are trained by providing an input sequence and a set of targets into
which the network should transform the input sequence. The standard trainingalgorithm is backpropagation, an optimization technique that uses error signals
derived from the difference between the network’s output and target to updatethe network weights to more closely approximate the targets on the next roundof updates (Rumelhart et al., 1986). The weights between units could themselvesgrow without bound during training, but an input vector xtransformed by the
matrix of weights Wto produce an output vector ythat has been passed through
the activation function σensures yremains bounded. In sum, for each pair of lay-
ers connected by a weight matrix, the output vector can be calculated simply asy=σ(Wx).
One of the strengths of SRNs is that they can be trained on unannotated linguis-
tic data, using the so-called prediction task : the network is presented with sentences,
one word at a time, and is trained to output the next word in the sentence. To do
this successfully, the network must learn those probabilistic and structural prop-erties of the input language that constrain what the next word can be. The keyinsight of SRNs is the use of the context layer, which provides an exact copy ofthe hidden unit layer from the previous time-step. This allows the network tocombine information about its state at the previous time-step with the currentinput word when predicting what words can follow. SRNs have been successfullytrained on simpliﬁed, English-like languages based on grammars which enforcea range of linguistic constraints such as verb frame, agreement, and embedding(Elman 1991). To learn these languages, the network must not only learn simpleadjacencies, like the fact that ‘the’ can be followed by ‘ boy,’ but not ‘ate,’ but also
long-distance dependencies. Consider the following sentence-initial fragment:
(15) ‘The boy that the dog chased ___.’

“9781405155816_4_017” — 2010/5/8 — 12:10 — page 507 — #26
Computational Psycholinguistics 507
In predicting what word will follow chased , the network has to learn that,
although chased is a transitive verb, it cannot be followed by a noun phrase in this
context, because of the relative clause construction. Rather it must be followed bythe main verb of the sentence, which must further be singular since the boy is a
singular subject. Interestingly, however, SRNs do exhibit limitations which appearto correspond well with those exhibited by people, namely in the processing ofcenter-embedding constructions, as discussed in Section 3 (Christiansen & Chater1999b; MacDonald & Christiansen 2002).
As noted, SRNs provide a model of incremental sentence processing, in which
the network is presented with a sentence, word by word, and at each pointattempts to predict which words will follow. Not only are SRNs able to learncomplex distributional constraints with considerable success, they do so in a man-ner which reﬂects the relative frequencies of the training corpus. When the SRNis presented with the initial words of some sentence, w
1...wi, it activates out-
puts corresponding exactly to those words which could come next. Furthermore,the degree of activation of the next word w
i+1corresponds closely to the condi-
tional probability, as would be computed by a statistical language model as shownin equation (16) (see Section 4 above, and Chapter 3,
STATISTICAL LANGUAGE
MODELING ).
(16) P(w i+1|w1...wi)=f(w1...wi+1)
f(w1...wi)
Here, f(w1...wi+1)and f(w1...wi)are the training corpus frequencies for the
word sequences w1...wi+1and w1...wirespectively. The SRN thus predicts not
only which words can follow, but also the likelihood of each of those words, basedon the conditional probabilities of those words in the training corpus.
One fundamental criticism of SRNs, however, is that there is only indirect evi-
dence that syntactic structure is truly being acquired, at least in the conventionalsense. Indeed, it has been argued that, although the language used to train the SRNwas generated by a context-free grammar, the network may only be learning aweaker, probabilistic ﬁnite state approximation in (16), rather than the true hierar-chical structure of the language (Steedman 1999). The lack of any explicit symbolicsyntactic representation in SRNs also makes it difﬁcult to model empirical evi-dence concerning the processing of syntactic ambiguity, since such ambiguity ispredicated on the notion that two or more distinct hypotheses about the struc-ture of the sentence must be distinguished during processing. The visitation setgravitation model of Tabor et al. (1997), however, shows how reading times canbe derived from a post hoc analysis of a trained SRN. This analysis yields a land-scape of attractors – points in multi-dimensional space that are derived from the
hidden unit activations, and which correspond to particular sentence structures.By observing how long it takes a particular hidden unit state (representing aword along with its left-context) to gravitate into an attractor (possibly represent-
ing a kind of semantic integration), Tabor et al. obtain a measure of the work acomprehender does integrating a word into a developing analysis.

“9781405155816_4_017” — 2010/5/8 — 12:10 — page 508 — #27
508 Matthew W. Crocker
Recursive neural networks (RNNs; Costa et al., 2003) can be seen as addressing
Steedman’s criticism (1999) by developing an explicit model of structure disam-biguation processes. RNNs are trained on a complete hierarchical representationof a syntactic tree, which is encoded in a multi-layer feed-forward network inwhich the inputs represent the daughters and the output is the mother of a branchin the tree. The network is trained by exposing it recursively, from the leaves ofthe tree, to each branch of the tree until the root node is reached. The encoding ofthe root node thus represents an encoding of the entire tree. This enables trainingof the network using a parsed corpus (the Penn Treebank; Marcus et al., 1993), inwhich the network learns to make incremental parsing decisions, as in the relativeclause attachment ambiguity shown in Figure 17.1. Just as the SRN estimates theconditional probability of the next word given the words seen so far, the RNN esti-mates the conditional probability of each possible attachment for the current word,given the tree that has been built up to that point. The model therefore resembles aprobabilistic parser, with the exception that RNNs are crucially able to learn global
structural preferences (Sturt et al., 2003), which standard PCFG models are not.RNNs can be seen as an implementation of the tuning hypothesis of Mitchell et al.
(1995) (Section 4.2), in that they are trained solely on syntactic structure, and notspeciﬁc lexical items. One clear limitation of this approach, however, is that it doesnot account for lexical preferences or other kinds of non-structural biases (but seeCosta et al., 2005 for discussion of some enhancements to this approach).
One recent SRN-based model has also sought to model aspects of visually sit-
uated language understanding, as revealed by the visual worlds experiments (see
end of Section 2.2). Mayberry et al. (2009) build on the theoretical proposal ofKnoeferle and Crocker (2007), claiming that utterance-mediated attention in thevisual context is not only driven by incremental and anticipatory linguistic pro-cessing, but crucially that it is this modulation of visual attention that underpinsthe rapid inﬂuence of the relevant visual context on comprehension – which theydub the coordinated interplay account (CIA). Mayberry et al’s CIANet (2009) is based
on a simple recurrent network (SRN; Elman 1990) that produces a case-role inter-pretation of the input utterance. To allow visual input, CIANet incorporates anadditional input representation of a scene as (optional) visual context for theinput utterance. Scenes contain two events, only one of which is relevant to theinput utterance, where each of the two scene events has three constituents (agent,action,a n d patient ) that are propagated to the SRN’s hidden layer through shared
weights (representing a common post-visual-processing pathway).
In line with the language-mediated visual attention mechanisms of the CIA,
the unfolding linguistic input to CIANet modulates the activation of the relevantscene event based on the unfolding interpretation that is represented in the hid-den layer. A gating vector implements the attentional mechanism in CIANet, andis multiplied element-wise with the corresponding units in each of the three lexicalrepresentations (agent, action, and patient) of one event (see Figure 17.5). Each unitof the gate is subtracted from 1.0 to derive a vector-complement that then modu-lates the second event. This means that more attention to one event in the modelentails less attention to another. In this way, as the sentence is processed – possi-bly referring to the characters or actions in one of the scene events – the relevant

“9781405155816_4_017” — 2010/5/8 — 12:10 — page 509 — #28
Computational Psycholinguistics 509
WORD UTTERANCE REPRESENTATIONEvent 1 Event 2
Gate(t )Gate(t–1)
Interpretation
Figure 17.5 CIANet : a network featuring scene–language interaction with a basic
attentional gating mechanism to select relevant events in a scene with respect toan unfolding utterance.
event is activated by the gating vector, causing it to have a greater inﬂuence on theunfolding interpretation. The resulting network was shown to model the on-lineinﬂuence of scene events on comprehension (Knoeferle et al., 2005, Experiment 1),and the relative priority of depicted events versus stereotypical knowledge(Knoeferle & Crocker 2006, Experiment 2), with the gating vector providing aqualitative model of experimentally observed visual attention behavior. While thelinguistic coverage of this model is currently limited to simple sentence structures,it is currently the only cognitive model of visually situated comprehension, andassociated gaze behavior (but see Roy & Mukherjee 2005 for a psycholinguisticallyinspired account of how visual processing can inﬂuence speech understanding).
6 Hybrid Models
Within computational psycholinguistics, hybrid models can broadly be seen asidentifying that class of architectures that combine explicit symbolic representa-tions of linguistic structure and constraints with the use of connectionist inspiredconstraint satisfaction and competitive activation techniques. Typically the goalof such approaches is to combine the transparent use of symbolic linguistic rep-resentations, which are absent in pure connectionist architectures, with the kindsof distributed, competitive, and graded processing mechanisms that are absent inpurely symbolic approaches. One early example is Stevenson’s CAPERS model(1994), in which each word projects its phrasal structure as it is encountered, andinitially all possible connections with the left-context are considered. Each possi-ble attachment is assigned an activation, based on the extent to which it satisﬁesor violates lexical and syntactic constraints. Each node in the structure also hasa limited amount of activation it can assign to its connections, such that as someconnections gain in strength, activation is taken away from others. The parseriterates until it stabilizes on a single, well-formed syntactic parse as each word is

“9781405155816_4_017” — 2010/5/8 — 12:10 — page 510 — #29
510 Matthew W. Crocker
Structural
bias
Structure A Structure BA BLexical
bias
A BThematic
bias
A B
Figure 17.6 The competitive integration model (Spivey-Knowlton & Sedivy 1995).
input. Vosse and Kempen (2000) propose a related model of parsing, based on alexicalized grammar, in which possible uniﬁcation links between words are graded
and compete via lateral inhibition (see also Tabor & Hutchins’s SOPARSE (2004)for a related model, and more general discussion of this approach). The resultingmodel accounts for not only a range of standard parsing phenomena, but also thebehavior found in some aphasic speakers.
As mentioned at the end of Section 3.1, constraint-based models of sentence
disambiguation (MacDonald et al., 1994; Tanenhaus et al., 2000) deny that syn-tactic processes have any distinct modular status with the human languageprocessor, rather assuming that all relevant constraints are integrated during pro-cessing. Such constraint-based accounts exploit the symbolic representations oflinguistic constraints in combination with the use of competition-based constraint-satisfaction techniques (MacDonald et al., 1994). The competitive integration model
(Spivey-Knowlton & Sedivy 1995; Spivey & Tanenhaus 1998), for example, empha-sizes the interaction of various heterogeneous linguistic constraints in resolvingsyntactic ambiguity, each with its own bias (see Figure 17.6), to be combined indeciding between several structural interpretations. For example, one might iden-tify a general structural bias (as proposed by the tuning hypothesis, Section 4.2),a lexical verb frame bias, and perhaps a thematic bias (e.g., the plausibility ofeither structure). McRae et al. (1998) proposed that the bias be established usingexperience-based measures: either corpus frequencies (e.g., for the structural andlexical constraint), or completions norms (e.g., for the thematic constraint). Oncethe relevant linguistic constraints are stipulated, the model allows two kinds ofparameters to be set (Tanenhaus et al., 2000): (1) the weight of each constraint, e.g.,
structural, lexical, and thematic, must be determined, and (2) for each constraint,itsbiastowards Structure A versus Structure B must be established.
Once the parameters for the model have been determined, reading times are
modeled by observing the time it takes the model to settle on a preferred struc-ture as the different constraints compete. Informally, activation is propagated fromeach constraint to a particular structural candidate in accordance with the con-straints bias. The activation of a given structure is then computed as the weighted

“9781405155816_4_017” — 2010/5/8 — 12:10 — page 511 — #30
Computational Psycholinguistics 511
sum of the activations from each constraint. This activation is then propagatedback to the constraints, and another iteration is performed. Once the activationfor a particular structure exceeds a speciﬁc threshold value, the system beginsprocessing the next word. The number of iterations required for processing eachword is then directly linked to the reading times observed during self-paced read-ing. McRae et al. (1998) demonstrate how the model can be used successfully topredict reading times for reduced-relative clauses, as a function of their semanticplausibility, as in example (12), above.
One shortcoming of this approach, however, is that the model separates the
mechanism which builds interpretations from the mechanism which chooses theinterpretation. While independent modeling of the constraint reconciliation mech-anisms might simply be viewed as abstracting away from the underlying structure
building processes, the approach implies that structure building itself does notcontribute to processing complexity, since the constraint integration mechanismsalone determine reading times. Furthermore, it has been standard practice toconstruct a separate model for each syntactic disambiguation phenomenon, eachwith different (possibly overlapping) constraints, and different constraint weights(Tanenhaus et al., 2000). This, combined with the already substantial number ofdegrees of freedom, clearly reduces the predictive capacity and falsiﬁability ofsuch models. Further empirical challenges to such constraint satisfaction mod-els have also been made (Frazier 1995; Binder et al., 2001; but see also Green &Mitchell 2006).
7 Concluding Remarks
The challenges of natural language understanding are daunting. Language isinherently complex – drawing on different levels of linguistic competence, as wellas world and contextual knowledge – while also being highly ambiguous. Thatpeople are nonetheless able to comprehend language accurately and in real time isa remarkable feat that is unmatched by any artiﬁcial system. Computational psy-cholinguistics is concerned with modeling how people achieve such performance,and seeks to develop implemented models of the architectures, mechanisms, andrepresentations involved. The approaches are diverse, ranging from purely sym-bolic accounts to neurally inspired connectionist approaches, with hybrid andprobabilistic models occupying the landscape in between. For reasons of space,we have focused our attention here on models of sentence processing, leavingaside models of lexical access (McClelland & Elman 1986; Norris 1999; Norriset al., 2000). Equally, we have not addressed the topic of language acquisition,which is concerned with how our linguistic knowledge emerges as a consequenceof linguistic experience. While the goals of acquisition and processing models dif-fer with respect to the kinds of empirical data they attempt to explain, ultimatelyit is essential that models of adult sentence comprehension be the plausible endresult of the acquisition process. The increasing dominance of experience-basedmodels of language processing, whether connectionist or probabilistic, holds

“9781405155816_4_017” — 2010/5/8 — 12:10 — page 512 — #31
512 Matthew W. Crocker
promise for a uniform and possibly even integrated account of language acquisi-tion and adult performance (Chater & Manning 2006). Indeed, language learningdrove the early development of connectionist models of lexical and syntacticacquisition (Rumelhart & McClelland 1987; Elman 1990) which now ﬁgure promi-nently in computational psycholinguistics (Tabor et al., 1997; Christiansen &Chater 1999b; 2001; Mayberry et al., 2009). Probabilistic, especially Bayesian,approaches have also been applied to problems of learning argument structure(Alishahi & Stevenson 2008), syntax (Clark 2001a), and semantics (Niyogi 2002).Not surprisingly, however, many models of acquisition emphasize the role ofvisual scene information (see also Siskind 1996). Knoeferle and Crocker (2006)argue that this may explain the priority of visual context in adult sentence pro-cessing – as modeled by the CIANet architecture (Mayberry et al., 2009) – furtherdemonstrating the kind of synergy that may be possible between acquisition andprocessing theories in future.
Virtually all modern accounts of sentence understanding share the assumption
that language processing is highly incremental, with each encountered word beingimmediately integrated into an interpretation of what has been read or heard sofar. Even this assumption, however, has been recently challenged by experimen-tal ﬁndings suggesting that comprehension processes may build interpretationswhich make sense locally , even when they are ungrammatical with respect to the
entire preceding context (Tabor & Hutchins 2004). Nonetheless, incrementality isalmost certainly the rule, even if there are occasional exceptions. Indeed, there isan increasing emphasis on the role of predictive mechanisms in parsing, to explain
the wealth of experimental ﬁndings that people not only process language incre-mentally, but in fact actively generate hypotheses about the words they expect tofollow. Much in the way that statistical language models assign probabilities tothe words that may come next, both probabilistic (Hale 2001; 2003; Levy 2008) andconnectionist (Elman 1990; 1991; Mayberry et al., 2009; Crocker et al., 2010) psy-cholinguistic models potentially offer natural explanations of predictive behaviorin people.
There remain some issues which truly distinguish competing theories. For
example whether or not people actively consider multiple interpretations inthe face of ambiguity, or adopt a single one, backtracking to some alterna-tive when necessary. Similarly, the degree of modularity is often viewed as adeﬁning characteristic. While it has proven challenging to decide deﬁnitivelyamong these positions empirically, there is increasing consensus that languagecomprehension mechanisms must support the rapid and adaptive integrationof virtually all relevant information – linguistic and world knowledge, as wellas discourse and visual context – as reﬂected by incremental and predictivecomprehension behavior (for an overview of relevant empirical ﬁndings, seeCrocker et al., 2010).
Finally, some models that appear quite different superﬁcially may simply be
offering accounts of processing at different levels of abstraction. Connectionist andprobabilistic approaches most often share the idea that language understanding isan optimized process which yields, for example, the most likely interpretation

“9781405155816_4_017” — 2010/5/8 — 12:10 — page 513 — #32
Computational Psycholinguistics 513
for some input based on prior experience. Thus SRNs make very similar behav-ioral predictions to probabilistic language models based on n-grams or PCFGs.
Typically, however, connectionist models intend to provide and account for thealgorithmic or even implementation level in Marr’s terms (recall Section 2.1),while probabilistic approaches may be construed as theories at the higher, compu-
tational, level. That is, while connectionist learning and distributed representationsare postulated to have some degree of biological plausibility, the parsing and train-ing mechanisms of probabilistic models typically are not. Hybrid architecturesoccupy a middle ground, combining explicitly stipulated symbolic representationswith connectionist-inspired processing mechanisms.
The emergence of experience-based approaches represents a major milestone for
computational psycholinguistics, resulting in models that offer broader coverage(Crocker & Brants 2000) and rational behavior (Chater et al., 1998; Crocker 2005),while also explaining a wide range of experimentally observed frequency effects(Jurafsky 2003). As can be seen from the models discussed in this article, however,there is a tendency to isolate language processing from other cognitive processessuch as perception and action. As such, computational models are lagging behindemerging theories of situated and embodied language processing, which empha-size the interplay and overlap of language, perception and action (Barsalou 1999;Fischer & Zwaan 2008; Spivey & Richardson 2009). The CIANet model (May-berry et al. 2009) is one attempt to model visually situated comprehension, therebyalso connecting with situated language learning models, but computational psy-cholinguistics still lags behind current experimental results and theoretical claimsconcerning the integration of language with other cognitive systems. Future devel-opments in this direction will likely connect with models of language acquisition,and ultimately contribute to a better understanding of the origins of the humancapacity for language.
NOTES
1 The essence of this argument is that understanding language ultimately requires full
intelligence – requiring both extensive world knowledge and reasoning abilities – whichremain out of reach in the general case (Shapiro 1992).
2 I deliberately use the term analyses to abstract away from what particular linguistic
representation – lexical, syntactic, semantic, etc. – we might be interested in.

