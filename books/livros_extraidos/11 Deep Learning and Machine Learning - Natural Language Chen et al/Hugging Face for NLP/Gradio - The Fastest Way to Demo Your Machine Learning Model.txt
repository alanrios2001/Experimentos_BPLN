CHAPTER /four.pnum. HUGGING FACE FOR NLP /two.pnum/two.pnum/nine.pnum
/four.pnum./two.pnum/four.pnum Gradio-TheFastestWaytoDemoYourMachineLearningMo del
In this section, we will explore how to create a simpleuser in terface for Natural LanguageProcessing
(NLP) tasks using Gradio. [ /one.pnum/zero.pnum/three.pnum] Gradio is a Python library that makes it easy to create custo mizable
UIs for machine learning models. We will integrate it with a p re-trained model from the Hugging Face
Transformers library to demonstrate how this can be done.
/four.pnum./two.pnum/four.pnum./one.pnum Introduction to Gradio
Gradio allows you to create web interfaces for your machine l earning models with very few lines of
code. It’s especially useful for NLP tasks, where users can i nput text and see real-time results of
model predictions. Here, we will use Gradio to build an inter active demo that uses a Hugging Face
Transformer model to perform text classiﬁcation.
/four.pnum./two.pnum/four.pnum./two.pnum Step-by-Step Guide
Let’s walk through the process of building a Gradio app with a Hugging Face Transformer model. In
this example, we will use a pre-trained model for sentiment a nalysis.
/four.pnum./two.pnum/four.pnum./two.pnum./one.pnum Installing Dependencies
First, ensure you have installed the required libraries. Yo u can install them via pip:
/one.pnum# Install gradio and transformers
/two.pnum!pip install gradio transformers
The ‘transformers‘ library is provided by Hugging Face, whi le ‘gradio‘ is the library used to create
the user interface.
/four.pnum./two.pnum/four.pnum./two.pnum./two.pnum Loading the Pre-trained Model
Next, we will load a pre-trained model andtokenizer from Hug ging Face. For this example, we will use
the‘distilbert-base-uncased-ﬁnetuned-sst-/two.pnum-english‘ model, which istrained for sentimentanalysison
the SST-/two.pnum dataset.
/one.pnumfrom transformers import pipeline
/two.pnum
/three.pnum# Load the sentiment analysis pipeline
/four.pnumsentiment_pipeline = pipeline( "sentiment-analysis" )
The ‘pipeline‘ API simpliﬁes the process of using pre-train ed models for different tasks such as
sentiment analysis, text generation, and translation.
/four.pnum./two.pnum/four.pnum./two.pnum./three.pnum Deﬁning the Gradio Interface
Now, let’s deﬁne the Gradio interface. In Gradio, you deﬁne t he input and output types, and then link
them to a function that performs the model inference. In our c ase, the function will take user input,
pass it through the Hugging Face model, and return the sentim ent.

CHAPTER /four.pnum. HUGGING FACE FOR NLP /two.pnum/three.pnum/zero.pnum
/one.pnumimport gradio as gr
/two.pnum
/three.pnum# Function to analyze sentiment
/four.pnumdef analyze_sentiment(text):
/five.pnumresult = sentiment_pipeline(text)
6return result[0][ ’label’]
/seven.pnum
8# Create Gradio interface
/nine.pnuminterface = gr.Interface(fn=analyze_sentiment,
/one.pnum/zero.pnum inputs="text",
/one.pnum/one.pnum outputs= "text",
/one.pnum/two.pnum title="Sentiment Analysis with Hugging Face" )
/one.pnum/three.pnum
/one.pnum/four.pnum# Launch the interface
/one.pnum/five.pnuminterface.launch()
Explanation:
• The function analyze_sentiment takes a piece of text as input and returns the sentiment label
(either"POSITIVE" or"NEGATIVE" ).
•gr.Interface is used to deﬁne the user interface, where:
–fnis the function that processes the input.
–inputsspeciﬁes the type of input (in this case, text).
–outputs speciﬁes the type of output (text).
–titlesets the title of the web interface.
Once the interface is created, we launch it using interface.launch() . This will generate a local
URL where users can access the interface.
/four.pnum./two.pnum/four.pnum./three.pnum Running the Gradio Interface
After running the code above, a URL will be generated, allowi ng you to open the Gradio interface in
your browser. Users can then type in a sentence, and the model will predict whether the sentiment is
positive or negative.
For example:
•Input: "I love this product!"
•Output: "POSITIVE"
/four.pnum./two.pnum/four.pnum./four.pnum Complete Example
Here is the complete code in one place for reference:

CHAPTER /four.pnum. HUGGING FACE FOR NLP /two.pnum/three.pnum/one.pnum
/one.pnum# Importing necessary libraries
/two.pnumfrom transformers import pipeline
/three.pnumimport gradio as gr
/four.pnum
/five.pnum# Load the sentiment analysis model
6sentiment_pipeline = pipeline( "sentiment-analysis" )
/seven.pnum
8# Function for sentiment analysis
/nine.pnumdef analyze_sentiment(text):
/one.pnum/zero.pnumresult = sentiment_pipeline(text)
/one.pnum/one.pnumreturn result[0][ ’label’]
/one.pnum/two.pnum
/one.pnum/three.pnum# Create Gradio interface
/one.pnum/four.pnuminterface = gr.Interface(fn=analyze_sentiment,
/one.pnum/five.pnum inputs="text",
/one.pnum6 outputs= "text",
/one.pnum/seven.pnum title="Sentiment Analysis with Hugging Face" )
/one.pnum8
/one.pnum/nine.pnum# Launch the interface
/two.pnum/zero.pnuminterface.launch()
/four.pnum./two.pnum/four.pnum./five.pnum Conclusion
In this section, we demonstrated how to integrate Gradio wit h Hugging Face Transformers to create
a simple, interactive sentiment analysis tool. With minima l code, we built a web-based interface that
users can interact with in real time. This framework can be ea sily extended to other NLP tasks, such
as text generation or translation, by simply changing the pr e-trained model in the pipeline.
/four.pnum./two.pnum/four.pnum.6 Extending the Gradio Interface
Now that we’ve successfully built a simple Gradio interface , let’s explore how to extend it by adding
more functionalities. There are many ways to enhance a basic interface, such as including multiple
inputs, adding dropdowns, or integrating different Huggin g Face models. In this section, we’ll explore
these possibilities step by step.
/four.pnum./two.pnum/four.pnum.6./one.pnum Adding Multiple Inputs
In some cases, you might want your interface to accept multip le types of inputs. For example, you
may want to provide the user with a text input for sentiment an alysis and a second input to choose
the model for prediction. We can extend the interface as foll ows:
/one.pnum# Function to analyze sentiment with multiple models
/two.pnumdef analyze_sentiment(text, model_choice):
/three.pnumif model_choice == "DistilBERT" :
/four.pnum model = pipeline( "sentiment-analysis" )
/five.pnumelif model_choice == "BERT":
6 model = pipeline( "sentiment-analysis" , model= "nlptown/bert-base-multilingual-uncased-
sentiment" )

CHAPTER /four.pnum. HUGGING FACE FOR NLP /two.pnum/three.pnum/two.pnum
/seven.pnumresult = model(text)
8return result[0][ ’label’]
/nine.pnum
/one.pnum/zero.pnum# Create Gradio interface with multiple inputs
/one.pnum/one.pnuminterface = gr.Interface(
/one.pnum/two.pnumfn=analyze_sentiment,
/one.pnum/three.pnuminputs=[ "text", gr.inputs.Dropdown(choices=[ "DistilBERT" ,"BERT"], label= "Choose a Model" )],
/one.pnum/four.pnumoutputs= "text",
/one.pnum/five.pnumtitle="Sentiment Analysis with Multiple Models"
/one.pnum6)
/one.pnum/seven.pnum
/one.pnum8# Launch the interface
/one.pnum/nine.pnuminterface.launch()
Explanation:
• We added a dropdown input using gr.inputs.Dropdown ,allowing users to choose between two
models: "DistilBERT" and"BERT".
• Thefunction analyze_sentiment takestwoinputs: text(thesentencetoanalyze)and model_choice
(the selected model).
• Based on the user’s selection, either the DistilBERT or BER T model is loaded, and the sentiment
of the input text is predicted.
This simple addition shows how to incorporate ﬂexibility in to the interface, letting users choose
between multiple pre-trained models.
/four.pnum./two.pnum/four.pnum.6./two.pnum Displaying Multiple Outputs
Gradioalsoallowsforthedisplayofmultipleoutputs. Fore xample,wecouldshowboththesentiment
label and the conﬁdence score of the prediction. Here’s how t o do that:
/one.pnum# Function to return sentiment and confidence
/two.pnumdef analyze_sentiment_with_confidence(text):
/three.pnumresult = sentiment_pipeline(text)
/four.pnumsentiment = result[0][ ’label’]
/five.pnumconfidence = result[0][ ’score’]
6return sentiment, confidence
/seven.pnum
8# Create Gradio interface with multiple outputs
/nine.pnuminterface = gr.Interface(
/one.pnum/zero.pnumfn=analyze_sentiment_with_confidence,
/one.pnum/one.pnuminputs="text",
/one.pnum/two.pnumoutputs=[ "text","number" ],
/one.pnum/three.pnumtitle="Sentiment Analysis with Confidence Score"
/one.pnum/four.pnum)
/one.pnum/five.pnum
/one.pnum6# Launch the interface
/one.pnum/seven.pnuminterface.launch()

CHAPTER /four.pnum. HUGGING FACE FOR NLP /two.pnum/three.pnum/three.pnum
Explanation:
• The function analyze_sentiment_with_confidence returns two values: the sentiment label and
the conﬁdence score (ranging from /zero.pnum to /one.pnum).
• We set the outputs to include both a textoutput (for the sentiment label) and a numberoutput
(for the conﬁdence score).
• Gradio will automatically display the two outputs in the us er interface.
/four.pnum./two.pnum/four.pnum.6./three.pnum Using Other NLP Models
Gradio’s ﬂexibility makes it easy to integrate models for va rious NLP tasks. Let’s explore how we can
use a text generation model from Hugging Face to generate tex t based on user input. We’ll use the
‘gpt/two.pnum‘ model from Hugging Face for this example.
/one.pnum# Load text generation pipeline
/two.pnumtext_gen_pipeline = pipeline( "text-generation" , model= "gpt2")
/three.pnum
/four.pnum# Function to generate text
/five.pnumdef generate_text(prompt):
6result = text_gen_pipeline(prompt, max_length=50, num_r eturn_sequences=1)
/seven.pnumreturn result[0][ ’generated_text’ ]
8
/nine.pnum# Create Gradio interface for text generation
/one.pnum/zero.pnuminterface = gr.Interface(
/one.pnum/one.pnumfn=generate_text,
/one.pnum/two.pnuminputs="text",
/one.pnum/three.pnumoutputs= "text",
/one.pnum/four.pnumtitle="Text Generation with GPT-2"
/one.pnum/five.pnum)
/one.pnum6
/one.pnum/seven.pnum# Launch the interface
/one.pnum8interface.launch()
Explanation:
• The pipeline text-generation is used here to load the GPT-/two.pnum model, which is designed for gen -
erating text.
• The function generate_text takesa text promptasinputandreturnsgeneratedtext with a max-
imum length of /five.pnum/zero.pnum tokens.
• The Gradio interface accepts a text input (prompt) and retu rns the generated text.
/four.pnum./two.pnum/four.pnum./seven.pnum Saving the Interface as a Standalone Web Application
Gradioalsoallowsyoutoeasilydeployyourinterface. Byde fault,Gradiolaunchestheinterfacelocally,
but you can share the application via a public link or host it o n a server for continuous access.

CHAPTER /four.pnum. HUGGING FACE FOR NLP /two.pnum/three.pnum/four.pnum
If you want to save your interface as a standalone Python appl ication that others can run, simply
save the Python code we’ve written in a ‘.py‘ ﬁle, and anyone w ith Python and the required libraries
installed will be able to launch the interface.
For example:
/one.pnum# Save this script as app.py
/two.pnum# To run the app, use the command:
/three.pnum# python app.py
This method is helpful when you want to share the application with other developers or deploy it
in a production environment.
/four.pnum./two.pnum/four.pnum./seven.pnum./one.pnum Deploying the Interface on Hugging Face Spaces
Gradioappscanalso bedeployedon HuggingFace Spaces, whic hallows you to showcaseyour mod-
elsandapplicationsonthewebforfree. HuggingFaceSpaces provideaneasywaytohostyourGradio
applications.
To deploy the app on Hugging Face Spaces, follow these steps:
/one.pnum. Create a repository on Hugging Face Spaces.
/two.pnum. Upload the Python script (e.g., app.py)to the repository.
/three.pnum. Hugging Face will automatically detect the Gradio app and deploy it.
Forexample,youcanﬁndinstructionsfordeployingtoSpace s[here](https://huggingface.co/spaces).
/four.pnum./two.pnum/four.pnum.8 Conclusion
In this extended section, we’ve learned how to enhance a basi c Gradio interface by adding multiple
inputs and outputs, using various Hugging Face models, and e ven creating a text generation tool.
We’vealso touched upon deploying the app as a standalone Pyt hon ﬁle or on Hugging Face Spaces.
This ﬂexibility in both Gradio and Hugging Face makes it incr edibly easy to build and deploy inter-
active applications for a wide variety of NLP tasks. You can n ow experiment with other models and
tasks, such as machine translation or text summarization, t o further expand your knowledge.
/four.pnum./two.pnum/four.pnum./nine.pnum Integrating Gradio with More Complex NLP Pipelines
In previous examples, we used Hugging Face pipelines to quic kly set up models for tasks like sen-
timent analysis and text generation. However, many real-wo rld applications require more complex
workﬂows that may involve multiple steps, such as text prepr ocessing, model inference, and post-
processing.
Inthissection,wewillexplorehowtointegrateGradiowith amorecomplexNLPpipeline,whichwill
involvebothpreprocessingandpost-processingsteps. For thisexample,let’sconsideraNamedEntity
Recognition(NER)taskwhereweextractentitiesfromtexta ndalsoprovideadditionalinformationlike
the type of entity.

CHAPTER /four.pnum. HUGGING FACE FOR NLP /two.pnum/three.pnum/five.pnum
/four.pnum./two.pnum/four.pnum./nine.pnum./one.pnum Preprocessing and Post-Processing in a Pipeline
We will create a pipeline that performs the following steps:
/one.pnum.Preprocessing : Clean the input text (e.g., removing unnecessary whitespa ce).
/two.pnum.Model Inference : Use a Hugging Face model to perform Named Entity Recognitio n.
/three.pnum.Post-Processing : Format the output to display the recognized entities and th eir types in a read-
able format.
/one.pnum# Import necessary libraries
/two.pnumfrom transformers import pipeline
/three.pnumimport gradio as gr
/four.pnumimport re
/five.pnum
6# Load the Named Entity Recognition pipeline
/seven.pnumner_pipeline = pipeline( "ner", grouped_entities=True)
8
/nine.pnum# Preprocessing function
/one.pnum/zero.pnumdef preprocess_text(text):
/one.pnum/one.pnum# Basic text cleaning (removing extra spaces, etc.)
/one.pnum/two.pnumreturn re.sub( r"\s+"," ", text).strip()
/one.pnum/three.pnum
/one.pnum/four.pnum# Post-processing function to format output
/one.pnum/five.pnumdef format_ner_output(entities):
/one.pnum6formatted_result = []
/one.pnum/seven.pnumfor entity in entities:
/one.pnum8 formatted_result.append(f "Entity: {entity[’word’]} - Label: {entity[’entity_grou p’]}")
/one.pnum/nine.pnumreturn"\n".join(formatted_result)
/two.pnum/zero.pnum
/two.pnum/one.pnum# Complete pipeline for NER
/two.pnum/two.pnumdef named_entity_recognition(text):
/two.pnum/three.pnum# Preprocess the text
/two.pnum/four.pnumcleaned_text = preprocess_text(text)
/two.pnum/five.pnum
/two.pnum6# Perform NER using Hugging Face model
/two.pnum/seven.pnumentities = ner_pipeline(cleaned_text)
/two.pnum8
/two.pnum/nine.pnum# Format and return the output
/three.pnum/zero.pnumreturn format_ner_output(entities)
/three.pnum/one.pnum
/three.pnum/two.pnum# Create Gradio interface
/three.pnum/three.pnuminterface = gr.Interface(
/three.pnum/four.pnumfn=named_entity_recognition,
/three.pnum/five.pnuminputs="text",
/three.pnum6outputs= "text",
/three.pnum/seven.pnumtitle="Named Entity Recognition with Preprocessing and Post-Pro cessing"
/three.pnum8)
/three.pnum/nine.pnum
/four.pnum/zero.pnum# Launch the interface

CHAPTER /four.pnum. HUGGING FACE FOR NLP /two.pnum/three.pnum6
/four.pnum/one.pnuminterface.launch()
Explanation:
•Preprocessing : Thepreprocess_text function performs basic text cleaning, such as removing
extra spaces. Thisensuresthattheinputtextisinacleanfo rmatbeforepassingitto themodel.
•ModelInference : Weusethe HuggingFace NER pipeline( pipeline("ner") )to detect entities in
the cleanedtext. The option grouped_entities=True ensuresthat entitiesare groupedtogether.
•Post-Processing : Theformat_ner_output function takes the output of the NER model and for-
mats it in a human-readable format, showing both the recogni zed entity and its label.
•Gradio Interface : The Gradio interface wraps this complete pipeline into a si mple text-based
interface where the user can input raw text, and the recogniz ed entities are displayed in a well-
formatted manner.
/four.pnum./two.pnum/four.pnum./one.pnum/zero.pnum Customizing Gradio for Advanced UIs
Gradio is not limited to simple text-based inputs and output s. It also supports more advanced UIs,
such as:
•Image inputs : For tasks like image classiﬁcation or object detection.
•Audio inputs : For tasks like speech recognition or audio classiﬁcation.
•Checkboxes ,sliders, andradio buttons : For customized inputs.
In this section, we’ll explore how to create a more advanced G radio interface that integrates multi-
ple input types. Let’s build an interface for a multi-modal m odel that can handle both text and image
inputs.
/four.pnum./two.pnum/four.pnum./one.pnum/zero.pnum./one.pnum Building a Multi-Modal Interface
For this example, we will create a Gradio interface that can c lassify text or images depending on the
user’sinput. Wewill allow users to select whether theywant to classify text or an image using a radio
button.
/one.pnum# Import necessary libraries
/two.pnumfrom transformers import pipeline
/three.pnumimport gradio as gr
/four.pnum
/five.pnum# Load text classification and image classification pipeli nes
6text_classifier = pipeline( "text-classification" , model= "distilbert-base-uncased-finetuned-sst-2-
english" )
/seven.pnumimage_classifier = pipeline( "image-classification" , model= "google/vit-base-patch16-224" )
8
/nine.pnum# Function to classify text or image
/one.pnum/zero.pnumdef classify_input(input_type, text=None, image=None):
/one.pnum/one.pnumif input_type == "Text":

CHAPTER /four.pnum. HUGGING FACE FOR NLP /two.pnum/three.pnum/seven.pnum
/one.pnum/two.pnum return text_classifier(text)[0][ ’label’]
/one.pnum/three.pnumelif input_type == "Image":
/one.pnum/four.pnum return image_classifier(image)[0][ ’label’]
/one.pnum/five.pnumelse:
/one.pnum6 return"Invalid input"
/one.pnum/seven.pnum
/one.pnum8# Create Gradio interface with multiple input types
/one.pnum/nine.pnuminterface = gr.Interface(
/two.pnum/zero.pnumfn=classify_input,
/two.pnum/one.pnuminputs=[gr.inputs.Radio(choices=[ "Text","Image"], label= "Input Type" ),
/two.pnum/two.pnum gr.inputs.Textbox(label= "Text Input" , optional=True),
/two.pnum/three.pnum gr.inputs.Image(label= "Image Input" , optional=True)],
/two.pnum/four.pnumoutputs= "text",
/two.pnum/five.pnumtitle="Multi-Modal Classification (Text or Image)"
/two.pnum6)
/two.pnum/seven.pnum
/two.pnum8# Launch the interface
/two.pnum/nine.pnuminterface.launch()
Explanation:
•Multiple Inputs : The interface takes three inputs: a radio button to choose t he input type (either
text or image), a textbox for text input, and an image input. T he inputs for text and image are
optional based on the input type.
•ModelSelection : Basedontheinputtypeselectedbytheuser,eitherthetext classiﬁcationmodel
or the image classiﬁcation model is called.
•Gradio Interface : This example showcases the ﬂexibility of Gradio, allowing you to handle mul-
tiple types of inputs and process them with different models .
/four.pnum./two.pnum/four.pnum./one.pnum/one.pnum Error Handling and Robustness in Gradio Applicatio ns
It’s essential to ensure that your Gradio applications can h andle user errors and unexpected input
gracefully. For instance, a user may forget to enter text, up load the wrong type of ﬁle, or provide input
that the model cannot process.
Here’s how you can add basic error handling to your Gradio app lication to ensure it provides clear
feedback to the user when something goes wrong.
/four.pnum./two.pnum/four.pnum./one.pnum/one.pnum./one.pnum Adding Error Handling for Invalid Input
In the following example, we’ll extend our sentiment analys is interface to check if the input text is
empty or too short, and return an error message in such cases.
/one.pnum# Function with error handling
/two.pnumdef analyze_sentiment_with_error_handling(text):
/three.pnum# Check if input is valid
/four.pnumif not text or len(text.strip()) < 3:
/five.pnum return"Error: Please provide a valid input of at least 3 characters ."

CHAPTER /four.pnum. HUGGING FACE FOR NLP /two.pnum/three.pnum8
6
/seven.pnum# Perform sentiment analysis
8result = sentiment_pipeline(text)
/nine.pnumreturn result[0][ ’label’]
/one.pnum/zero.pnum
/one.pnum/one.pnum# Create Gradio interface
/one.pnum/two.pnuminterface = gr.Interface(
/one.pnum/three.pnumfn=analyze_sentiment_with_error_handling,
/one.pnum/four.pnuminputs="text",
/one.pnum/five.pnumoutputs= "text",
/one.pnum6title="Sentiment Analysis with Error Handling"
/one.pnum/seven.pnum)
/one.pnum8
/one.pnum/nine.pnum# Launch the interface
/two.pnum/zero.pnuminterface.launch()
Explanation:
•Input Validation : We added a condition to check if the input text is either empt y or shorter than
/three.pnum characters. If it is, the function returns an error message instead of trying to pass the input to
the model.
•GracefulErrorMessages : Theuserreceivesaclearmessagewhentheirinputisinvali d,ensuring
a better user experience.
/four.pnum./two.pnum/four.pnum./one.pnum/two.pnum Scaling Gradio Applications for Production
AsyourGradioapplicationgrowsmorecomplexandyouprepar etodeployitforlarger-scaleuse,there
are a few important considerations:
•Model Performance : If you’re working with large models, consider using GPU acc eleration or
optimizing the models for faster inference times.
•Load Balancing : For high-trafﬁc applications, you might need to deploy you r application using
cloud services that offer load balancing (e.g., AWS, GCP, or Azure).
•Authentication : If your application requires user login or restricted acce ss, you can integrate it
with an authentication system, like OAuth.
Gradio makes it easy to scale your interface by supporting de ployment on cloud platforms, inte-
grating with containers (e.g., Docker), and providing opti ons for scaling based on trafﬁc.
/four.pnum./two.pnum/four.pnum./one.pnum/three.pnum Conclusion
In this section, we’ve explored more advanced use cases of Gr adio, including building complex NLP
pipelines with preprocessing and post-processing, handli ng multiple input modalities, implementing
error handling, and deploying applications at scale. Gradi o’s simplicity and ﬂexibility make it an excel-
lenttool forbothrapidprototyping andproduction-leveld eploymentofmachinelearningapplications.
With these tools, you can now create more interactive and use r-friendly NLP applications, extend
them with more complex workﬂows, and scale them for real-wor ld use cases.

CHAPTER /four.pnum. HUGGING FACE FOR NLP /two.pnum/three.pnum/nine.pnum
/four.pnum./two.pnum/five.pnum Deploying Gradio Applications
Onceyou’vebuiltyourGradiointerfaceandtesteditlocall y,thenextlogicalstepistodeployitsoothers
caninteractwithitovertheweb. Inthissection,wewillexp loredifferentmethodsfordeployingGradio
applications, including both free and scalable options. Th e deployment platforms covered include
Hugging Face Spaces, Google Colab, and cloud services like A WS, GCP, and Heroku.
/four.pnum./two.pnum/five.pnum./one.pnum Deploying on Hugging Face Spaces
Hugging Face Spaces is a popular platform for hosting machin e learning demos, and it offers free
hosting for Gradio applications. Spaces are powered by Git r epositories, and Hugging Face automat-
ically handles the setup for Gradio applications, making th is one of the easiest ways to deploy your
project.
/four.pnum./two.pnum/five.pnum./one.pnum./one.pnum Step-by-Step Deployment on Hugging Face Spaces
Here’s how you can deploy your Gradio app on Hugging Face Spac es:
/one.pnum.CreateaHuggingFaceAccount : Ifyoudon’talreadyhaveanaccount,createoneat huggingface.co .
/two.pnum.Create a New Space : Go to the Spaces page and click on “Create new Space”. You can choose
between a public or private space depending on whether you wa nt to share your app publicly.
/three.pnum.UploadYourCode : Createanewrepositoryforyourapp. UploadyourPythonscr ipt(forexample,
app.py) and any other necessary ﬁles, such as a requirements.txt ﬁle to specify the required
libraries. Here’s an example requirements.txt ﬁle:
gradio
transformers
/four.pnum.Deploy the Space : Once the code and required ﬁles are uploaded, Hugging Face S paces will
automatically detect that your application is builtwith Gr adio anddeploy it. Youcan monitor the
build process on the repository page.
/five.pnum.AccessandShare YourApp : Afterthebuildprocesscompletes,youwillreceiveaURLwh erethe
app is hosted. You can share this URL with anyone who wants to i nteract with your Gradio app.
Advantages :
• Free hosting for most use cases.
• Easy integration with Hugging Face models.
• Ideal for showcasing demos and prototypes.
Hugging Face Spaces is an excellent choice for those looking for a hassle-free way to deploy
smaller applications or public demos.
/four.pnum./two.pnum/five.pnum./two.pnum Deploying on Google Colab
Google Colab is another free platform you can use to run and sh are Gradio apps. Colab provides free
GPUs, making it a great option for more compute-intensive ap plications. Although Colab is primarily
a notebook environment, it can also serve Gradio apps.

CHAPTER /four.pnum. HUGGING FACE FOR NLP /two.pnum/four.pnum/zero.pnum
/four.pnum./two.pnum/five.pnum./two.pnum./one.pnum Deploying Gradio on Google Colab
Here’s a simple workﬂow for deploying your Gradio app using G oogle Colab:
/one.pnum.Open a New Colab Notebook : Go toGoogle Colab and create a new notebook.
/two.pnum.Install the Required Libraries : In a code cell, install Gradio and Transformers using pip:
!pip install gradio transformers
/three.pnum.WriteYour GradioApp : Inanothercell, writethePythoncodeforyourGradioapp(e .g.,usingone
of the examples we covered earlier).
/four.pnum.Launch the App : Useinterface.launch() to launch the app. Gradio will generate a public URL
for your app that can be accessed from any device:
interface.launch(share=True)
/five.pnum.SharetheLink : Afterrunningthecell,youwillgetalink(somethinglike https://<unique_id>.gradio.app )
which you can share with others. This link will remain active as long as the Colab notebook is
running.
Advantages :
• Free GPU access for compute-heavy models.
• Easy to share with collaborators and users.
• Suitable for short-term deployments and experimentation .
Keep in mind that Colab sessions will eventually expire, mak ing it better suited for temporary de-
ployments or testing.
/four.pnum./two.pnum/five.pnum./three.pnum Deploying on Heroku
Herokuisapopularcloudplatformthatofferseasydeployme ntforwebapplications, includingGradio
apps. Heroku provides free tier hosting, but it’s limited in terms of uptime and resources.
/four.pnum./two.pnum/five.pnum./three.pnum./one.pnum Deploying Gradio on Heroku
Follow these steps to deploy your Gradio app on Heroku:
/one.pnum.Install Heroku CLI : First, you need to install the Heroku Command Line Interfac e (CLI). You can
ﬁnd installation instructions at Heroku CLI .
/two.pnum.Create a Heroku App : Initialize a Git repository for your Gradio app and run the f ollowing com-
mand in your terminal:
heroku create my-gradio-app
/three.pnum.Prepare Your App for Deployment :
• Ensure that you have a requirements.txt ﬁle that lists all the necessary dependencies.

CHAPTER /four.pnum. HUGGING FACE FOR NLP /two.pnum/four.pnum/one.pnum
• Create a Procfile in the root of your project with the following content:
web: python app.py
/four.pnum.Deploy Your App : Once your repository is ready, push the code to Heroku using Git:
git add .
git commit -m "Deploy␣Gradio␣app"
git push heroku master
/five.pnum.AccesstheApp : Afterthedeploymentiscomplete,HerokuwillprovideaURL foryourapplication.
You can visit the URL to see your Gradio app live.
Advantages :
• Easy to deploy web apps with minimal conﬁguration.
• Scalable if you choose a paid plan.
• Ideal for long-term or production deployments.
Heroku is a great option if you want to maintain an always-on G radio app without worrying about
the underlying infrastructure.
/four.pnum./two.pnum/five.pnum./four.pnum Deploying on Amazon Web Services (AWS)
For large-scale applications that require signiﬁcant comp utational resources or need to handle high
trafﬁc, AWS provides a highly scalable option. You can use se rvices like EC/two.pnum (Elastic Compute Cloud)
or ECS (Elastic Container Service) to deploy your Gradio app .
/four.pnum./two.pnum/five.pnum./four.pnum./one.pnum Deploying Gradio on AWS EC/two.pnum
Here’s a high-level overview of deploying a Gradio app on an A WS EC/two.pnum instance:
/one.pnum.Launch an EC/two.pnum Instance : Goto theAWSManagementConsoleandlaunchanEC/two.pnuminstancew ith
the desiredspeciﬁcations. Choose a machinewith enoughcom pute power for your application.
/two.pnum.Install Dependencies : SSH into the EC/two.pnum instance and install Python, Gradio, Trans formers, and
any other necessary libraries.
/three.pnum.Transfer Your Code : Upload your Gradio application to the EC/two.pnum instance using scpor any ﬁle
transfer method.
/four.pnum.Run the App : Run your Gradio app as you would locally, and use an HTTP serv er like Nginx or
Apache to servetheapp. You canalso conﬁgure Gradioto serve your app on aspeciﬁc portthat
is accessible from the web.
/five.pnum.Access the App : Once the serveris running,you can access the app using the p ublic IP address
of your EC/two.pnum instance.
Advantages :
• Highly scalable and customizable.

CHAPTER /four.pnum. HUGGING FACE FOR NLP /two.pnum/four.pnum/two.pnum
• Access to powerful hardware, including GPUs for compute-i ntensive models.
• Ideal for production-grade deployments.
AWS offers a lot of ﬂexibility, but it also requires more conﬁ guration compared to other platforms.
It’s best suited for large-scale or enterprise application s.
/four.pnum./two.pnum/five.pnum./five.pnum Deploying on Google Cloud Platform (GCP)
Similar to AWS, Google Cloud Platform (GCP) offers scalable options for deploying Gradio apps, in-
cluding using services like Compute Engine (GCE) or Google K ubernetes Engine (GKE).
/four.pnum./two.pnum/five.pnum./five.pnum./one.pnum Deploying Gradio on Google Compute Engine (GCE)
Here’s an overview of deploying on GCP:
/one.pnum.Create a Compute Engine Instance : In the GCP Console, create a new virtual machine (VM)
instance with the appropriate resources.
/two.pnum.Install Dependencies : SSH into the instance and install Python, Gradio, and other libraries your
app requires.
/three.pnum.Transfer Your Code : Upload your Gradio app to the GCP instance.
/four.pnum.Run the App : Runyour Gradio app and conﬁgure the VM instance to allow ext ernal trafﬁc on the
port Gradio is using.
/five.pnum.Access the App : Once the server is running, you can access your app via the ex ternal IP of the
VM instance.
Advantages :
• Google Cloud offers competitive pricing and a robust infra structure.
• Scalable for large applications.
• Suitable for long-term and production use cases.
/four.pnum./two.pnum/five.pnum.6 Conclusion
In this section, we explored various ways to deploy your Grad io applications, from simple and free
options like Hugging Face Spaces and Google Colab to more sca lable and enterprise-gradesolutions
like AWS and GCP.

